{"primary": "Physical Sciences and Engineering",
"domain": "Chemical Engineering",
"subdomain": "Bioengineering",
"journal name": "Biocybernetics and Biomedical Engineering",
"articles": [
    {"article name": "Robotic orthosis compared to virtual hand for Brain–Computer Interface feedback",
     "doi": "https://doi.org/10.1016/j.bbe.2018.12.002",
     "publication date": "06-2019",
     "abstract": "Brain–Computer Interfaces (BCI) allow the control of external devices by decoding the users’ intentions from their central nervous system. Feedback, one of the main elements of a closed-loop BCI, is used to enhance the user's performance. The present work aimed to compare the effect of two different feedback sources; congruent anatomical visual hand representation and passive hand movement on BCI performance and cortical activations. Electroencephalography of 12 healthy right-handed subjects was recorded to set a BCI activated by right-hand motor imagery. Afterward, the subjects were asked to control the system by imagining the movement. The system provided either visual feedback, shown on a computer screen or kinesthetic feedback, provided by a robotic hand orthosis. Differences in performance and cortical activations were assessed, using classification accuracy and event-related desynchronization/synchronization in μ and β bands, respectively. Performance was significantly better with kinesthetic feedback as it allowed for higher correct classification of motor imagery. Cortical activations in the ipsilateral central channel in μ were different between the two feedback modalities. Our results imply that healthy subjects can achieve a greater degree of control using a motor imagery-based BCI with kinesthetic feedback than with anatomically congruent visual feedback. Furthermore, cortical activation differences show that kinesthetic feedback seems to elicit higher recruitment of sensorimotor cortex brain cells, which probably reflects enhanced local information modulation related to fine motor processing. Therefore, kinesthetic feedback provided by a robotic orthosis could be a more suitable feedback strategy for BCI systems designed for neuromodulation and neurorehabilitation.",
     "keywords": ["Motor imagery", "Neurofeedback", "BCI", "Kinesthetic", "Visual", "ERD"]},
    {"article name": "Coupling of inertial measurement units with a virtual world model for supporting navigation in bronchoscopy",
     "doi": "https://doi.org/10.1016/j.bbe.2018.12.001",
     "publication date": "06-2019",
     "abstract": "The purpose of this paper is to provide a method for supporting navigation in bronchoscopy based on measurements of absolute orientation of a tip of a bronchoscope and the length a bronchoscope is pushed in the lumen of an examined bronchial structure.A hardware solution is designed and developed for collecting the data related to the absolute orientation of a tip of a bronchoscope and the length a bronchoscope is pushed in the lumen of an examined structure. A software which processes these data and visualizes in real-time the actual location of a bronchoscope tip in the lumen of a digital model of the examined structure (i.e. virtual bronchoscopy) is also designed and implemented.A calibration procedure is developed which constitutes a basis for the operation of the proposed system. A phantom of a tree-like structure is build, imitating the anatomy of a bronchial tree, and the proposed method of navigation is tested for the task of navigating in the lumen of the phantom to user-selected target locations.A method has been proposed and tested for Inertial Measurement Unit (IMU)-based support of navigation in bronchoscopy.",
     "keywords": ["IMU", "Virtual bronchoscopy", "Surgical guidance", "Image-guided intervention"]},
    {"article name": "A novel fused coupled chaotic map based confidential data embedding-then-encryption of electrocardiogram signal",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.012",
     "publication date": "06-2019",
     "abstract": "In telecardiology applications, research has been underway to protect the patient's confidential information from unauthorized access using Electrocardiogram (ECG) steganography or encryption approaches. A novel Fused Coupled Chaotic Map (FCCM) structure based integrated embedding-then-encryption approach is proposed for patient's confidential data embedding in ECG and its subsequent encryption. The proposed ECG embedding-then-encryption algorithm consists of four phases: confidential data ciphering, LSB embedding, substitution, and permutation. Four FCCMs under different initial conditions and control parameters undergoes level shifting or sorting based quantization. The updation of control parameters made to be ECG content aware of security enhancement. The generated {FCCMi,: i ∈ (1–4)} are applied to (i) cipher confidential data, (ii) craft the embedding locations to hide segmented-ciphered confidential data, (iii) substitution and (iv) permutation processes for data embedding-then-encryption of ECG. The performance of the proposed method was evaluated over MIT-BIH Arrhythmia and self-recorded ECG (lead-II) database. The test suites NIST-800 and 0-1 are employed to check randomness of chaotic sequences. The PRD, PRDN, PRD1024, RMS, SNR, PSNR, WWPRD, WEDD, and BERs were 0.04, 1.05, 0.75, 5.55 × 10−4, 41.21, 70.17, 3.02 × 10−2, 5.91 × 10−3, and 0.00 for MIT-BIH Arrhythmia ECG database (Lead-II) at payload 2.4Kb. Performance measures for Self-recorded dataset are 0.04, 2.62, 2.62, 5.49 × 10−4, 32.16, 68.72, 9.36 × 10−2, 1.93 × 10−2, and 0.00 respectively. Experimental results, security analysis and comparison with existing state-of-art methods prove the effectiveness of the proposed approach for assured patient's confidential data security. Furthermore, the efficiency of the proposed approach has also been evaluated on compressed ECG.",
     "keywords": ["ECG embedding", "ECG steganography", "ECG encryption", "Patient privacy", "Coupled chaotic map", "LSB embedding"]},
    {"article name": "Geometrical parameters of the mandible in 3D CBCT imaging",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.005",
     "publication date": "06-2019",
     "abstract": "The aim of the study is to report on a method for the measurement and analysis of the accuracy in mapping the shape of the mandible spatially modeled based on cone beam imaging. To achieve this goal, the geometrical determinants of the mandible shape were identified; in addition, the accuracy of their cone beam in computer tomography (CBCT) images was verified. The latter – verification of images – was based on reference measures made by a coordinate measuring machine (CMM). The parameters that were analyzed were: Bonville's triangle, the occlusal plane, and the mandible symmetry in relation to the sagittal plane. Descriptive statistics and distribution of individual variables were determined. The results were analyzed statistically using the U-Mann Whitney test. The geometrical parameters of the mandible determined on the basis of CBCT and CMM imaging do not differ significantly.",
     "keywords": ["3D-dimensional analysis", "Virtual model", "Volumetric imaging", "Coordinate measurement", "Mandible shape parameters"]},
    {"article name": "Accurate automated detection of congestive heart failure using eigenvalue decomposition based features extracted from HRV signals",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.001",
     "publication date": "06-2019",
     "abstract": "Congestive heart failure (CHF) is a cardiac abnormality in which heart is not able to pump sufficient blood to meet the requirement of all the parts of the body. This study aims to diagnose the CHF accurately using heart rate variability (HRV) signals. The HRV signals are non-stationary and nonlinear in nature. We have used eigenvalue decomposition of Hankel matrix (EVDHM) method to analyze the HRV signals. The lowest frequency component (LFC) and the highest frequency component (HFC) are extracted from the eigenvalue decomposed components of HRV signals. After that, the mean and standard deviation in time domain, mean frequency calculated from Fourier-Bessel series expansion, k-nearest neighbor (k-NN) entropy, and correntropy features are evaluated from the decomposed components. The ranked features based on t-value are fed to least-squares support vector machine (LS-SVM) classifier with radial basis function (RBF) kernel for automated diagnosis of CHF HRV signals. The study is performed on three normal datasets and two CHF datasets. Our proposed system has yielded an accuracy of 93.33%, sensitivity of 91.41%, and specificity of 94.90% using 500 HRV samples. The automated toolkit can aid cardiac physicians in the accurate diagnosis of CHF patients to confirm their findings with our system. Hence, it will help to provide timely treatment for CHF patients and save life.",
     "keywords": ["Eigenvalue decomposition", "Hankel matrix", "Congestive heart failure", "Heart rate variability", "Non-stationary signal analysis"]},
    {"article name": "The use of the Hellwig's method for feature selection in the detection of myeloma bone destruction based on radiographic images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.008",
     "publication date": "06-2019",
     "abstract": "The radiological test is cost-effective, widely available, allows for the visualisation of large areas of the skeleton and can identify long bones potentially at risk for fractures in osteolysis sites. Therefore, radiology is often used in the early stages of multiple myeloma, in the detection and characterisation of complications, and in the assessment of the patient's response to treatment. The accuracy of this method can be improved through the use of appropriate algorithms of computer image processing and analysis. In the study, the feature vector based on humerus CR images was extracted. As a result of the analysis, 279 image descriptors were obtained. Hellwig's method in the selection process was applied. It found the set of feature combinations of the largest integral index of information capacity. To evaluate these combinations, 11 classifiers were built and tested. As a result, 2 feature sets were identified that provided the highest classification accuracy in combination with the K-NN classifier. The 9-NN classifier for the first combination (2 features) was used and 5-NN for the second one (3 features). The classification accuracy (depending on the quality index used) was as follows: overall classification accuracy – 93%, classification sensitivity – 92%, classification specificity – 96%, positive predictive value – 96% and negative predictive value – 93%. Results show that: (1) the use of humerus CR images may be useful in the detection of bone damages caused by multiple myeloma; (2) the Hellwig's method is effective in the feature selection of the analysed kind of images.",
     "keywords": ["Hellwig's method", "Feature selection", "Texture classification", "Computed radiography", "Multiple myeloma"]},
    {"article name": "Evaluation of filters over different stimulation models in evoked potentials",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.007",
     "publication date": "06-2019",
     "abstract": "Filtering is a key process which removes unwanted parts of signals. During signal recording, various forms of noises distort data. Physiological signals are highly noise sensitive and to evaluate them powerful filtering approaches must be applied. The aim of this study is to compare modern filtering approaches on scalp signals. Brain activities were generally examined by brain signals like EEG and evoked potentials (EP). In this study, data were recorded from university students whose age between 18 and 25 years with visual and auditory stimuli. Discrete wavelet transforms, singular spectrum analysis, empirical mode decomposition and discrete Fourier transform based filters were used and compared with raw data on classification performance. Higuchi fractal dimension and entropy features were extracted from EEG; P300 features were extracted from EP signals. Classification was applied with support vector machines. All filtered data gave better scores than raw data. Empirical mode decomposition (EMD) and Fourier-based filter yielded lower results than the discrete wavelet-based filter. Singular spectrum analysis gave the best result at 84.32%. The current study suggests that singular spectrum analysis removes noise from sensitive physiological signals, and EMD requires new mode selection procedures before resynthesizing.",
     "keywords": ["Filters", "EEG", "Visual evoked potentials", "Auditory evoked potentials", "Attention", "Support vector machine"]},
    {"article name": "Multi-channeled MR brain image segmentation: A novel double optimization approach combined with clustering technique for tumor identification and tissue segmentation",
     "doi": "https://doi.org/10.1016/j.bbe.2018.12.003",
     "publication date": "06-2019",
     "abstract": "Growth of cancer cells within the human body is a major outcome of the manipulation of cells and it has resulted in the deterioration of the life span of humans. The impact of cancer cells is irretrievable and it has paved the way to the formation of tumors within the human body. For achieving and developing a single-structured framework to prominently identify the tumor regions and segmenting the tissue structures specifically in human brain, a novel combinational algorithm is proposed through this paper. The algorithm has been embodied with two optimization techniques namely particle swarm optimization (PSO) and bacteria foraging optimization (BFO), wherein, PSO helps in finding the best position of global bacterium for BFO, consecutively, BFO supports the modified fuzzy c means (MFCM) algorithm by providing optimized cluster heads. Finally, MFCM segments the tissue regions and identifies the tumor portion, thereby reducing the interaction and complication experienced by a radiologist during patient diagnosis. The strength of the proposed algorithm is proven by comparing it with the state-of-the-art techniques by means of evaluation parameters like mean squared error (MSE), peak signal to noise ratio (PSNR), sensitivity, specificity, etc., Data sets used in this paper were exclusively obtained from hospital, Brain web simulator and BRATS-2013 challenge. The sensitivity and specificity values for 115 MR brain slice images are 0.9545 and 0.9905, which prove the segmentation ability and multitude characteristics possessed by the proposed PSBFO based MFCM (PSBFO-MFCM) algorithm.",
     "keywords": ["Tumor identification and tissue segmentation", "Particle swarm optimization", "Bacteria foraging optimization", "Modified fuzzy c-means algorithm.\u2019"]},
    {"article name": "Comparison of traditional image processing and deep learning approaches for classification of white blood cells in peripheral blood smear images",
     "doi": "https://doi.org/10.1016/j.bbe.2019.01.005",
     "publication date": "06-2019",
     "abstract": "Automated classification and morphological analysis of white blood cells has been addressed since last four decades, but there is no optimal method which can be used as decision support system in laboratories due to biologically complex nature of the cells. Automated blood cell analysis facilitates quick and objective results and can also handle massive amount of data without compromising with efficiency. In the present study, we demonstrate classification of white blood cells into six types namely lymphocytes, monocytes, neutrophils, eosinophils, basophils and abnormal cells. We provide the comparison of traditional image processing approach and deep learning methods for classification of white blood cells. We evaluated neural network classifier results for hand-crafted features and obtained the average accuracy of 99.8%. We also used full training and transfer learning approaches of convolutional neural network for the classification. An accuracy around 99% was obtained for full training CNN.",
     "keywords": ["Peripheral blood smear analysis", "White blood cells", "Classification", "Machine learning", "Deep learning"]},
    {"article name": "Granular filter in medical image noise suppression and edge preservation",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.006",
     "publication date": "03-2019",
     "abstract": "An alternative non-linear filtering technique for medical image denoising while preserving edge is introduced. Two different variants of the approach i.e. crisp and fuzzy are developed. The solution is demonstrated based on US breast images as well as CT studies and gave promising results in comparison with commonly known and popular filtering techniques (i.e. spatial averaging and median, bilateral filter, anisotropic diffusion). Many different measures were used to evaluate the method. There are pixel-to-pixel error measures, structural information factors and edge preservation measures. The benefits are noticeable in all three categories.",
     "keywords": ["Granular computing", "Filtering", "Ultrasound images (US)", "Breast", "Computed tomography (CT)"]},
    {"article name": "Detection of Modic changes in MR images of spine using local binary patterns",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.003",
     "publication date": "03-2019",
     "abstract": "With increase in prevalence of lower back pain, fast and reliable computer aided methods for clinical diagnosis associated with the same is needed for improving the healthcare reach. The magnetic resonance images exhibit a change in signal intensity on the vertebral body close to end plates, which are termed as Modic changes (MC), and are known to be clear indicators of lower back pain. The current work deals with computer aided methods for automating the classification of signal changes between normal and degenerate cases so as to aid physicians in precise and suitable diagnosis for the ailment.In order to detect Modic changes in vertebrae, initially the vertebrae are segmented from sagittal MR T1 and T2 imaged using a semi automatic cellular automata based segmentation. This is followed by textural feature extraction using Local Binary Patterns (LBP) and its variants. Various classifiers based on machine learning approaches using Random Forest, kNN, Bayes and SVM were evaluated for its classification performance. Since medical image dataset in general have bias towards healthy and diseased state, data augmentation techniques were also employed.The implemented method is tested and validated over a dataset containing 100 patients. The proposed framework achieves an accuracy of 81% and 91.7% with and without augmentation of data respectively. A comparative study with the state of art methods reported in literature shows that the method proposed in better in terms of computational cost without any compromise on classification accuracy.A novel approach to identify MC in vertebrae by exploiting textural features is proposed. This shall assist radiologists in detecting abnormalities and in treatment planning.",
     "keywords": ["Modic changes", "Vertebral degenerations", "Local binary patterns", "Cellular automata", "Feature detection", "Data augmentation"]},
    {"article name": "Automatic method for assessment of proliferation index in digital images of DLBCL tissue section",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.004",
     "publication date": "03-2019",
     "abstract": "Diffuse large B-cell lymphoma (DLBCL) is a fast-growing and aggressive neoplasm originating from B lymphocytes. Evaluation of proliferation index (PI) based on Ki67 immunohistochemical nuclear staining is used to distinguish proliferating (immunopositive) from nonproliferating (immunonegative) lymphoma cells. Human interpretation of PI varies and is time-consuming, therefore automatic computer-assisted approach may facilitate the performance.Herein we propose a new fully automatic proliferation index estimation (FLAPIE) algorithm, dedicated to detection of immunopositive and immunonegative nuclei, and evaluation of PI in digital microscopy images of DAB&H-stained samples from patients with high-grade DLBCL.FLAPIE performs nuclei detection in original RGB colour space and is independent of image brightness due to its textural-statistical approach. Validation of FLAPIE was performed in 61 non-overlapping whole-slide image fragments and compared to the results of PI estimation by QuPath open-source software, MetPiKi algorithm and manual evaluation by two independent observers. Interobserver agreement was calculated between the nuclei count and PIs by two observers.High concordance was found between both DAB and H-stained nuclei count, and PIs by two observers. Compared to MetPiKi, FLAPIE presented improved results of DAB and H-stained nuclei detection. In contrary to MetPiKi and QuPath, FLAPIE performed nuclei detection in all images and its results closely matched the number of DAB-stained nuclei evaluated by two observers. No significant difference was found between PIs by all computational methods and observers.FLAPIE achieved good results in PI estimation and prospectively aims to serve as a tool for clinical application in support of patients selection and decision to treatment.",
     "keywords": ["DAB 3,3\u2032-diaminobenzidine", "3,3\u2032-diaminobenzidine", "DLBCL diffuse large B-cell lymphoma", "diffuse large B-cell lymphoma", "H haematoxylin", "haematoxylin", "PI proliferation index", "proliferation index", "SD standard deviation", "standard deviation", "WSI whole slide image", "whole slide image", "DLBCL", "Ki67", "Digital histopathology", "Computer-aided diagnosis"]},
    {"article name": "Detection of type-2 diabetes using characteristics of toe photoplethysmogram by applying support vector machine",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.007",
     "publication date": "03-2019",
     "abstract": "Diabetes mellitus (DM) is one of the most widespread and rapidly growing diseases. With its advancement, DM-related complications are also increasing. We used characteristic features of toe photoplethysmogram for the detection of type-2 DM using support vector machine (SVM). We collected toe PPG signal, from 58 healthy and 83 type-2 DM subjects. From each PPG signal 37 different features were extracted for further classification. To improve the performance of SVM and reduce the noisy data we employed hybrid feature selection technique that reduces the feature set of 37 to 10 on the basis of majority voting. Using 10 selected features set, we gained an accuracy of 97.87%, sensitivity of 98.78% and specificity of 96.61%. Further for the validation of our method we need to do random population test, so that it can be used as a non-invasive screening tool. Photoplethysmogram is an economic, technically easy and completely non-invasive method for both physician and subject. With the high accuracy that we obtained, we hope that our work will help the clinician in screening of diabetes and adopting suitable treatment plan for preventing end organ damage.",
     "keywords": ["Diabetes", "Feature selection technique", "Photoplethysmogram", "Principal component analysis", "Second derivative of photoplethysmogram", "Support vector machine"]},
    {"article name": "Design factors of lumbar pedicle screws under bending load: A finite element analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.003",
     "publication date": "03-2019",
     "abstract": "Loosening and breakage of lumbar pedicle screw are the most common complications affecting the spinal stability. The design factors of the pedicle screw that may affect the fixation strength under bending load are pitch length, major diameter, thread profiles and geometry.In this study, 84 finite element (FE) models of the pedicle screw were generated having 7 pitch lengths, 3 major diameters, 2 thread profiles and 2 geometries. The assembly of pedicle screw and CT scan based half section FE model of 4th lumbar vertebra was loaded with a 200 N force on the screw head which is equivalent to a bending moment of 11 Nm.With triangular thread profile and cylindrical geometry, for 300% increase in pitch length (1–4 mm), von Mises stress in screw and von Mises strain in bone increased by 65% and 117% respectively, for a 26% decrease in major diameter (7.6 mm to 5.6 mm) and correlations were proposed among screw stress (r2 = 0.992) or bone strain (r2 = 0.986), pitch length and major diameter. Similar correlations were also proposed for trapezoidal thread profile and tapered geometry (r2 = 0.994 for screw stress and r2 = 0.986 for bone strain).Hence, a combination of tapered pedicle screw with lower pitch length, higher diameter and trapezoidal thread profile may serve better under bending load for lumbar vertebral implant.",
     "keywords": ["Lumbar vertebra", "Bending load", "Implant loosening", "Pedicle screw design factors", "Finite element (FE) analysis"]},
    {"article name": "Magnetic resonance imaging-based brain tumor grades classification and grading via convolutional neural networks and genetic algorithms",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.004",
     "publication date": "03-2019",
     "abstract": "Gliomas are the most common type of primary brain tumors in adults and their early detection is of great importance. In this paper, a method based on convolutional neural networks (CNNs) and genetic algorithm (GA) is proposed in order to noninvasively classify different grades of Glioma using magnetic resonance imaging (MRI). In the proposed method, the architecture (structure) of the CNN is evolved using GA, unlike existing methods of selecting a deep neural network architecture which are usually based on trial and error or by adopting predefined common structures. Furthermore, to decrease the variance of prediction error, bagging as an ensemble algorithm is utilized on the best model evolved by the GA. To briefly mention the results, in one case study, 90.9 percent accuracy for classifying three Glioma grades was obtained. In another case study, Glioma, Meningioma, and Pituitary tumor types were classified with 94.2 percent accuracy. The results reveal the effectiveness of the proposed method in classifying brain tumor via MRI images. Due to the flexible nature of the method, it can be readily used in practice for assisting the doctor to diagnose brain tumors in an early stage.",
     "keywords": ["Brain tumor", "Magnetic resonance imaging", "Medical image classification", "Convolutional neural networks", "Genetic algorithms", "Bagging ensemble algorithm"]},
    {"article name": "Heart rate extraction from PPG signals using variational mode decomposition",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.001",
     "publication date": "03-2019",
     "abstract": "Monitoring of vital signs using the photoplethysmography (PPG) signal is desirable for the development of home-based healthcare systems in the aspect of feasibility, mobility, comfort, and cost-effectiveness of the PPG device. In this paper, a new technique based on the variational mode decomposition (VMD) for estimating heart rate (HR) from the PPG signal is proposed. The VMD decomposes an input PPG signal into a number of modes or sub-signals. Afterward, the modes which are dominantly influenced by the HR information are selected and further processed for extracting HR of the patient. The proposed scheme is validated over a large number of recordings acquired from three independent databases, namely the Capnobase, MIMIC, and University of Queens Vital Sign (UQVS). Experiments are performed over different data length segments of the PPG recordings. Using the data length of 30 s, the proposed technique outperformed the existing techniques by achieving the lower median (1st quartile, 3rd quartile) values of root mean square error (RMSE) as 0.23 (0.19, 0.31) beats per minute (bpm), 0.41 (0.31, 0.56) bpm and 1.1 (0.9, 1.22) bpm for the Capnobase, MIMIC, and UQVS datasets, respectively. Since the shorter data length is more suitable for the clinical applications, the proposed technique also provided satisfactory agreement between the derived and reference HR values for the shorter data length segments. Performance results over three independent datasets suggest that the proposed technique can provide accurate and reliable HR information using the PPG signal recorded from the patients suffering from dissimilar problems.",
     "keywords": ["PPG", "Heart rate", "VMD", "PCA", "STFT"]},
    {"article name": "Gray-level co-occurrence matrix of Fourier synchro-squeezed transform for epileptic seizure detection",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.006",
     "publication date": "03-2019",
     "abstract": "Epilepsy is a brain disorder that many persons of different ages in the world suffer from it. According to the world health organization, epilepsy is characterized by repetitive seizures and more electrical discharge in a group of brain neurons results in sudden physical actions. The aim of this paper is to introduce a new method to classify epileptic phases based on Fourier synchro-squeezed transform (FSST) of electroencephalogram (EEG) signals. FSST is a time-frequency (TF) analysis and provides sharper TF estimates than the conventional short-time Fourier transform (STFT). Absolute of FSST of EEG signal is computed and segmented into five non-overlapping frequency sub-bands as delta (δ), theta (θ), alpha (α), beta (β), and gamma (γ). Each sub-band is considered as a gray-scale image and then we propose to obtain the gray-level co-occurrence matrix (GLCM) of each sub-band as features. We concatenate the features of different sub-bands to obtain the final feature vector. After selecting informative features by infinite latent feature selection (ILFS) method, the support vector machine (SVM) and K-nearest neighbor (KNN) classifiers are used separately to classify EEG signals. We use the EEG signals from Bonn University database and different combinations of its sets are considered. Simulation results show that the proposed method efficiently classifies the EEG signals and can be used to determine the phase of epilepsy.",
     "keywords": ["EEG signal", "Epileptic seizure", "Fourier synchro-squeezed transform (FSST)", "Gray-level co-occurrence matrix (GLCM)"]},
    {"article name": "Assessment of despeckle filtering algorithms for segmentation of breast tumours from ultrasound images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.002",
     "publication date": "03-2019",
     "abstract": "In the present work, the performance assessment of despeckle filtering algorithms has been carried out for (a) noise reduction in breast ultrasound images and (b) segmentation of benign and malignant tumours from breast ultrasound images. The despeckle filtering algorithms are broadly classified into eight categories namely local statistics based filters, fuzzy filters, Fourier filters, multiscale filters, non-linear iterative filters, total variation filters, non-local mean filters and hybrid filters. Total 100 breast ultrasound images (40 benign and 60 malignant) are processed using 42 despeckle filtering algorithms. A despeckling filter is considered to be appropriate if it preserves edges and features/structures of the image. Edge preservation capability of a despeckling filter is measured by beta metric (β) and feature/structure preservation capability is quantified using image quality index (IQI). It is observed that out of 42 filters, six filters namely Lee Sigma, FI, FB, HFB, BayesShrink and DPAD yield more clinically acceptable images in terms of edge and feature/structure preservation. The qualitative assessment of these images has been done on the basis of grades provided by the experienced participating radiologist. The pre-processed images are then fed to a segmentation module for segmenting the benign or malignant tumours from ultrasound images. The performance assessment of segmentation algorithm has been done quantitatively using the Jaccard index. The results of both quantitative and qualitative assessment by the radiologist indicate that the DPAD despeckle filtering algorithm yields more clinically acceptable images and results in better segmentation of benign and malignant tumours from breast ultrasound images.",
     "keywords": ["Breast ultrasound", "Speckle noise", "Despeckling filters", "Image quality metrics", "Structure and edge preservation", "Segmentation"]},
    {"article name": "Computer-aided detection of mesial temporal sclerosis based on hippocampus and cerebrospinal fluid features in MR images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.005",
     "publication date": "03-2019",
     "abstract": "Mesial temporal sclerosis (MTS) is the commonest brain abnormalities in patients with intractable epilepsy. Its diagnosis is usually performed by neuroradiologists based on visual inspection of magnetic resonance imaging (MRI) scans, which is a subjective and time-consuming process with inter-observer variability. In order to expedite the identification of MTS, an automated computer-aided method based on brain MRI characteristics is proposed in this paper. It includes brain segmentation and hippocampus extraction followed by calculating features of both hippocampus and its surrounding cerebrospinal fluid. After that, support vector machines are applied to the generated features to identify patients with MTS from those without MTS. The proposed technique is developed and evaluated on a data set comprising 15 normal controls, 18 left and 18 right MTS patients. Experimental results show that subjects are correctly classified using the proposed classifiers with an accuracy of 0.94 for both left and right MTS detection. Overall, the proposed method could identify MTS in brain MR images and show a promising performance, thus showing its potential clinical utility.",
     "keywords": ["Mesial temporal sclerosis", "Hippocampus", "Segmentation", "Support vector machines"]},
    {"article name": "Adaptive shrinkage on dual-tree complex wavelet transform for denoising real-time MR images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.003",
     "publication date": "03-2019",
     "abstract": "Performance of denoising filters which are based on the principle of wavelet thresholding greatly depends upon selection of the threshold value. An objective method is proposed in this paper for computing the optimum value of threshold in DTCWT based denoising. At optimum threshold, annoying intensity transitions of pixels in the homogeneous regions of the images, contributed by noise get completely suppressed and the true edges remain unaffected. For finding optimum value of threshold a newly derived quality metric termed as Optimum Denoising Index (ODI), which quantifies both the edge-preservation and smoothing of homogeneous regions is used. The ODI values corresponding to mean, median, Gaussian, Wiener, Bilateral, Kuwahara filters and wavelet thresholding are 0.1192 ± 0.0118, 0.2196 ± 0.0125, 0.1283 ± 0.0118, 0.2106 ± 0.0145, 0.1590 ± 0.0331, 0.2200 ± 0.0101 and 0.2516 ± 0.0094, respectively. The wavelet thresholding has better edge-preservation and denoising capacity than the said denoising schemes. The ODI is highly correlated with its existing alternatives like Peak Signal to Noise Ratio (PSNR) and Structured Similarity Index Metric (SSIM) with values 0.9165 ± 0.0536 and 0.9050 ± 0.0452 respectively. This shows ODI is a good alternative to PSNR and SSIM.",
     "keywords": ["Dual Tree Complex Wavelet Transform (DTCWT)", "Edge preservation index", "Edge preserved smoothing", "Magnetic Resonance Imaging (MRI)", "Optimum Denoising Index (ODI)", "Wavelet thresholding"]},
    {"article name": "A new framework using deep auto-encoder and energy spectral density for medical waveform data classification and processing",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.004",
     "publication date": "03-2019",
     "abstract": "This paper proposes a new framework for medical data processing which is essentially designed based on deep autoencoder and energy spectral density (ESD) concepts. The main novelty of this framework is to incorporate ESD function as feature extractor into a unique deep sparse auto-encoders (DSAEs) architecture. This allows the proposed architecture to extract more qualified features in a shorter computational time compared with the conventional frameworks.In order to validate the performance of the proposed framework, it has been tested with a number of comprehensive medical waveform datasets with varying dimensionality, namely, Epilepsy Serious Detection, SPECTF Classification and Diagnosis of Cardiac Arrhythmias. Overall, the ESD function speeds up the deep auto-encoder processing time and increases the overall accuracy of the results which are compared to several studies in the literature and a promising agreement is achieved.",
     "keywords": ["Energy spectral density", "Deep auto-encoder", "Deep learning", "Medical waveform data process"]},
    {"article name": "Automated detection of the preseizure state in EEG signal using neural networks",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.007",
     "publication date": "03-2019",
     "abstract": "The life-threatening neural syndrome epilepsy is elicited by seizure which affects over 50 million people in the universal. A seizure is a brain condition made by excessive, unusual exoneration by nerve cells of the brain. Contemporary seizure forecast research works exhibited worthy results in both undersized and lengthy electroencephalography (EEG) signal; however it is essential to formulate superior epileptic seizure forecast system; that shall be steady, constant and less resource intensive for effectively employed to heading for evolving a convenient and easily manageable ictal or seizure forewarning prearrangement or devices. Based on our exploration, we have found a novel seizure prediction method which we evaluated by producing ten sub-frequency EEG data from initially recorded signal. Simple, robust and computationally less-intense EEG characteristics are mined using the generated sub-frequency signals and applied the extracted features to computationally less intense generalized regression neural network (GRNN) to segregate EEG signal clips into normal or preseizure files. In this research work, we have engendered 10 sub-frequency bands of signals from original EEG recordings, extracted various meaningful features from those sub-frequency band signals, created 10 GRNN neural networks to categorize feature files as normal or preseizure, and then applied post-processing techniques with 10 thresholding mechanisms to each classifier output. As such, we determined that seizure forewarning may function better in various sub-frequency bands for many patients in a subject-specific manner. We also found that epileptic-seizure forecast performed superior at ‘60 Hz high pass’ filtered sub-frequency band EEG signal for all subjects or canines data.",
     "keywords": ["Interictal", "Preictal", "Preseizure", "Seizure prediction", "Generalized regression neural networks", "Sub-frequency band"]},
    {"article name": "Chemotherapy-induced fatigue estimation using hidden Markov model",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.002",
     "publication date": "03-2019",
     "abstract": "Chemotherapy-induced fatigue undermines the physical performance and alter gait behaviour of patients. In clinics, there is not a well-established method to objectively assess the effects of chemotherapy-induced fatigue on gait characteristics. Clinical trials commonly use 6 Minute Walking Tests (6MWT) to assess patients’ gait. However, these studies only measure the distance that patients can walk. The distance does not provide comprehensive information about variations in ambulatory motion characteristics and body postural behaviour which can more appropriately describe the fatigue effects on general physical performance. Gait characteristics provide a manifestation of relationships between muscular and cardiovascular fitness status and physical motions. Hence, an assessment of gait characteristics provides more appropriate information about the effects of chemotherapy-induced fatigue on gait behaviour. A novel approach is proposed to objectively assess the impacts of chemotherapy-induced fatigue on cancer gait by analysing the gait characteristics during 6MWT. The joint angles of the lower body segments are measured by inertial sensors and modelled through a Hidden Markov Model (HMM) with Gaussian emissions. A Gaussian clustering method classifies the joint angles of first gait cycle to determine the six gait phases of a normal gait as initial training values. A comparison of gait characteristics before and after chemotherapy-induced fatigue determines the gait abnormalities. The method is applied to four cancer patients and outcomes are benchmarked against the gait of a healthy subject before and after running program-induced fatigue. The results indicate a more accurate quantitative-based tool to measure the effects of chemotherapy-induce fatigue on gait and physical performance.",
     "keywords": ["Chemotherapy-induced fatigue", "Inertial sensors", "Gait analysis", "Hidden Markov model"]},
    {"article name": "Primary stenosis progression versus secondary stenosis formation in the left coronary bifurcation: A mechanical point of view",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.006",
     "publication date": "03-2019",
     "abstract": "Biomechanical forces and hemodynamic factors influence the blood flow and the endothelial cells (ECs) morphology. These factors behave differently beyond the coronary artery stenosis. In the present study, unsteady blood flow in the left coronary artery (LCA) and its atherosclerotic bifurcating vessels, left anterior descending (LAD) and left circumflex (LCX) arteries, were numerically simulated to investigate the risk of plaque length development and secondary plaque formation in the post-stenotic areas. Using fluid–structure interaction (FSI) model, compliance of arterial wall and vessel curvature variations due to cardiac motion were considered. The arteries included plaques at the beginning of the bifurcation. Stenosis degree varied from 40% to 70% based on diameter reduction. Healthy coronary artery was also reconstructed to compare with the atherosclerotic arteries. Circumferential and longitudinal strains of ECs as well as wall shear stress (WSS) were computed in different locations downstream of the stenosis. It was concluded that the most critical regions experiencing low circumferential strain and low WSS were located proximal to the plaque throat, and the effects of these parameters intensified by stenosis degree. The results proposed that primary plaque length progression is more probable than secondary plaque formation distal to the stenosis when the stenosis degree increases.",
     "keywords": ["Stenosis", "Coronary arteries", "Wall shear stress", "Strain", "Fluid\u2013structure interaction"]},
    {"article name": "Support vector machine classification of brain states exposed to social stress test using EEG-based brain network measures",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.008",
     "publication date": "03-2019",
     "abstract": "Stress is one of the most significant health problems in the 21st century, and should be dealt with due to the costs of primary and secondary cares of stress-associated psychological and psychiatric problems. In this study, the brain network states exposed to stress were monitored based on electroencephalography (EEG) measures extracted by complex network analysis. To this regard, 23 healthy male participants aged 18–28 were exposed to a stress test. EEG data and salivary cortisol level were recorded for three different conditions including before, right after, and 20 min after exposure to stress. Then, synchronization likelihood (SL) was calculated for the set of EEG data to construct complex networks, which are scale reduced datasets acquired from multi-channel signals. These networks with weighted connectivity matrices were constructed based on original EEG data and also by using four different waves of the recorded signals including δ, θ, α, and β. In addition to these networks with weighted connectivity, networks with binary connectivity matrices were also derived using threshold T. For each constructed network, four measures including transitivity, modularity, characteristic path length, and global efficiency were calculated. To select the sensitive optimal features from the set of the calculated measures, compensation distance evaluation technique (CDET) was applied. Finally, multi-class support vector machine (SVM) was trained in order to classify the brain network states. The results of testing the SVM models showed that the features based on the original EEG, α and β waves have got better performances in monitoring the brain network states.",
     "keywords": ["Trier social stress test", "Complex brain network", "Synchronization likelihood", "Support vector machine"]},
    {"article name": "Automatic mitosis detection in breast histopathology images using Convolutional Neural Network based deep transfer learning",
     "doi": "https://doi.org/10.1016/j.bbe.2018.10.007",
     "publication date": "03-2019",
     "abstract": "The exact measure of mitotic count is one of the crucial parameters in breast cancer grading and prognosis. Detection of mitosis in standard H & E stained histopathology images is challenging due to diffused intensities along object boundaries and shape variation in different stages of mitosis. This paper explores the feasibility of transfer learning for mitosis detection. A pre-trained Convolutional Neural Network is transformed by coupling random forest classifier with the initial fully connected layers to extract discriminant features from nuclei patches and to precisely prognosticate the class label of cell nuclei. The modified Convolutional Neural Network accurately classify the detected cell nuclei with limited training data. The designed framework accomplishes higher classification accuracy by carefully fine tuning the pre-trained model and pre-processing the extracted features. Moreover, proposed method is evaluated on MITOS dataset provided for the MITOS-ATYPIA contest 2014 and clinical data set from Regional Cancer Centre, Thiruvananthapuram, India. Significance of Convolutional Neural Network based method is justified by comparing with recently reported works including a Multi Classifier System based on Deep Belief Network. Experiments show that the pre-trained Convolutional Neural Network model outperforms conventionally used detection systems and provides at least 15% improvement in F-score on other state-of-the-art techniques.",
     "keywords": ["Histopathology", "Mitosis", "Krill herd optimization", "Convolutional Neural Network", "Transfer learning", "Random forest"]},
    {"article name": "A CFD investigation of intra-aortic balloon pump assist ratio effects on aortic hemodynamics",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.009",
     "publication date": "03-2019",
     "abstract": "Intra-aortic balloon pump (IABP) is a mechanical circulatory support approach used in case of several cardiac diseases and a challenge of IABP therapy is the weaning process accomplished by decreasing the assist ratio. However, the impact of weaning on aortic hemodynamics on organs perfusions is not well known.Aim of this study was to evaluate and compare the global effects of IABP assistance frequencies on hemodynamics and perfusions in a patient-specific geometry by means of the computational fluid dynamics (CFD). A 3D aorta model was obtained from CT images using segmentation and reverse engineering techniques. The balloon was modeled and positioned in the descending aorta as in clinical practice and its inflation/deflation behavior was realized with a parametric study. Four assist ratios have been investigated: full assistance (1:1), partial assistances (1:2 and 1:3) and weak assistance (1:4). To perform the comparison, same boundary conditions were applied.Our results highlighted that the presence of balloon in aorta modifies significantly its hemodynamics and that the four assist ratios generate different perfusions in the human districts. Data suggested also that the biggest difference occurs between 1:2 and 1:3 frequencies and that 1:4 ratio is more suitable for the weaning of counterpulsation treatment than the 1:3 ratio.This first CFD analysis of IABP weaning increases information and knowledge on hemodynamics and organs perfusions.",
     "keywords": ["Computational fluid dynamics (CFD)", "Intra-aortic balloon pump (IABP)", "Aorta", "Hemodynamics", "Assist ratio"]},
    {"article name": "A speech recognition system based on electromyography for the rehabilitation of dysarthric patients: A Thai syllable study",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.010",
     "publication date": "03-2019",
     "abstract": "The objective of this study is to develop a speech recognition system for classifying nine Thai syllables, which is used for the rehabilitation of dysarthric patients, based on five channels of surface electromyography (sEMG) signals from the human articulatory muscles. After the sEMG signal from each channel was collected, it was processed by a band-pass filter from 20–450 Hz for noise removal. Then, six features from three feature categories were determined and analyzed, namely, mean absolute value (MAV) and wavelength (WL) from amplitude based features (ABF), zero crossing (ZC) and mean frequency (MNF) from frequency based features (FBF), and L-kurtosis (L-KURT) and L-skewness (L-SKW) from statistics based features (SBF). Subsequently, a spectral regression extreme learning machine (SRELM) was used as the feature projection technique to reduce the dimension of feature vector from 30 to 8. Finally, the projected features were classified using a feed forward neural network (NN) classifier with 5-fold cross-validation. The proposed system was evaluated with the sEMG signals from seven healthy volunteers and five dysarthric volunteers. The results show that the proposed system can recognize the sEMG signals from both healthy and dysarthric volunteers. The average classification accuracies obtained from all six features in the healthy and dysarthric volunteers were 94.5% and 89.4%, respectively.",
     "keywords": ["Dysarthria", "Surface electromyography (sEMG)", "Feature", "Classification", "Speech recognition system"]},
    {"article name": "Multi-channel acoustic analysis of phoneme /s/ mispronunciation for lateral sigmatism detection",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.005",
     "publication date": "03-2019",
     "abstract": "The paper presents a method for computer-aided detection of lateral sigmatism. The aim of the study is to design an automated sigmatism diagnosis tool. For that purpose, a reference speech corpus has been collected. It contains 438 recordings of a phoneme /s/ surrounded by certain vowels with normative and simulated pathological pronunciation. The acoustic signal is recorded with an acoustic mask, which is a set of microphones organised in a semi-cylindrical surface around the subject's face. Frames containing /s/ phoneme are subjected to beamforming and feature extraction. Two different feature vectors containing, e.g., Mel-frequency cepstral coefficients and fricative formants, are defined and evaluated in terms of binary classification involving support vector machines. A single-channel analysis is confronted with multi-channel processing. The experimental results show that the multi-channel speech signal processing supported by beamforming is able to increase the pathology detection capabilities in general.",
     "keywords": ["Computer-aided speech diagnosis", "Lateral sigmatism", "Multi-channel speech acquisition", "Automated acoustic analysis"]},
    {"article name": "A novel method to design an electro-kinetic platform based on complementary metal-oxide semiconductor technology using SKILL scripting of cadence",
     "doi": "https://doi.org/10.1016/j.bbe.2018.11.011",
     "publication date": "03-2019",
     "abstract": "The dielectrophoresis (DEP) is the motion of polarizable particles which is a result of the interaction between a non-uniform electric field and the induced dipole moment of these particles. The electro-kinetic DEP is a widely used technique for biological cells’ manipulation, characterization and separation. The electro-kinetic DEP consists of three major configurations, they are; traveling wave dielectrophoresis (twDEP), electro-rotation dielectrophoresis (rotDEP), and levitation (levDEP). In this paper, a design of electrokinetic platform that includes the three electrokinetic configurations is presented and discussed. The design of the electrokinetic platform is implemented and simulated using 130 nm complementary metal-oxide-semiconductor (CMOS) technology. Also, this paper presents a developed technique to design the electrokinetic platform's electrodes. This developed technique is the usage of SKILL scripting of cadence (SSC) language. CMOS is a technology which is used to fabricate integrated circuits (IC). SKILL is a scripting language which supports the automation of a specific layout design by commands. The layout of electrokinetic DEP platform is developed using SSC. The performance of the developed electrokinetic platform using SSC versus the platforms based on the other traditional techniques is presented and evaluated using COMSOL Multiphysics®.",
     "keywords": ["Dielectrophoresis", "Electro-kinetic", "Traveling", "Levitation", "SKILL scripting of cadence"]},
    {"article name": "Validation of Emotiv EPOC+ for extracting ERP correlates of emotional face processing",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.006",
     "publication date": "01-2018",
     "abstract": "The article presents our proposed adaptation of the commercially available Emotiv EPOC+ EEG headset for neuroscience research based on event-related brain potentials (ERP). It solves Emotiv EPOC+ synchronization problems (common to most low-cost systems) by applying our proposed stimuli marking circuit. The second goal was to check the capabilities of our modification in neuroscience experiments on emotional face processing. Results of our experiment show the possibility of measuring small differences in the early posterior negativity (EPN) component between neutral and emotional (angry/happy) stimuli consistently with previous works using research-grade EEG systems.",
     "keywords": ["EEG", "Emotiv EPOC+", "ERP", "Early posterior negativity", "Emotional facial expression"]},
    {"article name": "Formulation and statistical evaluation of an automated algorithm for locating small bowel tumours in wireless capsule endoscopy",
     "doi": "https://doi.org/10.1016/j.bbe.2018.07.003",
     "publication date": "01-2018",
     "abstract": "Wireless capsule endoscopy (WCE) is an imaging modality which is highly reliable in the diagnosis of small bowel tumors. But locating the frames carrying tumors manually from the lengthy WCE is cumbersome and time consuming. A simple algorithm for the automated detection of tumorous frames from WCE is proposed in this work. In the proposed algorithm, local binary pattern (LBP) of the contrast enhanced green channel is used as the textural descriptor of the WCE frames. The features employed to differentiate tumorous and non-tumorous frames are skewness (S) and kurtosis (K) of the LBP histogram. The threshold value of the features which offers the trade-off between sensitivity and specificity is identified through Receiver Operating Characteristic (ROC) curve analysis. At the optimum threshold, both the features exhibited a sensitivity of 100% and specificity of 90%. The skewness and kurtosis of the LBP computed from the enhanced green channel of tumorous and non-tumorous frames differ significantly (p « 0.05) with a p-value of 2.2 × 10−16. The proposed method is helpful to reduce the time spent by the doctors for reviewing WCE.",
     "keywords": ["Kurtosis", "Local binary pattern", "Receiver Operating Characteristic curve", "Small bowel tumor", "Skewness", "Wireless capsule endoscopy"]},
    {"article name": "Modeling the 2D space of emotions based on the poincare plot of heart rate variability signal",
     "doi": "https://doi.org/10.1016/j.bbe.2018.07.001",
     "publication date": "01-2018",
     "abstract": "Emotions mean accepting, understanding, and recognizing something with one's senses. The physiological signals generated from the internal organs of the body can objectively and realistically reflect changes in real-time human emotions and monitor the state of the body. In this study, the two-dimensional space-based emotion model was introduced on the basis of Poincare's two-dimensional plot of the signal of heart rate variability. Four main colors of psychology, blue, red, green, and yellow were used as a stimulant of emotion, and the ECG signals from 70 female students were recorded. Using extracted features of Poincare plot and heart rate asymmetry, two tree based models estimated the levels of arousal and valence with 0.05 mean square errors, determined an appropriate estimation of these two parameters of emotion. In the next stage of the study, four different emotions mean pleasure, anger, joy, and sadness, were classified using IF-THEN rules with the accuracy of 95.71%. The results show the color red is associated with more excitement and anger, while green has small anxiety. So, this system provides a measure for numerical comparison of mental states and makes it possible to model emotions for interacting with the computer and control mental states independently of the pharmaceutical methods.",
     "keywords": ["HRV heart rate variability", "heart rate variability", "HRA heart rate asymmetry", "heart rate asymmetry", "ECG electrocardiogram", "electrocardiogram", "AV Plane arousal \u2013 valence plane", "arousal \u2013 valence plane", "SAM self-assessment manikin", "self-assessment manikin", "MSE mean square error", "mean square error", "ANS autonomic nervous system", "autonomic nervous system", "ADM affective dimensional model", "affective dimensional model", "Heart rate variability", "Arousal", "Valence", "Emotion recognition", "Colors", "Heart rate asymmetry", "Poincare plot", "Regression tree"]},
    {"article name": "Eye and EEG activity markers for visual comfort level of images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.001",
     "publication date": "01-2018",
     "abstract": "Depth perception by binocular cues is based on the matching of image features from one retina with corresponding elements from the second retina. However, high disparities are related to the higher visual discomfort levels and may cause the eye fatigue during extended stereoscopic perception time. The goal of the investigation was to find a set of measurable features for stereoscopic image visual comfort level prediction. The investigation involved gaze, pupillometric and EEG data from 28 subjects who evaluated visual comfort level of 120 stereoscopic images. Six different time frame windows were used to analyze four measured features: the number of focus points; the dynamics of pupil size; disparity level at the focus points; the activity of EEG bands at the frontal lobe. A significant difference was found in all investigated stereoscopic image groups. 2-s and 5-s pre-DPI window showed best results for the selected feature sets. The higher disparity at the focus points, lower number of focus points are related to the lower levels of visual comfort. However, features such as the number of focus points, the pupil size and the disparity level for the images with lowest visual comfort scores showed similar results to the images scored as “comfortable” or “very comfortable”.",
     "keywords": ["04-12", "10-44", "Eye tracking", "Visual comfort", "Electroencephalogram"]},
    {"article name": "Predicting the success of wart treatment methods using decision tree based fuzzy informative images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.007",
     "publication date": "01-2018",
     "abstract": "Warts are small, rough, benign tumours caused by human papillomavirus (HPV). A challenge is predicting the success of wart treatment methods because success may vary depending on the patient and the features of disease. Recently, a machine learning based expert prediction system and related prediction rules were proposed. However, the success of this system is not satisfactory and should be improved. Furthermore, medical experts find it difficult to interpret the suggested rules of this system. The decision tree-based method was accordingly used in this study to determine the rules of predicting the success of wart treatment methods. According to findings, the success rate varied from 90 to 95% according to the treatment method; these rates are higher than previously reported. Furthermore, the decision tree rules that were determined can be transformed into images to visually interpret the success rates of treatment methods as a function of patient age and the time elapsed since disease appearance. This study provides a method for simple and more accurate interpretation of rules for medical experts. The success of treatment methods is now predictable as a percentage.",
     "keywords": ["Wart", "Decision Trees", "Cryotherapy", "Immunotherapy", "Common", "Plantar"]},
    {"article name": "Continuous blood glucose level prediction of Type 1 Diabetes based on Artificial Neural Network",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.005",
     "publication date": "01-2018",
     "abstract": "Recent technological advancements in diabetes technologies, such as Continuous Glucose Monitoring (CGM) systems, provide reliable sources to blood glucose data. Following its development, a new challenging area in the field of artificial intelligence has been opened and an accurate prediction method of blood glucose levels has been targeted by scientific researchers. This article proposes a new method based on Artificial Neural Networks (ANN) for blood glucose level prediction of Type 1 Diabetes (T1D) using only CGM data as inputs. To show the efficiency of our method and to validate our ANN, real CGM data of 13 patients were investigated. The accuracy of the strategy is discussed based on some statistical criteria such as the Root Mean Square Error (RMSE) and the Mean Absolute Percentage Error (MAPE). The obtained averages of RMSE are 6.43 mg/dL, 7.45 mg/dL, 8.13 mg/dL and 9.03 mg/dL for Prediction Horizon (PH) respectively 15 min, 30 min, 45 min and 60 min and the average of MAPE was 3.87% for PH = 15 min, knowing that the smaller is the RMSE and MAPE, the more accurate is the prediction. Experimental results show that the proposed ANN is accurate, adaptive, and very encouraging for a clinical implementation. Furthermore, while other studies have only focused on the prediction accuracy of blood glucose, this work aims to improve the quality of life of T1D patients by using only CGM data as inputs and by limiting human intervention.",
     "keywords": ["Artificial Neural Networks (ANN)", "Type 1 Diabetes (T1D)", "Continuous Glucose Monitoring (CGM)", "Prediction Horizon (PH)", "Time series forecasting"]},
    {"article name": "A miniature and low-cost glucose measurement system",
     "doi": "https://doi.org/10.1016/j.bbe.2018.07.004",
     "publication date": "01-2018",
     "abstract": "One of the bottlenecks in widespread adoption of biosensors is the large and sophisticated bioanalytical system that is required to perform signal transduction and analysis. A miniaturized bioanalytical system facilitates biosensing techniques that are portable, easy to handle and inexpensive for fast and reliable measurements of biochemical species. Thus, downscaling the bioanalytical system has become a highly active research area, significantly assisted by recent advances in the microelectronics technology. In this work, a miniaturized system is designed and implemented for amperometric detection, and subsequently tested with a glucose biosensor based on the one-step approach utilizing water soluble poly(o-aminophenol). Several experiments are conducted to assess the viability of this system including calibration, interference and application tests. The results are compared with the previously published work performed using the same biosensor tested with a commercial potentiostat in order to verify the applicability of the designed system.",
     "keywords": ["Glucose biosensor", "Measurement", "Lab-on-a-chip", "Portable", "Potentiostat", "Amperometry"]},
    {"article name": "Automated fuzzy optic disc detection algorithm using branching of vessels and color properties in fundus images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.003",
     "publication date": "01-2018",
     "abstract": "Optic disc (OD) detection is a basic procedure for the image processing algorithms which intend to diagnose and track retinal disorders. In this study, a new OD localization approach is proposed, based on color and shape properties of OD as well as the convergence point of the main vessels. This study is comprised of two successive fundamental steps. At the first step, an algorithm finding the approximate convergent point of the vessels is used in order to roughly localize OD. At the second step, three new features are suggested and a fuzzy logic controller (FLC) whose input membership functions are designed based on these features is proposed. The proposed method is applied to the DRIVE, STARE, DIARETDB0 and DIRETDB1 datasets and the obtained results validate the improvement in the performance by attaining success rate of 100%, 91,35%, 90% and 100% respectively and detecting OD centers and contours precisely in a reasonable execution time.",
     "keywords": ["Optic disc detection", "Fuzzy logic controller", "Vessel convergence", "Fundus image", "Feature extraction"]},
    {"article name": "Design and miniaturization of dual band implantable antennas",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.008",
     "publication date": "01-2018",
     "abstract": "Two types of miniaturized dual band implantable antennas are designed and presented, one of a meander type and the other is the so called comb antenna. In medical applications the electromagnetic characteristic changes of tissue in different situations and the corresponding resonant frequency shifts, should not disturb the data transmission. The objective is to design dual band antennas in 400 MHz and 2.4 GHz with suitable bandwidths and small sizes. The meander type antenna was fabricated and its S parameters were measured using an equivalent liquid phantom of skin, fat and muscle which included propanol, butanol, purified water and salt. The experimental results are shown and compared.",
     "keywords": ["Implantable antenna", "Miniaturization", "Bandwidths", "Dual band antennas"]},
    {"article name": "Fast statistical model-based classification of epileptic EEG signals",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.002",
     "publication date": "01-2018",
     "abstract": "This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4 s, performing similarly to the best approaches from the literature.",
     "keywords": ["Generalized Gaussian distribution", "Wavelet filter banks", "EEG", "Epilepsy", "Leave-one-out cross-validation", "Linear classifier"]},
    {"article name": "Use of features from RR-time series and EEG signals for automated classification of sleep stages in deep neural network framework",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.005",
     "publication date": "01-2018",
     "abstract": "Sleep is a physiological activity and human body restores itself from various diseases during sleep. It is necessary to get sufficient amount of sleep to have sound physiological and mental health. Nowadays, due to our present hectic lifestyle, the amount of sound sleep is reduced. It is very difficult to decipher the various stages of sleep manually. Hence, an automated system may be useful to detect the different stages of sleep. This paper presents a novel method for the classification of sleep stages based on RR-time series and electroencephalogram (EEG) signal. The method uses iterative filtering (IF) based multiresolution analysis approach for the decomposition of RR-time series into intrinsic mode functions (IMFs). The delta (δ), theta (θ), alpha (α), beta (β) and gamma (γ) waves are evaluated from EEG signal using band-pass filtering. The recurrence quantification analysis (RQA) and dispersion entropy (DE) based features are evaluated from the IMFs of RR-time series. The dispersion entropy and the variance features are evaluated from the different bands of EEG signal. The RR-time series features and the EEG features coupled with the deep neural network (DNN) are used for the classification of sleep stages. The simulation results demonstrate that our proposed method has achieved an average accuracy of 85.51%, 94.03% and 95.71% for the classification of ‘sleep vs wake’, ‘light sleep vs deep sleep’ and ‘rapid eye movement (REM) vs non-rapid eye movement (NREM)’ sleep stages.",
     "keywords": ["Sleep stages", "RR-time series", "Electroencephalography", "Dispersion entropy", "Deep neural network", "Stacked autoencoders"]},
    {"article name": "RASIT: Region shrinking based Accurate Segmentation of Inflammatory areas from Thermograms",
     "doi": "https://doi.org/10.1016/j.bbe.2018.07.002",
     "publication date": "01-2018",
     "abstract": "Effective segmentation of thermal images reflecting the inflamed region in human body to assist medical diagnosis is a challenging task. In this paper we propose a method for thermal image segmentation, named as “Region shrinking based Accurate Segmentation of Inflammatory areas from Thermograms”, in short RASIT. The method comprising of four steps encompassing thermal image contextual electrostatic force extraction, intensity adjustment as applicable, automated generation of the weighted threshold, and segmentation of thermograms based on the computed threshold. The proposed method is operative devoid of the subjective and possibly questionable task of parameter selection clearly offering an edge over the state-of-the-art methods in terms of usage. The efficacy of our proposed technique is shown by experimenting on abnormal thermograms taken from two datasets: one is newly created knee arthritis thermogram dataset and another is online available Database of Mastology Research (DMR) of breast thermograms. The averages on correct detection rates obtained by the proposed method for both the knee and breast thermograms are 98.2% and 96.98% respectively with favorable inference on basis of Wilcoxon's test. Application of the proposed method minimizes the complexity of parameter selection, time complexity of execution and amount of under segmentation compared to existing state-of-the-art methods of thermogram segmentation.",
     "keywords": ["Thermal imaging", "Arthritis", "Medical diagnosis", "Image segmentation", "RASIT"]},
    {"article name": "Extracting tumor in MR brain and breast image with Kapur’s entropy based Cuckoo Search Optimization and morphological reconstruction filters",
     "doi": "https://doi.org/10.1016/j.bbe.2018.07.005",
     "publication date": "01-2018",
     "abstract": "Magnetic Resonance Imaging (MRI) scanners are used to determine the presence of tumors in human bodies. In clinical oncology, algorithms are heavily used to analyze and identify the tumor region in the slice images produced by the MRI scanners. This article presents an unique algorithm which is developed based on Kapur’s Entropy-based Cuckoo Search Optimization and Morphological Reconstruction Filters. The former is used to locate and segment the boundary of tumors, while the later to remove unwanted pixels in the slice images. The proposed method yields 97% accuracy in the identification of the exact topographical location of tumor region. It requires less computational time (about 3 milliseconds, on average) for processing. Thus the proposed method can help radiologists quickly detect the exact topographical location of tumor regions even when there are severe intensity variations and poor boundaries. The method fares well in terms also of other standard comparison metrics like entropy, eccentricity, Jaccard Index, Hausdorff distance, MSE, PSNR, precision, recall and accuracy, when compared to the existing methods including Fuzzy C Means clustering and PSO. Above all, the algorithm developed can detect the tumor regions in the MR images of both brain and breast. The method is validated using various types of MR images (T1, T2 for MRI brain, and T1 post contrast and post processed images for breast) available in the online datasets of BRATS, RIDER and Harvard.",
     "keywords": ["Image segmentation", "Kapur\u2019s entropy", "Cuckoo Search Optimization", "Morphological reconstruction filters", "Performance measures"]},
    {"article name": "Early detection of sudden cardiac death using nonlinear analysis of heart rate variability",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.003",
     "publication date": "01-2018",
     "abstract": "Sudden cardiac death (SCD) is one of the most widespread reasons for death around the world. A precise and early prediction of SCD can improve the chance of survival by administering cardiopulmonary resuscitation (CPR). Hence, there is a vital need for an SCD prediction system.In this work, a novel and efficient algorithm for automated detection of SCD six minutes before its onset is proposed. This algorithm uses features based on the nonlinear modeling of heart rate variability (HRV). In fact, after the extraction of the HRV signals, increment entropy and recurrence quantification analysis-based features are extracted. The one-way ANOVA is applied for the dimension reduction of feature space—this results in lower computational cost. Finally, the distinguishing features are fed to classifiers such as the decision tree, K-nearest neighbor, naive Bayes, and the support vector machine.By using the decision tree classifier we have achieved SCD detection six minutes before its onset with an accuracy, specificity, and sensitivity of 95%. These results demonstrate the superiority of the presented algorithm compared to the existing ones in performance.This study shows that a combination of features based on the nonlinear modeling of HRV, such as laminarity (based on recurrence quantification analysis), and increment entropy leads to early detection of SCD. Choosing the decision tree improves the performance of the algorithm. The results could help in the development of a tool that would allow the detection of cardiac arrest six minutes before its onset.",
     "keywords": ["Sudden cardiac death", "Recurrence quantification analysis", "Increment entropy", "Heart rate variability"]},
    {"article name": "Fuzzy genetic-based noise removal filter for digital panoramic X-ray images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.005",
     "publication date": "01-2018",
     "abstract": "This paper proposed a novel fuzzy genetic-based noise removal filter and surveyed the gain of popular filters for noise removal in the digital orthopantomography (OPG) images. The proposed filter is a non-invasive technique for attaining sub-clinical information from the areas of interest in each tooth, both jaws and maxillofacial.The proposed Poisson removal filter combines 4th-order partial differential equations (PDE), total variation (TV) and Bayes shrink threshold accompanied by fuzzy genetic algorithm (FGA) and the exact unbiased inverse of generalized Anscombe transformation (EUIGAT). Experiments were performed in order to show the effect of noise removal filters on 110 simulated, 106 phantom and 104 panoramic radiographic images for subjects (aged 30–60 years old, 50 males and 54 females). Various noises degraded filters and Canny edge detection was performed separately in three kinds of images. The program measured mean square error (MSE), peak signal to noise ratio (PSNR), image quality index (IQI), structural similarity index metric (SSIM) and figure of merit (FOM).The results verify that the proposed filter enhances physicians’ and dentists’ skill of diagnosing normal and pathological events in the teeth, jaws, temporomandibular joint (TMJ) regions and changeable anatomical panoramic landmarks related to osteoporosis progress in the mandible bone using noise removal and improving images quality. Experimental results show the superiority of this filter over other noise removal filters.",
     "keywords": ["Orthopantomography images", "Genetic algorithm", "Poisson noise", "Anscombe transformation"]},
    {"article name": "Towards in-vivo assessment of fluorescence lifetime: imaging using time-gated intensified CCD camera",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.006",
     "publication date": "01-2018",
     "abstract": "A novel technique for imaging of a small animal with application of time-gated intensified CCD camera was proposed. The time-resolved method based on emission of picosecond light pulses and detection of the light penetrating in tissues was applied. In this technique, the fluorescence photons, excited in the dye circulating in the tissue, that diffusely penetrate in the optically turbid medium are detected. The data acquired during measurements carried out on a rat was analyzed in order to estimate fluorescence lifetime which depends strongly on the environment in which the dye is distributed. In the lifetime estimation a special emphasis was put on compensation of influence of the instrumental response function of the setup on the measured quantity. The proposed optical system was validated in series of phantom experiments, in which estimates of fluorescence lifetime of inclusions containing indocyanine green (ICG) were obtained. ICG is a dye revealing florescence properties in near-infrared wavelength region. Images of the estimate of fluorescence lifetime of the ICG accumulated in tissues of a rat were successfully acquired around six circular spots of illumination of the diameter of 6 mm. Larger lifetime values were observed in lung/heart region of the animal. Aspect of sampling rate of the fluorescence lifetime images optimization was finally discussed.",
     "keywords": ["Time-resolved imaging", "Fluorescence lifetime", "Small laboratory animals", "Time-gated CCD camera"]},
    {"article name": "A hybrid gene selection method for microarray recognition",
     "doi": "https://doi.org/10.1016/j.bbe.2018.08.004",
     "publication date": "01-2018",
     "abstract": "DNA microarray data is expected to be a great help in the development of efficient diagnosis and tumor classification. However, due to the small number of instances compared to a large number of genes, many of the computational learning methods encounter difficulties to select the low subgroups. In order to select significant genes from the high dimensional data for tumor classification, nowadays, several researchers are exploring microarray data using various gene selection methods. However, there is no agreement between existing gene selection techniques that produce the relevant gene subsets by which it improves the classification accuracy. This motivates us to invent a new hybrid gene selection method which helps to eliminate the misleading genes and classify a disease correctly in less computational time. The proposed method composes of two-stage, in the first stage, EGS method using multi-layer approach and f-score approach is applied to filter the noisy and redundant genes from the dataset. In the second stage, adaptive genetic algorithm (AGA) work as a wrapper to identify significant genes subsets from the reduced datasets produced by EGS that can contribute to detect cancer or tumor. AGA algorithm uses the support vector machine (SVM) and Naïve Bayes (NB) classifier as a fitness function to select the highly discriminating genes and to maximize the classification accuracy. The experimental results show that the proposed framework provides additional support to a significant reduction of cardinality and outperforms the state-of-art gene selection methods regarding accuracy and an optimal number of genes.",
     "keywords": ["Accuracy", "Ensemble", "Adaptive genetic algorithm", "Gene selection", "Support vector machine"]},
    {"article name": "Statistical methods for constructing gestational age-related charts for fetal size and pregnancy dating using longitudinal data",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.001",
     "publication date": "01-2018",
     "abstract": "The assessment of fetal size and the accurate estimation of gestational age are of crucial importance for proper pregnancy management. The information is almost exclusively based on ultrasound measurements of fetal biometric parameters and the means for evaluating these measurements are age-related reference charts (centile charts) allowing interpretation of obtained fetal measurement in comparison with the expected average measurement in the reference population. The construction of such reference charts requires an appropriate statistical methodology. The most frequent method for the construction of fetal reference charts from cross-sectional data is the parametric approach with fractional polynomials regression functions for the mean and standard deviation of each fetal measurement. This article suggests how this method can be extended to longitudinal data using fractional polynomials in linear mixed effect regression. The presented approach includes maximum likelihood estimation for fitting first- and second-order fractional polynomial models, and multimodel inference using Akaike's information criterion and related tools as a suitable strategy for model selection. Finally, an example of the suggested approach is presented.",
     "keywords": ["Fetal size", "Fetal reference charts", "Longitudinal data", "Mixed effects models", "Regression quantiles", "Multimodel inference"]},
    {"article name": "Extraction of fuzzy rules at different concept levels related to image features of mammography for diagnosis of breast cancer",
     "doi": "https://doi.org/10.1016/j.bbe.2018.09.002",
     "publication date": "01-2018",
     "abstract": "Mammography is an inexpensive and non-invasive method through which one can diagnose breast cancer in its early stages. As these images need interpretation by a radiologist, this may develop some problems due to fatigue, repetition, and need for a great deal of attention to details and other factors. Thus, a method capable of diagnosing breast cancer should be employed to help physicians in this regard.In this paper, The mini Mammographic Image Analysis Society (mini-MIAS) database of mammograms is used. The aim is to distinguish between normal and abnormal classes. In the preprocessing stage, noise removal, removal of labels of images, heightening the contrast, and ROI segmentation are performed, and then compactness, entropy, mean, and smoothness are extracted from the images. In addition to classification, we have come to a new approach in order to create a complete knowledge base, which then we use this knowledge base for classification. We have a comprehensive knowledge base which covers all the conceptual levels.The extracted features are referred to as fuzzy classifiers through the look-up table method. And, for evaluation of the results, the 10-fold method is used. Discretization operations are performed on training data across 2, 3, and 4 levels to develop concept hierarchy. Concept hierarchies reduce the data by replacing low-level concepts with higher-level concepts and the outcome is more meaningful and easier to interpret. Eventually, Bagging algorithm is used for finding out the majority vote and the final result of the discretization levels. The obtained accuracy is 89.37 ± 6.62.",
     "keywords": ["Mammography", "Breast cancer", "Feature extraction", "Fuzzy rule extraction", "Look-up table method", "Bagging algorithm"]},
    {"article name": "Peripheral blood smear analysis using image processing approach for diagnostic purposes: A review",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.002",
     "publication date": "01-2018",
     "abstract": "Peripheral blood smear analysis is a common practice to evaluate health status of a person. Many disorders such as malaria, anemia, leukemia, thrombocytopenia, sickle cell anemia etc., can be diagnosed by evaluating blood cells. Many groups have reported methods to automate blood smear analysis for detection of specific disorders for diagnostic purposes. In this paper, we have summarized the methods used to analyze peripheral blood smears using image processing techniques. We have categorized these methods into three groups based on approaches such as WBC analysis, RBC analysis and platelet analysis. We conclude that there is a need for a method of automation to match with human evaluation process and rule out any abnormality present in the blood smear. It is desirable for studies on automation of peripheral blood smear analysis to focus on development of robust method to handle illumination and color shade variations. Also, it is desirable to design a method which could collect all the abnormal regions from all views of a specimen to limit the manual evaluation to those regions making it more feasible for telemedicine applications.",
     "keywords": ["Peripheral blood smear", "Image analysis", "Computer aided diagnosis", "Malaria diagnosis", "Leukemia diagnosis"]},
    {"article name": "Enhancement of graphene quantum dots based applications via optimum physical chemistry: A review",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.006",
     "publication date": "01-2018",
     "abstract": "Graphene quantum dots (GQDs) is a promising new substance from the carbon material family that has been attracting researchers of many fields, such as biomedical sensors, medical imaging, polymer science, solar cells, light emitting diodes, and photoelectrons. Its unique electrical and mechanical properties could encourage its usage due to its low cost, high surface area, safety, stable luminescence, excellent biocompatibility, suitable conductivity, and low toxicity. The dispersibility of GQDs in common solvents depends on hydrophobicity/hydrophilicity, which is particularly important toward its homogeneous incorporation into various polymer layers. This review discusses the global demand for GQDs and explore the main factors encouraging its utilization in various devices. Moreover, different synthesis methods of GQDs were compared, and recent investigation on GQDs based composite applications are analyzed. Finally, the future of GQDs is detailed, focusing on the gaps in its role in future technology.",
     "keywords": ["Synthesizing GQDs", "Composites", "Electrochemical applications", "Functionalization"]},
    {"article name": "A fast and robust level set motion-assisted deformable registration method for volumetric CT guided lung intervention",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.002",
     "publication date": "01-2018",
     "abstract": "This paper describes the accurate deformable registration method for image-guided lung interventions, including lung nodule biopsy and radiofrequency ablation of lung tumours. A level set motion assisted deformable registration method for computed tomography (CT) images was proposed and its accuracy and speed were compared with those of other conventional methods. Fifteen 3D CT images obtained from lung biopsy patients were scanned. Each scan consisted of diagnostic and preoperative CT images. Each deformable registration method was initially evaluated with a landmark-based affine registration algorithm. Various deformable registration methods such as level set motion, demons, diffeomorphic demons, and b-spline were compared. Visual assessment by two expert thoracic radiologists using five scales showed an average visual score of 3.2 for level set motion deformable registration, whereas scores were below 3 for other deformable registration methods. In the qualitative assessment, the level set motion algorithm showed better results than those obtained with other deformable registration methods. A level set motion based deformable registration algorithm was effective for registering diagnostic and preoperative volumetric CT images for image-guided lung intervention.",
     "keywords": ["Medical image processing", "Image registration", "Level-set method"]},
    {"article name": "Automatic identifying of maternal ECG source when applying ICA in fetal ECG extraction",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.003",
     "publication date": "01-2018",
     "abstract": "Independent component analysis (ICA) is usually used as a preliminary step for maternal electrocardiogram (ECG) QRS detection in fetal ECG extraction. When applying ICA to do this, a troublesome problem arises from how to automatically identify the separated maternal ECG component. In this paper we proposed a method called PRCH (short for Peak to peak entropy, R-R interval entropy, Correlation coefficient and Heart rate) for the automatic identifying. In the method, we defined four kinds of features, including amplitude, instantaneous heart rate, morphology and average heart rate, to characterize a signal, and determined some decision parameters through machine learning. Experiments and comparison with other three existed methods were given. Through taking metric F1 for evaluation, it showed that the proposed PRCH method has the highest identifying accuracy and generalization capability.",
     "keywords": ["Fetal ECG extraction", "Independent component analysis (ICA)", "Automatic identification", "ECG features"]},
    {"article name": "Improvement in the diagnosis of melanoma and dysplastic lesions by introducing ABCD-PDT features and a hybrid classifier",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.005",
     "publication date": "01-2018",
     "abstract": "Melanoma and dysplastic lesions are pigmented skin lesions whose accurate classification is of great importance. In this paper, we have proposed a computer-aided diagnosis (CAD) system to improve the diagnostic ability of the conventional ABCD (asymmetry, border irregularity, color, and diameter) analysis. We introduced features extracted by local analysis of range of intensity variations within the lesion that describe pigment distribution and texture (PDT) features. The statistical distribution of pigmentation at a specified direction and distance was analyzed through grey level co-occurrence matrix (GLCM). Some other quantitative features were also extracted by computing neighborhood grey-tone difference matrix. These were correlated with human perception of texture. A hybrid classifier was designed for classification of melanoma, dysplastic, and benign lesions. Log-linearized Gaussian mixture neural network (LLGMNN), K-nearest neighborhood (KNN), linear discriminant analysis (LDA), and support vector machine (SVM) construct the hybrid classifier. The proposed system was evaluated on a set of 792 dermoscopy images and the diagnostic accuracies of 96.8%, 97.3%, and 98.8% for melanoma, dysplastic, and benign lesions were achieved, respectively. The results indicate that PDT features are promising features which in combination with the conventional ABCD features are capable of enhancing the classification performance of the pigmented skin lesions.",
     "keywords": ["Computer-aided diagnosis", "Dysplastic lesion", "Hybrid classifier", "Melanoma", "Pigment distribution", "Texture features"]},
    {"article name": "Temperature controlled dual hypoxic chamber design for in vitro ischemia experiments",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.010",
     "publication date": "01-2018",
     "abstract": "In vitro ischemia models are designed to study various aspects of hypo-perfusion, focusing on the consequences of acute events under body temperature. Cold ischemia is less investigated even though the beneficial effects of cooling is expected. The aim of the present work was to develop a device modeling cold and warm ischemia in vitro. Oxygen-glucose deprivation was applied with continuous nitrogen flow and glucose-free cell culture media to mimic ischemia. The temperature in both chambers were independently set between 4 and 37 °C. Samples were placed inside for the ischemic period, followed by a reperfusion stage under standard cell culture conditions. We tested rat calvaria bone pieces undergoing 1, 7, 12 and 24 h of ischemia at 4 and 37 °C. After 24 h of reperfusion, cell number was measured with a tetrazolium cell viability assay. One hour of warm ischemia paradoxically increased the post-reperfusion cell count, while cold-ischemia had an opposite effect. After 7 h of warm ischemia the cells were already unable to recover, while under cold ischemia 60% of the cells were still functioning. After 12 h of cold ischemia 50% of the cells were still be able to recover, while at 24 h even the low temperature was unable to keep the cells alive. The markedly different effect of warm and cold ischemia suggests that this newly designed system is capable of reliable and reproducible modeling of ischemic conditions. Moreover, it also enables deeper investigations in the pathophysiology of cold ischemia at cellular and tissue level.",
     "keywords": ["Cold ischemia model", "Reperfusion", "Hypoxia", "Bone"]},
    {"article name": "A hybrid approach for the delineation of brain lesion from CT images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.003",
     "publication date": "01-2018",
     "abstract": "Brain lesion segmentation from radiological images is the most important task in accurate diagnosis of patients. This paper presents a hybrid approach for the segmentation of brain lesion from computed tomography (CT) images based on the combination of fuzzy clustering using hyper tangent function as the robust kernel and distance regularized level set evolution (DRLSE) function as the edge based active contour method. Kernel based fuzzy clustering method divides the image into different regions. These regions can be used to find region of interest by using DRLSE algorithm to generate the optimal region boundary. The proposed method results in smooth boundary of the required regions with high accuracy of segmentation. In this paper, results are compared with standard fuzzy c-means (FCM) clustering, spatial FCM, robust kernel based fuzzy clustering (RFCM) and DRLSE algorithms. The performance of the proposed method is evaluated on CT scan images of hemorrhagic lesion, which shows that our method can segment brain lesion more accurately than the other conventional methods.",
     "keywords": ["Brain lesion", "Segmentation", "Fuzzy c-means", "Kernel function", "Level set", "Distance regularized level set evolution (DRLSE)"]},
    {"article name": "Generalized Stockwell transform and SVD-based epileptic seizure detection in EEG using random forest",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.007",
     "publication date": "01-2018",
     "abstract": "Visual inspection of electroencephalogram (EEG) records by neurologist is the main diagnostic method of epilepsy but it is particularly time-consuming and expensive. Hence, it is of great significance to develop automatic seizure detection technique.In this work, a seizure detection approach, synthesizing generalized Stockwell transform (GST), singular value decomposition (SVD) and random forest, was proposed. Utilizing GST, the raw EEG was transformed into a time–frequency matrix, then the global and local singular values were extracted by SVD from the holistic and partitioned matrices of GST, respectively. Subsequently, four local parameters were calculated from each vector of local singular values. Finally, the global singular value vectors and local parameters were respectively fed into two random forest classifiers for classification, and the final category of a testing EEG was voted based on sub-labels obtained from the trained classifiers.Four most common but challenging classification tasks of Bonn EEG database were investigated. The highest accuracies of 99.12%, 99.63%, 99.03% and 98.62% were achieved using our presented technique, respectively.Our proposed technique is comparable or superior to other up-to-date methods. The presented method is promising and able to handle with kinds of epileptic seizure detection tasks with satisfactory accuracy.",
     "keywords": ["Electroencephalogram (EEG)", "Automatic seizure detection", "Generalized Stockwell transform (GST)", "Singular value decomposition (SVD)", "Random forest"]},
    {"article name": "Experimental investigation of particle size distribution and morphology of alumina-yttria-ceria-zirconia powders obtained via sol–gel route",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.010",
     "publication date": "01-2018",
     "abstract": "Oxide-doped zirconia is currently commonly used ceramics in dental prosthetics. However, its use raises a lot of controversy. This is related to the stability of the zirconia metastable phases in the human mouth environment and it sensitivity for the so-called low-temperature degradation. A key way to avoid this type of negative phenomena is doping ZrO2 with selected metal oxides and choosing appropriate methods for the synthesis of ceramic powders.The aim of this paper is to present investigations of modification and to analyse the influence of chemical composition and volume of parent-solvent for the morphology and thermal properties of ceramic powders prepared in a ZrO2-CeO2-Y2O3-Al2O3 system.The powders were obtained by using the sol–gel method in an inert gas atmosphere and ambient temperature using zirconium n-propoxide for this purpose. Morphology was examined by using scanning electron microscopy (SEM) and particle size distribution (PSD); thermal properties was evaluated using thermogravimetric analysis (TGA/DTA/DTG), and chemical composition was confirmed by using electron probe microanalysis (EPMA)Depending from the volume of the CeO2 precursor solution of and regardless of the volume of the second oxide precursor, was observed difference in morphology of the obtained powders. Overall trend is related to reduce the size of agglomerates with an increase in the volume of the precursor of CeO2.The influence of various chemical compositions for morphology and thermal properties is negligible. In contrast, a clear correlation is observed between the volume of parent alcohol for both morphology and thermal properties. Use of sol–gel method to further research in view of these results appears to be appropriate.",
     "keywords": ["Zirconia", "Prosthetic dentistry", "Sol\u2013gel", "Thermal analysis", "Morphology"]},
    {"article name": "Geometric verification of the validity of Finite Element Method analysis of Abdominal Aortic Aneurysms based on Magnetic Resonance Imaging",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.001",
     "publication date": "01-2018",
     "abstract": "The currently used criterion of maximum transverse diameter for the Abdominal Aortic Aneurysm treatment has some limitations. Attempts to create individualized, therapeutic strategies are being conducted, including biomechanical assessment of rupture risk of an aneurysm based on the Finite Element Analysis of the geometric models.The usual approach is to use the results of the computed tomography imaging to build a three-dimensional model of the aneurysm. The FEA is then performed and the resulting stress is analysed to estimate the risk of rupture. Although such an approach brings significant improvements over the traditional maximum diameter method, it is difficult to ensure the validity of the assumptions made.This paper presents a method to evaluate the correctness of such an approach. The emergence of gated Magnetic Resonance Imaging allows registering aneurysm in both the systolic and diastolic phase of cardiac cycle. The corresponding geometric models are built and the results of the FEA applied to the diastolic model are compared with the actual deformation of the aneurysm observed in the patient's body. Thus, it is possible to verify whether the individualized diagnostic approach applied to a specific patient was correct.The geometry of the reference and the analysed models were compared using the Differential Surface Area Method. The average geometry error equals 1.65%. In the best case the error amounts to 1.04%, in the worst to 3.00%.The obtained results provide evidence that the Finite Element Analysis is a reliable method and can be potentially used for individualized diagnostics and treatment.",
     "keywords": ["FE simulation", "Abdominal aortic aneurysm", "Patient-specific modeling"]},
    {"article name": "A robust pre-processing of BeadChip microarray images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.005",
     "publication date": "01-2018",
     "abstract": "Microarray images commonly used in gene expression studies are heavily contaminated by noise and/or outlying values (outliers). Unfortunately, standard methodology for the analysis of Illumina BeadChip microarray images turns out to be too vulnerable to data contamination by outliers. In this paper, an alternative approach to low-level pre-processing of images obtained by the BeadChip microarray technology is proposed. The novel approach robustifies the standard methodology in a complex way and thus ensures a sufficient robustness (resistance) to outliers. A gene expression data set from a cardiovascular genetic study is analyzed and the performance of the novel robust approach is compared with the standard methodology. The robust approach is able to detect and delete a larger percentage of outliers. More importantly, gene expressions are estimated more precisely. As a consequence, also the performance of a subsequently performed classification task to two groups (patients vs. control persons) is improved over the cardiovascular gene expression data set. A further improvement was obtained when considering weighted gene expression values, where the weights correspond to a robust estimate of variability of the measurements for each individual gene transcript.",
     "keywords": ["Microarray", "Robust image analysis", "Noise", "Outlying measurements", "Background effect"]},
    {"article name": "Automated diagnosis of atrial fibrillation ECG signals using entropy features extracted from flexible analytic wavelet transform",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.004",
     "publication date": "01-2018",
     "abstract": "Atrial fibrillation (AF) is the most common type of sustained arrhythmia. The electrocardiogram (ECG) signals are widely used to diagnose the AF. Automated diagnosis of AF can aid the clinicians to make a more accurate diagnosis. Hence, in this work, we have proposed a decision support system for AF using a novel nonlinear approach based on flexible analytic wavelet transform (FAWT). First, we have extracted 1000 ECG samples from the long duration ECG signals. Then, log energy entropy (LEE), and permutation entropy (PEn) are computed from the sub-band signals obtained using FAWT. The LEE and PEn features are extracted from different frequency bands of FAWT. We have found that LEE features showed better classification results as compared to PEn. The LEE features obtained maximum accuracy, sensitivity, and specificity of 96.84%, 95.8%, and 97.6% respectively with random forest (RF) classifier. Our system can be deployed in hospitals to assist cardiac physicians in their diagnosis.",
     "keywords": ["AF", "ECG segment", "FAWT", "Entropy", "Classification"]},
    {"article name": "Virus–human protein–protein interaction prediction using Bayesian matrix factorization and projection techniques",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.006",
     "publication date": "01-2018",
     "abstract": "Pathogens infect host organisms by exploiting host cellular mechanisms and evading host defence mechanisms through molecular pathogen–host interactions (PHIs). Discovering new interactions between pathogen and human proteins is very crucial in understanding the infection mechanisms. By analysing interaction networks, the interactions responsible for infectious diseases can be detected and new drugs disabling these interactions can be delivered. In this paper, we propose a method based on Bayesian matrix factorization for predicting PHIs along with a projection-based technique and combine the results by employing an ensemble method. Furthermore, two features, target similarity and attacker similarity, are utilized for the first time in the literature for PHI prediction. The advantages of the proposed methods are two folds. Firstly, they relieve the need for negative samples which is significant since there is no available dataset providing negative samples for most of the pathogenic systems. Secondly, the experiments demonstrate that the proposed approach outperforms state-of-the-art methods; roughly 20% of top 50 predictions are among recently validated interactions. So, the search space for wet-lab experiments to obtain validated interactions can be considerably narrowed down from a huge number of possible interactions.",
     "keywords": ["Bioinformatics", "Protein\u2013protein interaction", "Pathogen host interaction", "Interaction prediction", "Kernelized projection"]},
    {"article name": "Multi-modal framework for automatic detection of diagnostically important regions in nonalcoholic fatty liver ultrasonic images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.008",
     "publication date": "01-2018",
     "abstract": "The severity of fat in ultrasonic liver images is quantified based on characteristics of three regions in the image namely diaphragm, periportal veins and texture of liver parenchyma. The characteristics of these regions vary with the severity of fat in the liver, and is subjected to low signal to noise ratio, low contrast, poorly defined organ boundaries, etc., hence locating these regions in ultrasound images is challenging task for the sonographers. Automated detection of these regions will help the sonographers to do accurate diagnosis in shorter time, and also acts as a fundamental step to develop automated diagnostic algorithms. In this paper, we propose a novel multi-modal framework for detecting diaphragm, periportal veins and texture of liver parenchyma in ultrasonic liver ultrasound images. Since the characteristics of these regions differ from each other, we propose a specific algorithm for detecting each region. Diaphragm and periportal veins are detected with the combination of Viola Jones and GIST descriptor based classifier, while homogeneous texture regions are detected with the combination of histogram features based classifier and connected components algorithm. The proposed algorithm when tested on 180 ultrasound liver images, detected the diaphragm, periportal veins and texture regions with an accuracy of 97%, 91% and 100% respectively.",
     "keywords": ["Steatosis", "Diaphragm", "Periportal veins", "Ultrasonic liver parenchyma texture", "Viola Jones", "GIST"]},
    {"article name": "Thermal modelling and screening method for skin pathologies using active thermography",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.009",
     "publication date": "01-2018",
     "abstract": "This paper presents a novel screening approach of human skin pathologies using Active IR Thermography. The inputs of the proposed algorithm are the values of the physical parameters of the skin. Parameters are estimated based on dynamic thermographic measurements of human skin and the developed thermal model of the tissue. The calculations were based on the inverse thermal modelling. Classification was done using Support Vector Machine, Linear Discriminant Analysis and k-Nearest Neighbours classifiers. As an example, one presented the results of screening for psoriasis.",
     "keywords": ["Bioheat transfer", "Inverse thermal problem", "Active dynamic thermography", "Biomedical imaging", "Medical screening", "Cold provocation"]},
    {"article name": "An improved feature based image fusion technique for enhancement of liver lesions",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.004",
     "publication date": "01-2018",
     "abstract": "This paper describes two methods for enhancement of edge and texture of medical images. In the first method optimal kernel size of range filter suitable for enhancement of liver and lesions is deduced. The results have been compared with conventional edge detection algorithms. In the second method the feasibility of feature based pixel wise image fusion for enhancing abdominal images is investigated. Among the different algorithms developed in the medical image fusion pixel level fusion is capable of retaining the maximum relevant information with better implementation and computational efficiency. Conventional image fusion includes multi-modal fusion and multi-resolution fusion. The present work attempts to fuse together, texture enhanced and edge enhanced images of the input image in order to obtain significant enhancement in the output image. The algorithm is tested in low contrast medical images. The result shows an improvement in contrast and sharpness of output image which will provide a basis for a better visual interpretation leading to more accurate diagnosis. Qualitative and quantitative performance evaluation is done by calculating information entropy, MSE, PSNR, SSIM and Tenengrad values.",
     "keywords": ["00-01", "99-00", "Range filter", "Optimal filter kernel", "Image enhancement", "Image fusion and gradient image"]},
    {"article name": "Control of speed and direction of electric wheelchair using seat pressure mapping",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.007",
     "publication date": "01-2018",
     "abstract": "An electric wheelchair controlled through seat pressure mapping was developed to accomplish hands-free operation. The seat pressure mapping resulting from a change in posture was measured using a pressure sensor array seated on the wheelchair in real time. The movements of the upper body were discriminated using template matching. The speed and direction can be controlled based on the similarities between the measured pressure distribution and five templates of neutral, forward, backward, left, and right movements. The developed interface was built into a commercial electric wheelchair. As the results of an experiment show, the proposed wheelchair can be controlled in any direction and velocity.",
     "keywords": ["Electric wheelchair", "Hands-free operation", "Seat pressure mapping", "Interface", "Template matching"]},
    {"article name": "Time–frequency analysis in infant cry classification using quadratic time frequency distributions",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.002",
     "publication date": "01-2018",
     "abstract": "This paper presents a new investigation of time–frequency (t–f) based signal processing approach using quadratic time–frequency distributions (QTFDs) namely spectrogram (SPEC), Wigner–Ville distribution (WVD), Smoothed–Wigner Ville distribution (SWVD), Choi–William distribution (CWD) and modified B-distribution (MBD) for classification of infant cry signals. t–f approaches have proved as an efficient approach for applications involving the non stationary signals. In feature extraction, a cluster of t–f based features were extracted by extending the time-domain and frequency-domain features to the joint t–f domain from the generated t–f representation. Conventional features such as mel-frequency cepstral coefficients (MFCCs) and linear prediction coefficients (LPCs) were also extracted in order to compare the effectiveness of the t–f methods. The efficacy of the extracted feature vectors was validated using probabilistic neural network (PNN) and general regression neural network (GRNN). The proposed methodology was implemented to classify different sets of binary classification problems of infant cry signals from different native. The best empirical result of above 90% was reported and revealed the good potential of t–f methods in the context of infant cry classification.",
     "keywords": ["Infant cry", "Time\u2013frequency analysis", "Quadratic time\u2013frequency distributions", "t\u2013f based feature extraction", "Classification"]},
    {"article name": "Bayesian HCS-based multi-SVNN: A classification approach for brain tumor segmentation and classification using Bayesian fuzzy clustering",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.001",
     "publication date": "01-2018",
     "abstract": "Brain tumor segmentation and classification is the interesting area for differentiating the tumerous and the non-tumerous cells in the brain and to classify the tumerous cells for identifying its level. The conventional methods lack the automatic classification and they consumed huge time and are ineffective in decision-making. To overcome the challenges faced by the conventional methods, this paper proposes the automatic method of classification using the Harmony-Crow Search (HCS) Optimization algorithm to train the multi-SVNN classifier. The brain tumor segmentation is performed using the Bayesian fuzzy clustering approach, whereas the tumor classification is done using the proposed HCS Optimization algorithm-based multi-SVNN classifier. The proposed method of classification determines the level of the brain tumor using the features of the segments generated based on Bayesian fuzzy clustering. The robust features are obtained using the information theoretic measures, scattering transform, and wavelet transform. The experimentation performed using the BRATS database conveys proves the effectiveness of the proposed method and the proposed HCS-based tumor segmentation and classification achieves the classification accuracy of 0.93 and outperforms the existing segmentation methods.",
     "keywords": ["MRI image", "Brain tumor classification", "Brain tumor segmentation", "Bayesian fuzzy clustering", "Support vector neural network"]},
    {"article name": "Object detection based on deep learning for urine sediment examination",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.004",
     "publication date": "01-2018",
     "abstract": "Urine sediment examination (USE) is an important topic in kidney disease analysis and it is often the prerequisite for subsequent diagnostic procedures. We propose DFPN(Feature Pyramid Network with DenseNet) method to overcome the problem of class confusion in the USE images that it is hard to be solved by baseline model which is the state-of-the-art object detection model FPN with RoIAlign pooling. We explored the importance of two parts of baseline model for the USE cell detection. First, adding attention module in the network head, and the class-specific attention module has improved mAP by 0.7 points with pre-trained ImageNet model and 1.4 points with pre-trained COCO model. Next, we introduced DenseNet to the baseline model(DFPN) for cell detection in USE, so that the input of the network's head own multiple levels of semantic information, compared to the baseline model only has high-level semantic information. DFPN achieves top result with a mAP of 86.9% on USE test set after balancing between the classification loss and bounding-box regression loss, which improve 5.6 points compared to baseline model, and especially erythrocyte's AP is greatly improved from 65.4% to 93.8%, indicating class confusion has been basically resolved. And we also explore the impacts of training schedule and pre-trained model. Our method is promising for the development of automated USE.",
     "keywords": ["Urine sediment examination", "Cell detection", "DenseNet", "Attention mechanism"]},
    {"article name": "Representation learning-based unsupervised domain adaptation for classification of breast cancer histopathology images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.04.008",
     "publication date": "01-2018",
     "abstract": "Breast cancer has high incidence rate compared to the other cancers among women. This disease leads to die if it does not diagnosis early. Fortunately, by means of modern imaging procedure such as MRI, mammography, thermography, etc., and computer systems, it is possible to diagnose all kind of breast cancers in a short time. One type of BC images is histology images. They are obtained from the entire cut-off texture by use of digital cameras and contain invaluable information to diagnose malignant and benign lesions. Recently by requesting to use the digital workflow in surgical pathology, the diagnosis based on whole slide microscopy image analysis has attracted the attention of many researchers in medical image processing. Computer aided diagnosis (CAD) systems are developed to help pathologist make a better decision. There are some weaknesses in histology images based CAD systems in compared with radiology images based CAD systems. As these images are collected in different laboratory stages and from different samples, they have different distributions leading to mismatch of training (source) domain and test (target) domain. On the other hand, there is the great similarity between images of benign tumors with those of malignant. So if these images are analyzed undiscriminating, this leads to decrease classifier performance and recognition rate. In this research, a new representation learning-based unsupervised domain adaptation method is proposed to overcome these problems. This method attempts to distinguish benign extracted feature vectors from those of malignant ones by learning a domain invariant space as much as possible. This method achieved the average classification rate of 88.5% on BreaKHis dataset and increased 5.1% classification rate compared with basic methods and 1.25% with state-of-art methods.",
     "keywords": ["Whole slide microscopy image analysis", "Computer aided diagnosis (CAD) systems", "Histopathological image", "Breast cancer diagnosis", "Domain adaptation", "Representation learning"]},
    {"article name": "Discriminant analysis of neural style representations for breast lesion classification in ultrasound",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.003",
     "publication date": "01-2018",
     "abstract": "Ultrasound imaging is widely used for breast lesion differentiation. In this paper we propose a neural transfer learning method for breast lesion classification in ultrasound. As reported in several papers, the content and the style of a particular image can be separated with a convolutional neural network. The style, coded by the Gram matrix, can be used to perform neural transfer of artistic style. In this paper we extract the neural style representations of malignant and benign breast lesions using the VGG19 neural network. Next, the Fisher discriminant analysis is used to separate those neural style representations and perform classification. The proposed approach achieves good classification performance (AUC of 0.847). Our method is compared with another transfer learning technique based on extracting pooling layer features (AUC of 0.826). Moreover, we apply the Fisher discriminant analysis to differentiate breast lesions using ultrasound images (AUC of 0.758). Additionally, we extract the eigenimages related to malignant and benign breast lesions and show that these eigenimages present features commonly associated with lesion type, such as contour attributes or shadowing. The proposed techniques may be useful for the researchers interested in ultrasound breast lesion characterization.",
     "keywords": ["Breast lesions classification", "Deep learning", "Discriminant analysis", "Transfer learning", "Ultrasound imaging"]},
    {"article name": "Automatic detection of tuberculosis bacilli from microscopic sputum smear images using deep learning methods",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.007",
     "publication date": "01-2018",
     "abstract": "An automatic method for the detection of Tuberculosis (TB) bacilli from microscopic sputum smear images is presented in this paper. According to WHO, TB is the ninth leading cause of death all over the world. There are various techniques to diagnose TB, of which conventional microscopic sputum smear examination is considered to be the gold standard. However, the aforementioned method of diagnosis is time intensive and error prone, even in experienced hands. The proposed method performs detection of TB, by image binarization and subsequent classification of detected regions using a convolutional neural network. We have evaluated our algorithm using a dataset of 22 sputum smear microscopic images with different backgrounds (high density and low-density images). Experimental results show that the proposed algorithm achieves 97.13% recall, 78.4% precision and 86.76% F-score for the TB detection. The proposed method automatically detects whether the sputum smear images is infected with TB or not. This method will aid clinicians to predict the disease accurately in a short span of time, thereby helping in improving the clinical outcome.",
     "keywords": ["Tuberculosis", "Sputum smear microscopy", "Automatic TB detection", "Convolutional neural network", "Image processing"]},
    {"article name": "EEG with a reduced number of electrodes: Where to detect and how to improve visually, auditory and somatosensory evoked potentials",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.001",
     "publication date": "01-2018",
     "abstract": "The measurement of evoked potentials has become a standard tool to test new hardware and software for electroencephalography (EEG). In this study, we investigate where to detect and how to improve visually, auditory and somatosensory evoked potentials with a reduced number of electrodes. We measured a total of 50 evoked potentials in healthy subjects, and we were able to detect visually, auditory and somatosensory evoked potentials with just three electrodes. We also investigated where to measure a combination of visually, auditory and somatosensory evoked potentials and found the best positions to be Oz, O1, O2, TP9 and TP10. In the second part of this study, we analyzed how the evoked potentials depend on the segmentation frequency selected to superpose EEG responses. We found that the detection of visually evoked potentials requires the segmentation frequency to match the stimulus frequency with an accuracy of at least 99.92 percent. The detection of auditory evoked potentials and somatosensory evoked potentials requires a matching of at least 99.95 percent. Therefore, a correct matching of the segmentation frequency with the stimulation frequency is the primary key to improving the quality of evoked potentials.",
     "keywords": ["Evoked potentials", "EEG", "VEP", "AEP", "SEP", "10\u201320 system"]},
    {"article name": "Estimation of severity level of non-proliferative diabetic retinopathy for clinical aid",
     "doi": "https://doi.org/10.1016/j.bbe.2018.05.006",
     "publication date": "01-2018",
     "abstract": "Diabetic retinopathy, a symptomless complication of diabetes, is one of the significant causes of vision impairment in the world. The early detection and diagnosis can reduce the occurrence of severe vision loss due to diabetic retinopathy. The diagnosis of diabetic retinopathy depends on the reliable detection and classification of bright and dark lesions present in retinal fundus images. Therefore, in this work, reliable segmentation of lesions has been performed using iterative clustering irrespective of associated heterogeneity, bright and faint edges. Afterwards, a computer-aided severity level detection method is proposed to aid ophthalmologists for appropriate treatment and effective planning in the diagnosis of non-proliferative diabetic retinopathy. This work has been performed on a composite database of 5048 retinal fundus images having varying attributes such as position, dimensions, shapes and color to make a reasonable comparison with state-of-the-art methods and to establish generalization capability of the proposed method. Experimental results on per-lesion basis show that the proposed method outperforms state-of-the-methods with an average sensitivity/specificity/accuracy of 96.41/96.57/94.96 and 95.19/96.24/96.50 for bright and dark lesions respectively on composite database. Individual per-image based class accuracies delivered by the proposed method: No DR-95.9%, MA-98.3%, HEM-98.4%, EXU-97.4% and CWS-97.9% demonstrate the clinical competence of the method. Major contribution of the proposed method is that it efficiently grades the severity level of diabetic retinopathy in spite of huge variations in retinal images of different databases. Additionally, the substantial combined performance of these experiments on clinical and open source benchmark databases support a strong candidature of the proposed method in the diagnosis of non-proliferative diabetic retinopathy.",
     "keywords": ["Non-proliferative diabetic retinopathy", "Severity level", "Retinal lesions", "Feature extraction", "Neural network classifier", "Retinal fundus images"]},
    {"article name": "Computer-aided diagnosis of clinically significant prostate cancer from MRI images using sparse autoencoder and random forest classifier",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.009",
     "publication date": "01-2018",
     "abstract": "A novel method to diagnose clinically significant prostate cancer (PCa) using Multi-parametric Magnetic Resonance Imaging (mpMRI) biomarkers in a highly imbalanced dataset is investigated in this paper. Transaxial T2 Weighted (T2W), Apparent Diffusion Coefficient (ADC) and high B-Value (BVAL) Diffusion-Weighted (DW) images obtained from PROSTATEx 2016 challenge dataset publicly available in TCIA (The Cancer Imaging Archive) is used for this study. High-level features are extracted using a single layer Sparse Autoencoder (SAE). Synthetic Minority Oversampling Technique (SMOTE), Weka Resample algorithm and Adaptive Synthetic (ADASYN) sampling approach are explored to solve the class-imbalance problem. The performance of various classifiers are also investigated and it was found that the data augmented using ADASYN followed by classification using random forest classifier achieved the best performance. It achieved an area under ROC curve of 0.979. It also reached a Cohen's kappa score of 0.873, an accuracy of 93.65% and F-Measure of 0.94 in distinguishing clinically significant PCa from indolent PCa.",
     "keywords": ["Sparse autoencoder", "Prostate cancer", "Multi-parametric MRI", "ADASYN", "Random forest"]},
    {"article name": "Glossokinetic potential based tongue–machine interface for 1-D extraction using neural networks",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.004",
     "publication date": "01-2018",
     "abstract": "Tongue machine interface (TMI) is a tongue-operated assistive technology enabling people with severe disabilities to control their environments using their tongue motion. In many disorders such as amyotrophic lateral sclerosis or stroke, people can communicate with the external world in a limited degree. However, they may be disabled, while their mind is still intact. Various tongue–machine interface techniques has been developed to support these people by providing additional communication pathway. In this study, we aimed to develop a tongue–machine interface approach by investigating pattern of glossokinetic potential (GKP) signals using neural networks via simple right/left tongue touchings to the buccal walls for 1-D control and communication, named as GKP-based TMI. As can be known in the literature, the tongue is connected to the brain via hypoglossal cranial nerve. Therefore, it generally escapes from the severe damages, in spinal cord injuries and was slowly affected than limbs of persons suffering from many neuromuscular degenerative disorders.In this work, 8 male and 2 female naive healthy subjects, aged 22 to 34 years, participated. Multilayer neural network and probabilistic neural network were employed as classification algorithms with root-mean-square and power spectral density feature extraction operations. Then the greatest success rate achieved was 97.25%.This study may serve disabled people to control assistive devices in natural, unobtrusive, speedy and reliable manner. Moreover, it is expected that GKP-based TMI could be a collaboration channel for traditional electroencephalography (EEG)-based brain computer interfaces which have significant inadequacies arisen from the EEG signals.",
     "keywords": ["Glossokinetic potential", "Assistive technologies", "Multilayer neural network", "Probabilistic neural network"]},
    {"article name": "Parkinson's disease monitoring from gait analysis via foot-worn sensors",
     "doi": "https://doi.org/10.1016/j.bbe.2018.06.002",
     "publication date": "01-2018",
     "abstract": "In Parkinson’s disease (PD), neuronal loss in the substantia nigra ultimate in dopaminergic denervation of the stiratum is followed by disarraying of the movements’ preciseness, automatism, and agility. Hence, the seminal sign of PD is a change in motor performance of affected individuals. As PD is a neurodegenerative disease, progression of disability in mobility is an inevitable consequence. Indeed, the major cause of morbidity and mortality among patients with PD is the motor changes restricting their functional independence. Therefore, monitoring the manifestations of the disease is crucial to detect any worsening of symptoms timely, in order to maintain and improve the quality of life of these patients.The changes in motion of patients with PD can be ascertained by the help of wearable sensors attached to the limbs of subjects. Then analysing the recorded data for variation of signals would make it possible to figure an individualized profile of the disease. Advancement of such tools would improve understanding of the disease evolution in the long term and simplify the detection of precipitous changes in gait on a daily basis in the short term. In both cases the apperception of such events would contribute to improve the clinical decision making process with reliable data. To this end, we offer here a computational solution for effective monitoring of PD patients from gait analysis via multiple foot-worn sensors.We introduce a supervised model that is fed by ground reaction force (GRF) signals acquired from these gait sensors. We offer a hybrid model, called Locally Weighted Random Forest (LWRF), for regression analysis over the numerical features extracted from input signals to predict the severity of PD symptoms in terms of Universal Parkinson Disease Rating Scale (UPDRS) and Hoehn and Yahr (H&Y) scale. From GRF signals sixteen time-domain features and seven frequency-domain features were extracted and used.An experimental analysis conducted on a real data acquired from PD patients and healthy controls has shown that the predictions are highly correlated with the clinical annotations. Proposed approach for severity detection has the best correlation coefficient (CC), mean absolute error (MAE) and root mean squared error (RMSE) values with 0.895, 4.462 and 7.382 respectively in terms of UPDRS. The regression results for H&Y Scale discerns that proposed model outperforms other models with CC, MAE and RMSE with values 0.960, 0.168 and 0.306 respectively. In classification setup, proposed approach achieves higher accuracy in comparison with other studies with accuracy and specificity of 99.0% and 99.5% respectively. Main novelty of this approach is the fact that an exact value of the symptom level can be inferred rather than a categorical result that defines the severity of motor disorders.",
     "keywords": ["Parkinson\u2019s disease monitoring", "Gait analysis", "Force/pressure sensor", "Ground reaction force", "Regression"]},
    {"article name": "Comparative assessment of texture features for the identification of cancer in ultrasound images: a review",
     "doi": "https://doi.org/10.1016/j.bbe.2018.01.001",
     "publication date": "01-2018",
     "abstract": "In this paper, we review the use of texture features for cancer detection in Ultrasound (US) images of breast, prostate, thyroid, ovaries and liver for Computer Aided Diagnosis (CAD) systems. This paper shows that texture features are a valuable tool to extract diagnostically relevant information from US images. This information helps practitioners to discriminate normal from abnormal tissues. A drawback of some classes of texture features comes from their sensitivity to both changes in image resolution and grayscale levels. These limitations pose a considerable challenge to CAD systems, because the information content of a specific texture feature depends on the US imaging system and its setup. Our review shows that single classes of texture features are insufficient, if considered alone, to create robust CAD systems, which can help to solve practical problems, such as cancer screening. Therefore, we recommend that the CAD system design involves testing a wide range of texture features along with features obtained with other image processing methods. Having such a competitive testing phase helps the designer to select the best feature combination for a particular problem. This approach will lead to practical US based cancer detection systems which deliver real benefits to patients by improving the diagnosis accuracy while reducing health care cost.",
     "keywords": ["Cancer", "Ultrasound", "Texture analysis", "Computer Aided Diagnosis"]},
    {"article name": "Review on plantar data analysis for disease diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.004",
     "publication date": "01-2018",
     "abstract": "Force distribution on foot surface allows to understand the human mechanical behavior, providing detailed information for the evaluation of foot alterations. In diagnosis for diseases related to plantar pathologies, there are many devices for plantar pressure measurement, and corresponding algorithms for data analyzing, providing medical tools for assisting in treatment, early detection, and the development of preventive strategies. In medicine, use of computational intelligence is increasing, making the diagnostic processes faster and more accurate. Clinical Decision Support Systems (CDSS) can handle large amounts of data to improve decision-making, helping to prevent the deterioration of people's health. Numerous approaches have been applied over the past few decades to solve medical problems such as hepatitis, diabetes, liver disease, pathological gait, and plantar diseases, among others. This paper presents the developments reported in the literature for detecting diseases through plantar pressure data and the corresponding algorithms for its analysis and diagnosis, using different electronic measurements systems. Finally, we present a discussion about the future work required to improve in the field of plantar pressure diagnosis algorithms using different approaches suggested by the authors as potential candidates. In this sense, hybrid systems which include fuzzy concepts are the most promising methodology.",
     "keywords": ["Disease diagnosis", "Plantar pathologies", "Plantar data analysis", "Hybrid systems", "Clinical decision support systems"]},
    {"article name": "Entropies for automated detection of coronary artery disease using ECG signals: A review",
     "doi": "https://doi.org/10.1016/j.bbe.2018.03.001",
     "publication date": "01-2018",
     "abstract": "Coronary artery disease (CAD) develops when coronary arteries are unable to supply oxygen-rich blood to the heart due to the accumulation of cholesterol plaque on the inner walls of the arteries. Chronic insufficient blood flow leads to the complications, including angina and heart failure. In addition, acute plaque rupture may lead to vessel occlusion, causing a heart attack. Thus, it is encouraged to have regular check-ups to diagnose CAD early and avert complications. The electrocardiogram (ECG) is a widely used diagnostic tool to study the electrical activity of the heart. However, ECG signals are highly chaotic, complex, and non-stationary in their behaviour. It is laborious, and requires expertise, to visually interpret these signals. Hence, the computer-aided detection system (CADS) is developed to assist clinicians to interpret the ECG signals fast and reliably. In this work, we have employed sixteen entropies to extract the various hidden signatures from ECG signals of normal healthy persons as well as patients with CAD. We observed that the majority of extracted entropy features showed lower values for CAD patients compared to normal subjects. We believe that there is one possible reason which could be the decreased in the variability of ECG signals is associated with reduced heart pump function.",
     "keywords": ["Electrocardiogram signals", "Entropy features", "Coronary artery disease"]},
    {"article name": "An epileptic seizure detection system based on cepstral analysis and generalized regression neural network",
     "doi": "https://doi.org/10.1016/j.bbe.2018.01.002",
     "publication date": "01-2018",
     "abstract": "This study introduces a new and effective epileptic seizure detection system based on cepstral analysis utilizing generalized regression neural network for classifying electroencephalogram (EEG) recordings. The EEG recordings are obtained from an open database which has been widely studied with many different combinations of feature extraction and classification techniques. Cepstral analysis technique is mainly used for speech recognition, seismological problems, mechanical part tests, etc. Utility of cepstral analysis based features in EEG signal classification is explored in the paper. In the proposed study, mel frequency cepstral coefficients (MFCCs) are computed in the feature extraction stage and used in neural network based classification stage. MFCCs are calculated based on a frequency analysis depending on filter bank of approximately critical bandwidths. The experimental results have shown that the proposed method is superior to most of the previous studies using the same dataset in classification accuracy, sensitivity and specificity. This achieved success is the result of applying cepstral analysis technique to extract features. The system is promising to be used in real time seizure detection systems as the neural network adopted in the proposed method is inherently of non-iterative nature.",
     "keywords": ["Epileptic seizure detection", "Cepstral analysis", "Electroencephalogram", "Generalized regression neural network"]},
    {"article name": "A segment-wise reconstruction method based on bidirectional long short term memory for Power Line Interference suppression",
     "doi": "https://doi.org/10.1016/j.bbe.2018.01.003",
     "publication date": "01-2018",
     "abstract": "The overlap between the signal components of Power Line Interference (PLI) and biomedical signals in the frequency domain makes the filtered results prone to severe distortion. Electrocardiogram (ECG) is a type of biomedical electronic signal used for cardiac diagnosis. The objective of this work is to suppress the PLI components from biomedical signals with minimal distortion, and the object of study is mainly the ECG signals. In this study, we propose a novel segment-wise reconstruction method to suppress the PLI in biomedical signals based on the Bidirectional Recurrent Neural Networks with Long Short Term Memory (Bi-LSTM). Experiments are conducted on both synthetic and real signals, and quantitative comparisons are made with a traditional IIR notch filter and two state-of-the-art methods in the literature. The results show that by our method, the output Signal-to-Noise Ratio (SNR) is improved by more than 7 dB and the settling time for step response is reduced to 0.09 s on average. The results also demonstrate that our method has enough generalization ability for unforeseen signals without retraining.",
     "keywords": ["Electrocardiogram", "Interference suppression", "Long short term memory", "Power Line Interference", "Recurrent Neural Networks"]},
    {"article name": "Numerical simulations of the pulsatile blood flow in the different types of arterial fenestrations: Comparable analysis of multiple vascular geometries",
     "doi": "https://doi.org/10.1016/j.bbe.2018.01.004",
     "publication date": "01-2018",
     "abstract": "In medical terms, fenestration stands for an anomaly within the circulatory system in which the blood vessel lumen is divided into two separate channels that rejoin in the distal part of this vessel. The primary objective of this research was to analyze the impact of the left vertebral artery (LVA) and basilar artery (BA) fenestrations on the blood flow characteristics in their regions and downstream, in the cerebral circulation. The geometrical data, obtained from the angio-Computed Tomography, were the basis for the generation of a 3D model in SolidWorks 2015. In order to observe the flow characteristics within the whole spatial domain, computational fluid dynamics was involved in performing simulations of the blood flow in the patient-specific arterial system (beginning with the aortic arch and finishing with the Circle of Willis). To examine the flow distribution changes resulting from altered fenestration geometries, additional models were built. The blood flow velocity, volume flow rate and shear stress distribution were analyzed within this study. It was proven that the length/size/position of the fenestration altered the flow characteristics in different manners. The investigations showed that the patient-specific LVA, at the V3 section (extracranial part of the artery located between the spine and the skull), is not a reason of aneurysm formation. However, BA fenestration at the proximal segment might be a possible reason of future aneurysm formation. It was proven that the computational fluid dynamics tool could support medical diagnostic procedures and multivessel brain vascular disease treatment planning.",
     "keywords": ["Fenestration", "Blood flow", "Cerebral flow", "Circle-of-Willis"]},
    {"article name": "Use of the surface electromyography for a quantitative trend validation of estimated muscle forces",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.001",
     "publication date": "01-2018",
     "abstract": "Surface EMG is a non-invasive measurement of an individual muscle activity and it can be used as the indirect form of a simulated muscle forces validation. The quantitative curves comparison has some potential, which has not been fully exploited yet [13]. The purpose of current study was to quantitatively compare muscle forces predicted using musculoskeletal models to measured surface electromyography signals. A metrics based on correlation and an electromechanical delay correction for a quantitative trend validation has been proposed.Kinematics of a normal gait was collected for three healthy subjects together with ground reaction forces and EMG signals of eight different muscles of both legs. Dynamic simulations have been performed for two models of differing complexity from OpenSim library (Gait2392 and Gait2354) [2], [5], [6], static optimization method and computed muscle control algorithm [20] have been used. It has been shown, that the level of force-EMG trend compliance, obtained for applied models and simulation techniques, is related rather to the selected muscle than to applied optimization criteria or technique. The contribution of analyzed muscles during gait has been predicted better by complex model than by simplified model. Moreover relationship between the body proportion of subject and the degree of correlation has been observed. Proposed metrics and obtained results can be the basis for further identification of cost functions, which could most closely describe motor control strategy.",
     "keywords": ["Musculoskeletal modeling", "Surface electromyography", "Muscle forces", "Human gait", "Static optimization"]},
    {"article name": "Detection of valvular heart diseases using impedance cardiography ICG",
     "doi": "https://doi.org/10.1016/j.bbe.2017.12.002",
     "publication date": "01-2018",
     "abstract": "Impedance cardiography (ICG) is a simple, non-invasive and cost effective tool for monitoring hemodynamic parameters. It has been successfully used to diagnose several cardiovascular diseases, like the heart failure and myocardial infarction. In particular, valvular heart disease (VHD) is characterized by the affection of one or more heart valves: mitral, aortic, tricuspid or pulmonary valves and it is usually diagnosed using the Doppler echocardiography. However, this technique is rather expensive, requires qualified expertise, discontinuous, and often not necessary to make just a simple diagnosis. In this paper, a new computer aided diagnosis system is proposed to detect VHD using the ICG signals. Six types of ICG heartbeats are analyzed and classified: normal heartbeats (N), mitral insufficiency heartbeats (MI), aortic insufficiency heartbeats (AI), mitral stenosis heartbeats (MS), aortic stenosis heartbeats (AS), and pulmonary stenosis heartbeats (PS). The proposed methodology is validated on 120 ICG recordings. Firstly, ICG signal is denoised using the Daubechies wavelet family with order eight (db8). Then, these signals are segmented into several heartbeats and, later, subjected to the linear prediction LP and discrete wavelet transform DWT approaches to extract temporal and time–frequency features, respectively. In order to reduce the number of features and select the most relevant ones among them, the Student's t-test is applied. Therefore, a total of 16 features are selected (3 temporal features and 13 time–frequency features). For the classification step, the support vector machine SVM and k-nearest neighbors KNN classifiers are used. Different combinations between extracted features and classifiers are proposed. Hence, experimental results showed that the combination between temporal features, time–frequency features and SVM classifier achieved the highest classification performance in classifying the N, MI, MS, AI, AS and PS heartbeats with 98.94% of overall accuracy.",
     "keywords": ["Impedance cardiography ICG", "Temporal features", "Time\u2013frequency features", "K-nearest neighbors", "Support vector machine", "Valvular heart disease"]},
    {"article name": "Nonsubsampled shearlet domain fusion techniques for CT–MR neurological images using improved biological inspired neural model",
     "doi": "https://doi.org/10.1016/j.bbe.2017.12.005",
     "publication date": "01-2018",
     "abstract": "The fusion of multimodality medical images performs a very crucial role in the clinical diagnosis, analysis and the treatment of especially in critical diseases. It is considered as an assisted approach for the radiologist by providing the composite images having significant diagnostic information acquired from the source images. The main purpose of this work is to develop an efficient framework for fusing the multimodal medical images. Three different fusion techniques are proposed in this paper that presents the CT and MR medical image fusion in nonsubsampled shearlet transform (NSST) domain using the adaptive spiking neural model. The NSST having different features and a competent depiction of the image coefficients provides several directional decomposition coefficients. Maximum selection approach and regional energy are utilized for low frequency coefficients fusion. Spatial frequency, novel modified spatial frequency and novel sum modified Laplacian motivated spiking model are used for every high frequency subimage component. Finally, fused images are reconstructed by applying inverse NSST. The performance of proposed fusion techniques is validated by extensive simulations performed on different CT-MR image datasets using proposed and other thirty seven existing fusion approaches in terms of both the subjective and objective manner. The results revealed that the proposed techniques provide better visualization of resultant images and higher quantitative measures compared to several existing fusion approaches.",
     "keywords": ["Fusion", "Nonsubsampled shearlet", "Multimodality", "Computed tomography", "Magnetic resonance"]},
    {"article name": "Denoising of Electrocardiogram (ECG) signal by using empirical mode decomposition (EMD) with non-local mean (NLM) technique",
     "doi": "https://doi.org/10.1016/j.bbe.2018.01.005",
     "publication date": "01-2018",
     "abstract": "In this paper, the investigation on effectiveness of the empirical mode decomposition (EMD) with non-local mean (NLM) technique by using the value of differential standard deviation for denoising of ECG signal is performed. Differential standard deviation is calculated for collecting information related to the input noise so that appropriate formation in EMD and NLM framework can be performed. EMD framework in the proposed methodology is used for reduction of the noise from the ECG signal. The output of the EMD passes through NLM framework for preservation of the edges and cancel the noise present in the ECG signal after the EMD process. The performance of the proposed methodology has been validated by using added white and color Gaussian noise to the clean ECG signal from MIT-BIH arrhythmia database at different signal to noise ratio (SNR). The proposed denoising technique shows lesser mean of percent root mean square difference (PRD), mean square error (MSE), and better mean SNR improvement compared to other well-known methods at different input SNR. The proposed methodology also shows lesser standard deviation PRD, MSE, and SNR improvement compared to other well-known methods at different input SNR.",
     "keywords": ["Electrocardiogram (ECG) signal", "Empirical mode decomposition (EMD)", "Non local mean (NLM) technique", "R peak detection methodology"]},
    {"article name": "Gene selection from large-scale gene expression data based on fuzzy interactive multi-objective binary optimization for medical diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.002",
     "publication date": "01-2018",
     "abstract": "An efficient fuzzy interactive multi-objective optimization method is proposed to select the sub-optimal subset of genes from large-scale gene expression data. It is based on the binary particle swarm optimization (BPSO) algorithm tuned by a chaotic method. The proposed method is able to select the sub-optimal subset of genes with the least number of features that can accurately distinguish between the two classes, e.g. the normal and cancerous samples. The proposed method is evaluated on several publicly available microarray and RNA-sequencing gene expression datasets such as leukemia, colon cancer, central nervous system, lung cancer, ovarian cancer, prostate cancer and RNA-seq lung disease. The results indicate that the proposed method can identify the minimum number of genes to achieve the most accuracy, sensitivity and specificity in the classification process. Achieving 100% accuracy in six out of the seven datasets investigated in this study, demonstrates the high capacity of the proposed algorithm to find the sub-optimal subset of genes. This approach is useful in clinical applications to extract the most influential genes on a disease and to find the treatment procedure for the disease.",
     "keywords": ["Fuzzy interactive method", "Sub-optimal subset", "Gene selection", "Large-scale data", "Multi-objective", "Adaptive binary particle swarm optimization"]},
    {"article name": "Combination of clinical and multiresolution features for glaucoma detection and its classification using fundus images",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.003",
     "publication date": "01-2018",
     "abstract": "Glaucoma is a neuro-degenerative disorder of the eye and it leads to permanent blindness when untreated or detected in the later stage. The main cause of glaucoma is the damage of the optic nerve, which occurs due to the increase of eye pressure. Hence the early detection of this disease is critical in time and which can help to prevent further vision loss. The assessment of optic nerve head using fundus images is more beneficial than the raised intra ocular pressure assessment in population-based glaucoma screening. This work proposed a novel method for glaucoma identification based on time-invariant feature cup to disk ratio and anisotropic dual-tree complex wavelet transform features. Optic disk segmentation is done by using Fuzzy C-Means clustering method and Otsu's thresholding is used for optic cup segmentation. The results show the proposed method achieved an accuracy rate of 97.67% with 98% sensitivity using a multilayer perceptron model that is considered as clinically significant when compared to the existing works.",
     "keywords": ["Glaucoma", "Fundus image", "Wavelet transform", "Feature extraction", "Classification"]},
    {"article name": "Accurate prediction of continuous blood glucose based on support vector regression and differential evolution algorithm",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.005",
     "publication date": "01-2018",
     "abstract": "Type 1 diabetes (T1D) is a chronic disease requiring patients to know their blood glucose values in order to ensure blood glucose levels as close to normal as possible. Hence, the ability to predict blood glucose levels is of a great interest for clinical researchers. In this sense, the literature is rich with several solutions that can predict blood glucose levels. Unfortunately, these methods require the patient to specific their daily activities: meal intake, insulin injection and emotional factors, which can be error prone. To reduce this burden on the patent, this work proposes to use only continuous glucose monitoring (CGM) data to predict blood glucose levels independently of other factors. To support this, support vector regression (SVR) and differential evolution (DE) algorithms were investigated. The proposed method is validated using real CGM data of 12 patients. The obtained average of root mean square error (RMSE) was 9.44, 10.78, 11.82 and 12.95 mg/dL for prediction horizon (PH) respectively equal to 15, 30, 45 and 60 min. The results of the present study and comparison with some previous works show that the proposed method holds promise. The SVR based on DE algorithm achieved high prediction accuracy while being robustness, automatic, and requiring no human intervention.",
     "keywords": ["Continuous glucose monitoring (CGM)", "Differential evolution (DE)", "Support vector regression (SVR)", "Time series forecasting", "Type 1 diabetes (T1D)"]},
    {"article name": "Efficient compression of bio-signals by using Tchebichef moments and Artificial Bee Colony",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.006",
     "publication date": "01-2018",
     "abstract": "In this paper, an algorithm is proposed for efficient compression of bio-signals based on discrete Tchebichef moments and Artificial Bee Colony (ABC). The Tchebichef moments are used to extract features of the bio-signals, then, the ABC algorithm is used to select of the optimum features which achieve the best bio-signal quality for a specific compression ratio (CR). The proposed algorithm has been tested by using different datasets of Electrocardiogram (ECG), Electroencephalogram (EEG), and Electromyogram (EMG). The optimum feature selection using ABC significantly improve the quality of the reconstructed bio-signals. Different numerical experiments are performed to compress different records of ECG, EEG and EMG bio-signals by using the proposed algorithm and the most recent existing methods. The performance of the proposed algorithm and the other existing methods are evaluated using different metrics such as CR, PRD, and peak signal to noise ratio (PSNR). The comparison has shown that, at the same CR, the proposed compression algorithm yields the best quality of the reconstructed signals over the other existing methods.",
     "keywords": ["Bio-signals", "ECG", "EEG", "EMG", "Tchebichef moments", "Artificial Bee Colony"]},
    {"article name": "In silico testing of optimized Fuzzy P+D controller for artificial pancreas",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.009",
     "publication date": "01-2018",
     "abstract": "Despite therapeutic advances, a complete cure has not been found yet for patients with type 1 diabetes (T1D). Artificial pancreas (AP) is a promising approach to cope with this disease. The controller part of the AP can compute the insulin infusion rate that keeps blood glucose concentration (BGC) in normoglycemic ranges. Most controllers rely on model-based controllers and use manual meal announcements or meal detection algorithms. For a fully automated AP, a controller only using the patient's BGC data is needed.An optimized Mamdani-type hybrid Fuzzy P+D controller was proposed. Using the University of Virginia/Padova Simulator, a 36 h scenario was tested in nine virtual adult patients. To take into account the effect of continuous glucose monitor noise, the scenario was repeated 25 times for each adult. The main outcomes were the percentage of time BGC levels in the euglycemic range, low blood glucose index (LBGI), and blood glucose risk index (BGRI), respectively.The obtained BGC values were found to be in the euglycemic range for 82.6% of the time. Moreover, the BGC values were below 50 mg/dl, below 70 mg/dl and above 250 mg/dl for 0%, 0.35% and 0.74% of the time, respectively. The BGRI, LBGI, and high blood glucose index (HBGI) were also found as 3.75, 0.34 and 3.41, respectively. The proposed controller both increases the time the BGC levels in the euglycemic range and causes less hypoglycemia and hyperglycemia relative to the published techniques studied in a similar scenario and population.",
     "keywords": ["Artificial pancreas", "Closed-loop", "Fuzzy P+D controller", "Type 1 diabetes"]},
    {"article name": "An optimal spectroscopic feature fusion strategy for MR brain tumor classification using Fisher Criteria and Parameter-Free BAT optimization algorithm",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.008",
     "publication date": "01-2018",
     "abstract": "In the present work, a fused metabolite ratio is proposed that integrates the conventional metabolite ratios in a weighted manner to improve the diagnostic accuracy of glioma brain tumor categorization. Each metabolite ratio is weighted by the value generated by the Fisher and the Parameter-Free BAT (PFree BAT) optimization algorithm. Here, feature fusion is formulated as an optimization problem with PFree BAT optimization as its underlying search strategy and Fisher Criterion serving as a fitness function. Experiments were conducted on the magnetic resonance spectroscopy (MRS) data of 50 subjects out of which 27 showed low-grade glioma and rest presented high-grade. The MRS data was analyzed for the peaks. The conventional metabolite ratios, i.e., Choline/N-acetyl aspartate (Cho/NAA), Cho/Creatine (Cho/Cr), were quantitated using peak integration that exhibited difference among the tumor grades. The difference in the conventional metabolite ratios was enhanced by the proposed fused metabolite ratio that was duly validated by metrics of sensitivity, specificity, and the classification accuracy. Typically, the fused metabolite ratio characterized low-grade and high-grade with a sensitivity of 96%, specificity of 91%, and an accuracy of 93.72% when fed to the K-nearest neighbor classifier following a fivefold cross-validation data partitioning scheme. The results are significantly better than that obtained by the conventional metabolites where an accuracy equal to 80%, 87%, and 89% was attained. Prominently, the results using the fused metabolite ratio show a surge of 4.7% in comparison to Cho/Cr + Cho/NAA + NAA/Cr. Moreover, the obtained results are better than the similar works reported in the literature.",
     "keywords": ["Weighted fusion", "Fisher Criterion", "Parameter-Free BAT", "Optimization", "Glioma brain tumor"]},
    {"article name": "The ADHD effect on the actions obtained from the EEG signals",
     "doi": "https://doi.org/10.1016/j.bbe.2018.02.007",
     "publication date": "01-2018",
     "abstract": "Attention-deficit/hyperactivity disorder (ADHD) is an important challenge in studies of children's ethology that unbalances the opposite behaviors for creating inattention along with or without hyperactivity. Nevertheless, most studies on the ADHD children, which employed the EEG signals for analyzing the ADHD influence on the brain activities, considered the EEG signals as a random or chaotic process without considering the role of these opposites in the brain activities. In this study, we considered the EEG signals as a biotic process according to these opposites and examined the ADHD effect on the brain activity by defining the dual sets of transitions between states in the complement plots of quantized EEG segments. The results of this study generally indicated that the complement plots of quantized EEG signal have a surprising regularity similar to the Mandala patterns compared to the chaotic processes. These results also indicated that the probability of occurrence of dual sets in the complement plots of ADHD children was averagely different (p < 0.01) from that of healthy children, so that the SVM classifier developed by these probabilities could significantly separate the ADHD from healthy children (99.37% and 98.25% for training and testing sets, respectively). Therefore, the complement plots of quantized EEG signals relevant to the ADHD children not only can quantify informational opposition caused by inattention, hyperactivity and impulsivity, but also these plots can provide remarkable information for developing new diagnostic and therapeutic techniques.",
     "keywords": ["ADHD", "EEG", "BIOS theory", "Action", "Complement plot"]},
    {"article name": "Medical image registration in image guided surgery: Issues, challenges and research opportunities",
     "doi": "https://doi.org/10.1016/j.bbe.2017.10.001",
     "publication date": "01-2018",
     "abstract": "Multimodal images of a patient obtained at different time, pre-surgical planning, intra-procedural guidance and visualization, and post-procedural assessment are the core components of image-guided surgery (IGS). In IGS, the goal of registration is to integrate corresponding information in different images of the same organ into a common coordinate system. Registration is a fundamental task in IGS and its main purpose is to provide better visualization and navigation to the surgeons. In this paper, we describe the most popular types of medical image registration and evaluate their prominent state-of-the art issues and challenges in image-guided surgery. We have also presented the factors which affect the accuracy, reliability and efficiency of medical image registration methods. It is not possible to achieve highly successful IGS until all the issues and challenges in registration process are identified and subsequently solved.",
     "keywords": ["Medical image registration", "Image registration methods", "Image-guided surgery"]},
    {"article name": "A hybrid intelligent system for the prediction of Parkinson's Disease progression using machine learning techniques",
     "doi": "https://doi.org/10.1016/j.bbe.2017.09.002",
     "publication date": "01-2018",
     "abstract": "Parkinson's Disease (PD) is a progressive degenerative disease of the nervous system that affects movement control. Unified Parkinson's Disease Rating Scale (UPDRS) is the baseline assessment for PD. UPDRS is the most widely used standardized scale to assess parkinsonism. Discovering the relationship between speech signal properties and UPDRS scores is an important task in PD diagnosis. Supervised machine learning techniques have been extensively used in predicting PD through a set of datasets. However, the most methods developed by supervised methods do not support the incremental updates of data. In addition, the standard supervised techniques cannot be used in an incremental situation for disease prediction and therefore they require to recompute all the training data to build the prediction models. In this paper, we take the advantages of an incremental machine learning technique, Incremental support vector machine, to develop a new method for UPDRS prediction. We use Incremental support vector machine to predict Total-UPDRS and Motor-UPDRS. We also use Non-linear iterative partial least squares for data dimensionality reduction and self-organizing map for clustering task. To evaluate the method, we conduct several experiments with a PD dataset and present the results in comparison with the methods developed in the previous research. The prediction accuracies of method measured by MAE for the Total-UPDRS and Motor-UPDRS were obtained respectively MAE = 0.4656 and MAE = 0.4967. The results of experimental analysis demonstrated that the proposed method is effective in predicting UPDRS. The method has potential to be implemented as an intelligent system for PD prediction in healthcare.",
     "keywords": ["Healthcare", "Parkinson Disease diagnosis", "UPDRS", "Clustering", "Dimensionality reduction", "ISVR"]},
    {"article name": "Electroencephalography (EEG) signal processing for epilepsy and autism spectrum disorder diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.006",
     "publication date": "01-2018",
     "abstract": "Quantification of abnormality in brain signals may reveal brain conditions and pathologies. In this study, we investigate different electroencephalography (EEG) feature extraction and classification techniques to assist in the diagnosis of both epilepsy and autism spectrum disorder (ASD). First, the EEG signal is pre-processed to remove major artifacts before being decomposed into several EEG sub-bands using a discrete-wavelet-transform (DWT). Two nonlinear methods were studied, namely, Shannon entropy and largest Lyapunov exponent, which measure complexity and chaoticity in the EEG recording, in addition to the two conventional methods (namely, standard deviation and band power). We also study the use of a cross-correlation approach to measure synchronization between EEG channels, which may reveal abnormality in communication between brain regions. The extracted features are then classified using several classification methods. Different EEG datasets are used to verify the proposed design exploration techniques: the University of Bonn dataset, the MIT dataset, the King Abdulaziz University dataset, and our own EEG recordings (46 subjects). The combination of DWT, Shannon entropy, and k-nearest neighbor (KNN) techniques produces the most promising classification result, with an overall accuracy of up to 94.6% for the three-class (multi-channel) classification problem. The proposed method obtained better classification accuracy compared to the existing methods and tested using larger and more comprehensive EEG dataset.The proposed method could potentially be used to assist epilepsy and ASD diagnosis therefore improving the speed and the accuracy.",
     "keywords": ["EEG", "Computer aided diagnosis", "Epilepsy", "Neurological disorder", "Autism", "Machine learning"]},
    {"article name": "A generalized method for the segmentation of exudates from pathological retinal fundus images",
     "doi": "https://doi.org/10.1016/j.bbe.2017.10.003",
     "publication date": "01-2018",
     "abstract": "Diabetic retinopathy, an asymptomatic complication of diabetes, is one of the leading causes of blindness in the world. The exudates, abnormal leaked fatty deposits on retina, are one of the most prevalent and earliest clinical signs of diabetic retinopathy. In this paper, a generalized exudates segmentation method to assist ophthalmologists for timely treatment and effective planning in the diagnosis of diabetic retinopathy is developed. The main contribution of the proposed method is the reliable segmentation of exudates using dynamic decision thresholding irrespective of associated heterogeneity, bright and faint edges. The method is robust in the sense that it selects the threshold value dynamically irrespective of the large variations in retinal fundus images from varying databases. Since no performance comparison of state of the art methods is available on common database, therefore, to make a fair comparison of the proposed method, this work has been performed on a diversified database having 1307 retinal fundus images of varying characteristics namely: location, shapes, color and sizes. The database comprises of 649 clinically acquired retinal fundus images from eye hospital and 658 retinal images from publicly available databases such as STARE, MESSIDOR, DIARETDB1 and e-Optha EX. The segmentation results are validated by performing two sets of experiments namely: lesion based evaluation criteria and image based evaluation criteria. Experimental results at lesion level show that the proposed method outperforms other existing methods with a mean sensitivity/specificity/accuracy of 88.85/96.15/93.46 on a composite database of retinal fundus images. The segmentation results for image-based evaluation with a mean sensitivity/specificity/accuracy of 94.62/98.64/96.74 respectively prove the clinical effectiveness of the method. Furthermore, the significant collective performance of these experiments on clinically as well as publicly available standard databases proves the generalization ability and the strong candidature of the proposed method in the real-time diagnosis of diabetic retinopathy.",
     "keywords": ["Exudates", "Diabetic retinopathy", "Segmentation", "Retinal fundus Image", "Lesion and image based evaluation"]},
    {"article name": "An automated ECG signal quality assessment method for unsupervised diagnostic systems",
     "doi": "https://doi.org/10.1016/j.bbe.2017.10.002",
     "publication date": "01-2018",
     "abstract": "In this paper, the authors present an automated method for quality assessment of electrocardiogram (ECG) signal. Our proposed method not only detects and classifies the ECG noises but also localizes the ECG noises which can play a crucial role in extracting reliable clinical features for ECG analysis systems. The proposed method is based on three stages: Wavelet decomposition of ECG signal into sub-bands; simultaneous ECG signal and noise reconstruction; extraction of temporal features such as maximum absolute amplitude, zerocrossings, kurtosis and autocorrelation function for detection, localization and classification of ECG noises including flat line (FL), time-varying noise or pause (TVN), baseline wander (BW), abrupt change (AB), power line interference (PLI), muscle artifacts (MA) and additive white Gaussian noise (AWGN). The proposed method is tested and validated against manually annotated ECG signals corrupted with aforementioned noises taken from MIT-BIH arrhythmia database, Physionet challenge database, and real-time recorded ECG signals. Comparative detection and classification results depict the superior performance of the proposed method over state of art methods. Detection results show that our method can achieve an average sensitivity (Se), average specificity (Sp) and accuracy (A) of 99.61%, 98.51%, 99.49% respectively. Also, the method achieves a Se of 98.18%, and Sp of 94.97% for real-time recorded ECG signals. The method has an average timing error of 0.14 s in localizing the noise segments. Further, classification results demonstrate that the proposed method achieves an average sensitivity (Se), average positive predictivity (PP) and classification accuracy (Ac) of 98.53%, 98.89%, 97.50% respectively.",
     "keywords": ["Signal quality assessment", "Electrocardiogram", "Baseline wander", "Muscle artifacts"]},
    {"article name": "Automated and effective content-based mammogram retrieval using wavelet based CS-LBP feature and self-organizing map",
     "doi": "https://doi.org/10.1016/j.bbe.2017.09.003",
     "publication date": "01-2018",
     "abstract": "In this paper, automated, fast and effective content based-mammogram image retrieval system is proposed. The proposed pre-processing steps include automatic labelling-scratches suppression, automatic pectoral muscle removal and image enhancement. Further, for segmentation selective thresholds based seeded region growing algorithm is introduced. Furthermore, we apply 2-level discrete wavelet transform (DWT) on the segmented region and wavelet based centre symmetric-local binary pattern (WCS-LBP) features are extracted. Then, extracted features are fed to self-organizing map (SOM) which generates clusters of images, having similar visual content. SOM produces different clusters with their centres and query image features are matched with all cluster representatives to find closest cluster. Finally, images are retrieved from this closest cluster using Euclidean distance similarity measure. So, at the searching time the query image is searched only in small subset depending upon cluster size and is not compared with all the images in the database, reflects a superior response time with good retrieval performances. Descriptive experimental and empirical discussions confirm the effectiveness of this paper.",
     "keywords": ["Self-organizing map", "Mammography", "Image segmentation", "DWT", "CBIR", "CS-LBP"]},
    {"article name": "Development of a practical high frequency brain–computer interface based on steady-state visual evoked potentials using a single channel of EEG",
     "doi": "https://doi.org/10.1016/j.bbe.2017.10.004",
     "publication date": "01-2018",
     "abstract": "Brain–computer interfaces based on steady-state visual evoked potentials have recently gained increasing attention due to high performance and minimal user training. Stimulus frequencies in the range of 4–60 Hz have been used in these systems. However, eye fatigue when looking at low-frequency flickering lights, higher risk of induced epileptic seizure for medium-frequency flickers, and low signal amplitude for high-frequency flickers complicate appropriate selection of flickering frequencies. Here, different flicker frequencies were evaluated for development of a brain–computer interface speller that ensures user's comfort as well as the system's efficiency. A frequency detection algorithm was also proposed based on Least Absolute Shrinkage and Selection Operator estimate that provides excellent accuracy using only a single channel of EEG. After evaluation of the SSVEP responses in the range of 6–60 Hz, three stimulus frequency sets of 30–35, 35–40 and 40–45 Hz were adopted and the system's performance and corresponding eye fatigue were compared. While the accuracy of the asynchronous speller for all three stimulus frequency sets was close to the maximum (average 97.6%), repeated measures ANOVA demonstrated that the typing speed for 30–35 Hz (8.09 char/min) and 35–40 Hz (8.33 char/min) are not significantly different, but are significantly higher than for 40–45 Hz (6.28 char/min). On the other hand, the average eye fatigue scale for 35–40 Hz (80%) is comparable to that for 40–45 Hz (85%), but very higher than for 30–35 Hz (60%). Therefore, 35–40 Hz range was proposed for the system which resulted in 99.2% accuracy and 67.1 bit/min information transfer rate.",
     "keywords": ["Brain\u2013computer interface", "Steady-state visual evoked potential", "Eye fatigue", "High-frequency flickering stimuli"]},
    {"article name": "Contralateral asymmetry for breast cancer detection: A CADx approach",
     "doi": "https://doi.org/10.1016/j.bbe.2017.10.005",
     "publication date": "01-2018",
     "abstract": "Early detection is fundamental for the effective treatment of breast cancer and the screening mammography is the most common tool used by the medical community to detect early breast cancer development. Screening mammograms include images of both breasts using two standard views, and the contralateral asymmetry per view is a key feature in detecting breast cancer. However, most automated detection algorithms do not take it into account. In this research, we propose a methodology to incorporate said asymmetry information into a computer-aided diagnosis system that can accurately discern between healthy subjects and subjects at risk of having breast cancer. Furthermore, we generate features that measure not only a view-wise asymmetry, but a subject-wise one. Briefly, the methodology co-registers the left and right mammograms, extracts image characteristics, fuses them into subject-wise features, and classifies subjects. In this study, 152 subjects from two independent databases, one with analog- and one with digital mammograms, were used to validate the methodology. Areas under the receiver operating characteristic curve of 0.738 and 0.767, and diagnostic odds ratios of 23.10 and 9.00 were achieved, respectively. In addition, the proposed method has the potential to rank subjects by their probability of having breast cancer, aiding in the re-scheduling of the radiologists’ image queue, an issue of utmost importance in developing countries.",
     "keywords": ["Brest cancer", "Contralateral", "CADx", "Machine learning", "Detection", "Asymmetry"]},
    {"article name": "A bionic hand controlled by hand gesture recognition based on surface EMG signals: A preliminary study",
     "doi": "https://doi.org/10.1016/j.bbe.2017.11.001",
     "publication date": "01-2018",
     "abstract": "A bionic hand with fine motor ability could be a favorable option for replacing the human hand when performing various operations. Myoelectric control has been widely used to recognize hand movements in recent years. However, most of the previous studies have focused on whole-hand movements, with only a few investigating subtler motions. The aim of this study was to construct a prototype system for recognizing hand postures with the aim of controlling a bionic hand by analyzing sEMG signals measured at the flexor digitorum superficialis and extensor digitorum muscles. We adopted multiple features commonly used in previous studies—mean absolute value, zero crossing, slope sign change, and waveform length—in the algorithm for extracting hand-posture features, and the k-nearest-neighbors (KNN) algorithm as the classifier to perform hand-posture recognition. The bionic hand was controlled by an Arduino microprocessor, which converted the signals received from the classification process that were fed to the servo motors controlling the bionic fingers. We constructed a two-channel sEMG pattern-recognition system that can identify human hand postures and control a homemade bionic hand to perform corresponding hand postures. The KNN approach was able to recognize four different hand postures with a classification accuracy of 94% in the online experiment by using the channel combination. Moreover, the experimental tests show that the bionic hand could faithfully imitate the hand postures of the human hand. This study has bridged the gap between the features of sEMG signals of fingers and the postures of a bionic hand.",
     "keywords": ["Hand posture recognition", "Surface myoelectric signal", "k-nearest neighbors", "Hudgins\u2019 features", "Bionic hand", "LabVIEW"]},
    {"article name": "Application of intrinsic band function technique for automated detection of sleep apnea using HRV and EDR signals",
     "doi": "https://doi.org/10.1016/j.bbe.2017.11.003",
     "publication date": "01-2018",
     "abstract": "Sleep apnea is the most common sleep disorder that causes respiratory, cardiac and brain diseases. The heart rate variability (HRV) and the electrocardiogram-derived respiration (EDR) signals to capture the cardio-respiratory information and the features extracted from these two signals have been used for the detection of sleep apnea. Detection of sleep apnea using the combination of HRV and EDR signals may provide more information. This paper proposes a novel method for the automated detection of sleep apnea based on the features extracted from HRV and EDR signals. The method involves the extraction of features from the intrinsic band functions (IBFs) of both EDR and HRV signals, and the classification using kernel extreme learning machine (KELM). The IBFs of HRV and EDR signals are evaluated using the Fourier decomposition method (FDM). The energy and the fuzzy entropy (FE) features are extracted from these IBFs. The kernel extreme learning machine (KELM) classifier with four kernel functions such as ‘linear’, ‘polynomial’, ‘radial basis function (RBF)’ and ‘cosine wavelet kernel’ is used for the automated detection of sleep apnea. The proposed technique yielded a sensitivity and a specificity of 78.02% and 74.64%, respectively using the public database. The method outperformed some of the reported works using HRV and EDR signals.",
     "keywords": ["Sleep apnea", "HRV signal", "EDR signal", "Fourier decomposition method (FDM)", "Fuzzy entropy and kernel extreme learning machine"]},
    {"article name": "Automated quantification of ultrasonic fatty liver texture based on curvelet transform and SVD",
     "doi": "https://doi.org/10.1016/j.bbe.2017.12.004",
     "publication date": "01-2018",
     "abstract": "Fatty liver is a prevalent disease and is the major cause for the dysfunction of the liver. If fatty liver is untreated, it may progress into chronic diseases like cirrhosis, hepatocellular carcinoma, liver cancer, etc. Early and accurate detection of fatty liver is crucial to prevent the fatty liver progressing into chronic diseases. Based on the severity of fat, the liver is categorized into four classes, namely Normal, Grade I, Grade II and Grade III respectively. Ultrasound scanning is the widely used imaging modality for diagnosing the fatty liver. The ultrasonic texture of liver parenchyma is specific to the severity of fat present in the liver and hence we formulated the quantification of fatty liver as a texture discrimination problem. In this paper, we propose a novel algorithm to discriminate the texture of fatty liver based on curvelet transform and SVD. Initially, the texture image is decomposed into sub-band images with curvelet transform enhancing gradients and curves in the texture, then an absolute mean of the singular values are extracted from each curvelet decomposed image, and used it as a feature representation for the texture. Finally, a cubic SVM classifier is used to classify the texture based on the extracted features. Tested on a database of 1000 image textures with 250 image textures belonging to each class, the proposed algorithm gave an accuracy of 96.9% in classifying the four grades of fat in the liver.",
     "keywords": ["Fatty liver", "Curvelet transform", "SVD", "Texture features", "SVM", "Computer aided diagnosis"]},
    {"article name": "Easy and affordable method for rapid prototyping of tissue models in vitro using three-dimensional bioprinting",
     "doi": "https://doi.org/10.1016/j.bbe.2017.12.001",
     "publication date": "01-2018",
     "abstract": "In vitro tissue model systems have attracted considerable attention in drug discovery owing to their ability to facilitate identification of promising compounds in the near-physiological environment during drug development. Additive manufacturing helps in mimicking complex geometries including the microarchitecture of the body tissues. Exploiting this emerging technology, the present study demonstrates a simple and inexpensive approach for the fabrication of three-dimensional (3D) in vitro tissue models using a custom-designed automated bioprinting system. The bioink mixture comprised of a novel optimized composition of widely known biomaterials including gelatin, alginate and hydrolyzed type-1 collagen to embed and print the C2C12 myoblast cells. The structural stability and integrity of the cells-laden constructs were found to be significantly consistent for more than 14 days in culture. Rheological and mechanical properties of the bioink blend were characterized to assess its efficacy for the fabrication of cells-laden tissue constructs. Scanning electron micrographs were acquired to analyze porosity of the scaffold for cellular growth and proliferation. The viability of cells embedded within the hydrogel was >80%, 3 h post-printing. We anticipate that the fabricated tissues will serve as an alternative model for in vitro toxicological and drug response studies.",
     "keywords": ["3D bioprinting", "In vitro tissue model", "Bioink", "C2C12 cells", "Fused deposition modelling (FDM)"]},
    {"article name": "Novel expert system for glaucoma identification using non-parametric spatial envelope energy spectrum with fundus images",
     "doi": "https://doi.org/10.1016/j.bbe.2017.11.002",
     "publication date": "01-2018",
     "abstract": "Glaucoma is the prime cause of blindness and early detection of it may prevent patients from vision loss. An expert system plays a vital role in glaucoma screening, which assist the ophthalmologists to make accurate decision. This paper proposes a novel technique for glaucoma detection using optic disk localization and non-parametric GIST descriptor. The method proposes a novel area based optic disk segmentation followed by the Radon transformation (RT). The change in the illumination levels of Radon transformed image are compensated using modified census transformation (MCT). The MCT images are then subjected to GIST descriptor to extract the spatial envelope energy spectrum. The obtained dimension of the GIST descriptor is reduced using locality sensitive discriminant analysis (LSDA) followed by various feature selection and ranking schemes. The ranked features are used to build an efficient classifier to detect glaucoma. Our system yielded a maximum accuracy (97.00%), sensitivity (97.80%) and specificity (95.80%) using support vector machine (SVM) classifier with nineteen features. Developed expert system also achieved maximum accuracy (93.62%), sensitivity (87.50%) and specificity (98.43%) for public dataset using twenty six features. The proposed method is efficient and computationally less expensive as it require only nineteen features to model a classifier for the huge dataset. Therefore the proposed method can be effectively utilized in hospitals for glaucoma screening.",
     "keywords": ["Computer aided diagnosis", "GIST", "Glaucoma", "Support vector machine", "Radon transform"]},
    {"article name": "Parachuting training improves autonomic control of the heart in novice parachute jumpers",
     "doi": "https://doi.org/10.1016/j.bbe.2017.11.004",
     "publication date": "01-2018",
     "abstract": "This study aimed to investigate the acute effect of skydiving and the chronic effect of parachute jump training on the cardiac response in novice and trained parachuters.The study included 11 experienced skydivers (expert group), aged 35.9 ± 7.2 years, and 12 students (novice group), aged 27.9 ± 7.2 years. Participants underwent 10-unit training in accelerated freefall (AFF) from an altitude of 4000 m.In experts, the highest HR was noted during the phase of opening of the parachute and during the landing phase, and in pre-training novices during the phase of exit from the plane and the descent by parachute. Mean standard deviation of NN intervals (SDNN) was higher in experts than pre-training novices.In novices, post-training values of SDNN, root mean square of successive differences (RMSSD), and the low/high frequency oscillation ratio (LF/HF) were higher, and HF and LF were lower, than pre-training values. In experts the values of SDNN, RMSSD, LF, HF, and total power spectrum (TP) were significantly higher and LF/HF significantly lower than in pre-training novices.Novice compared to experienced skydivers are characterized by higher modulation of the sympathetic, and lower modulation of the parasympathetic autonomic nervous system (ANS). Chronic effects of 10-unit AFF training are characterized by decreased modulation of the sympathetic nervous system, increased total power spectrum of HRV, and increased activity of the parasympathetic nervous system. The changes in ANS modulation suggest that parachute training leads to a reduction of the stress response and improves autonomic control of cardiovascular function in novice skydivers.",
     "keywords": ["Heart rate variability", "Cardiac adaptation", "Accelerated freefall", "ECG", "Skydiving"]},
    {"article name": "Strabismic amblyopia affects decision processes preceding saccadic response",
     "doi": "https://doi.org/10.1016/j.bbe.2017.12.003",
     "publication date": "01-2018",
     "abstract": "Amblyopia is a developmental disorder of vision associated with abnormal visual stimulation during early childhood. It is known that amblyopia may affect not only spatial vision parameters but also oculomotor behavior. Several previous studies showed that increased saccadic reaction time (latency) may be present in amblyopic subjects. In our recent work, we have demonstrated that not only amblyopic but also a dominant eye may show increased saccadic latency in strabismic individuals. Since saccadic latency can be considered as a decision time, we have applied LATER (Linear Approach to Threshold with Ergodic Rate) decision model to find out how developmental impairment of visual input affects visual decision-making processes, as well as to verify whether amblyopia affects also the cortical ability to inhibit more primitive, early saccadic responses during our modified delayed saccade task. Ten subjects with strabismic amblyopia and twelve control subjects were examined. As we expected, strabismic amblyopes showed decreased rate of rise of the neural decision signal for all viewing conditions as compared to controls. In addition, the comparison between the strabismic and anisometropic groups revealed that the amblyopic eye in strabismic subjects showed decreased rate of rise of the decision signal as compared to amblyopic eye in anisometropic subjects. Although we speculated that amblyopia may reduce the ability of cortical control and favor more reflexive, early saccadic actions to occur, our findings did not confirm this hypothesis. This study provide further evidence that amblyopia is associated with cortical deficits which affect the cortical decision about saccade initiation.",
     "keywords": ["Amblyopia", "Decision processes", "Strabismic amblyopia", "Saccadic latency", "LATER model"]},
    {"article name": "A rapid algebraic 3D volume image reconstruction technique for cone beam computed tomography",
     "doi": "https://doi.org/10.1016/j.bbe.2017.07.001",
     "publication date": "01-2017",
     "abstract": "Computed tomography (CT) is a widely used imaging technique in medical diagnosis. Among the latest advances in CT imaging techniques, the use of cone-beam X-ray projections, instead of the usual planar fan beam, promises faster yet safer 3D imaging in comparison to the previous CT imaging methodologies. This technique is called Cone Beam CT (CBCT). However, these advantages come at the expense of a more challenging 3D reconstruction problem that is still an active research area to improve the speed and quality of image reconstruction. In this paper, we propose a rapid parallel Multiplicative Algebraic Reconstruction Technique (rpMART) via a vectorization process for CBCT which gives more accurate and faster reconstruction even with a lower number of projections via parallel computing. We have compared rpMART with the parallel version of Algebraic Reconstruction Technique (pART) and the conventional non-parallel versions of npART, npMART and Feldkamp, Davis, and Kress (npFDK) techniques. The results indicate that the reconstructed volume images from rpMART provide a higher image quality index of 0.99 than the indices of pART and npFDK of 0.80 and 0.39, respectively. Also the proposed implementation of rpMART and pART via parallel computing significantly reduce the reconstruction time from more than 6 h with npART and npMART to 580 and 560 s with the full 360° projections data, respectively. We consider that rpMART could be a better image reconstruction technique for CBCT in clinical applications instead of the widely used FDK method.",
     "keywords": ["Cone-beam computed tomography", "Reconstruction from projections", "Analytic reconstruction methods", "Iterative reconstruction methods", "Vectorization", "Parallel computing"]},
    {"article name": "Determining the shift of a bronchoscope catheter from the analysis of a video sequence of a bronchoscope video camera",
     "doi": "https://doi.org/10.1016/j.bbe.2017.07.002",
     "publication date": "01-2017",
     "abstract": "In this study we have proposed an algorithm for automated monitoring of the movements of a catheter used in peripheral bronchoscopy examination. We have shown that the shift of the catheter can be controlled in an automated way with quite a good accuracy by the means of analysis of video sequence recorded by a video camera of a bronchoscope. For a catheter moving between successive frames by no more than 1/3 of the distance between successive markers associated with a catheter the accuracy of a catheter shift measurement was equal to 1% and for a catheter moving between successive frames by no more than 1/2 of the distance between successive markers associated with a catheter the accuracy of a catheter shift measurement was equal to 5%. Visual inspection proved that the observed measurement errors were associated with faster movements of a catheter. Bronchoscope redesign option is proposed to improve catheter shift measurement accuracy. The results of this study demonstrate that application of image analysis techniques to data recorded during bronchoscopy examination can at least support the existing navigation methods for peripheral bronchoscopy with respect to the determination of the location of the catheter distal tip within the lumen of the pulmonary airways.",
     "keywords": ["Peripheral bronchoscopy", "Tracking", "Video analysis"]},
    {"article name": "Computer assisted classification framework for prediction of acute lymphoblastic and acute myeloblastic leukemia",
     "doi": "https://doi.org/10.1016/j.bbe.2017.07.003",
     "publication date": "01-2017",
     "abstract": "Hematological malignancies i.e. acute lymphoid leukemia and acute myeloid leukemia are the types of blood cancer that can affect blood, bone marrow, lymphatic system and are the major contributors to cancer deaths. In present work, an attempt has been made to design a CAC (computer aided classification system) for diagnosis of myeloid and lymphoid cells and their FAB (French, American, and British) characterization. The proposed technique improves the AML and ALL diagnostic accuracy by analyzing color, morphological and textural features from the blood image using image processing and to assist in the development of a computer-aided screening of AML and ALL. This paper endeavors at proposing a quantitative microscopic approach toward the discrimination of malignant from normal in stained blood smear. The proposed technique firstly segments the nucleus from the leukocyte cell background and then computes features for each segmented nucleus. A total of 331 geometrical, chromatic and texture features are computed. A genetic algorithm using support vector machine (SVM) classifier is used to optimize the feature space. Based on optimized feature space, an SVM classifier with various kernel functions is used to eradicate noisy objects like overlapped cells, stain fragments, and other kinds of background noises. The significance of the proposed method is tested using 331 features on 420 microscopic blood images acquired from the online repository provided by the American society of hematology. The results confirmed the viability or potential of using a computer aided classification method to reinstate the monotonous and the reader-dependent diagnostic methods.",
     "keywords": ["Acute leukemia", "Texture features", "Color features", "Geometric features", "Genetic algorithm", "SVM"]},
    {"article name": "Fractal analysis of the grey and binary images in diagnosis of Hashimoto's thyroiditis",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.004",
     "publication date": "01-2017",
     "abstract": "In the study, a fractal analysis of thyroid ultrasound images was applied. This method has not been too often used for testing such kind of images so far. Its advantage is a tool in a form of a fractal dimension, which easily quantifies a complexity of an image texture surface. There is a close relationship between the lesions and an ultrasound image texture in a case of a diffuse form of the Hashimoto's disease. As a result of the analysis, a set of nine fractal descriptors was obtained which made it possible to distinguish healthy cases from sick ones that suffer from the diffuse form of the Hashimoto's thyroiditis. The Hellwig's method for feature selection was utilised. It found the combinations of features of the highest value of the information capacity index. These combinations were applied to build and test five popular classifiers. The following methods were implemented: decision tree, random forests, K-nearest neighbours, linear and quadratic discriminant analysis. The best results were achieved with a combination of three descriptors – fractal dimension and intercept obtained by the power spectral density method and fractal dimension estimated by the box counting method. The LDA (linear discriminant analysis) classifier based on them was characterised by a sensitivity of 96.88%, a specificity at a level of 98.44%, and its overall classification accuracy was equal to 97.66%. These results are similar to the best results of other authors cited in the work where the greyscale image analysis was used.",
     "keywords": ["Fractal analysis", "Hashimoto's thyroiditis", "Thyroid ultrasound"]},
    {"article name": "Lumped models of the cardiovascular system of various complexity",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.001",
     "publication date": "01-2017",
     "abstract": "The main objective is to accelerate the mathematical modeling of complex systems and offer the researchers an accessible and standardized platform for model sharing and reusing.We describe a methodology for creating mathematical lumped models, decomposing a system into basic components represented by elementary physical laws and relationships expressed as equations. Our approach is based on Modelica, an object-oriented, equation-based, visual, non-proprietary modeling language, together with Physiolibrary, an open-source library for the domain of physiology.We demonstrate this methodology on an open implementation of a range of simple to complex cardiovascular models, with great complexity variance (simulation time from several seconds to hours). The parts of different complexity could be combined together.Thanks to the equation-based nature of Modelica, a hierarchy of subsystems can be built with an appropriate connecting component. Such a structural model follows the concept of the system rather than the computational order. Such a model representation retains structural knowledge, which is important for e.g., model maintainability and reusability of the components and multidisciplinary cooperation with domain experts not familiar with modeling methods.",
     "keywords": ["Modelica", "Modeling methodology", "Cardiovascular modeling", "Lumped model"]},
    {"article name": "Application of MODWT and log-normal distribution model for automatic epilepsy identification",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.003",
     "publication date": "01-2017",
     "abstract": "In this paper, a novel approach based on the maximal overlap discrete wavelet transform (MODWT) and log-normal distribution (LND) model was proposed for identifying epileptic seizures from electroencephalogram (EEG) signals. To carry out this study, we explored the potentials of MODWT to decompose the signals into time-frequency sub-bands till sixth level. And demodulation analysis (DA) was investigated to reveal the subtle envelope information from the sub-bands. All obtained coefficients were then used to calculate LDN features, scale parameter (σ) and shape parameter (μ), which were fed to a random forest classifier (RFC) for classification. Besides, some experiments have been conducted to evaluate the performance of proposed model in the consideration of various wavelet functions as well as feature extractors. The implementation results demonstrated that our proposed technique has yielded remarkable classification performance for all the concerned problems and outperformed the reported methods in terms of the universality. The major finding of this research is that the proposed technique was capable of classifying EEG segments with satisfied accuracy and clinically acceptable computational time. These advantages have make our technique an attractive diagnostic and monitoring tool, which helps doctors in providing better and timely care for the patients.",
     "keywords": ["EEG", "MODWT", "Log-normal distribution", "Random forest classifier"]},
    {"article name": "Cardiac arrhythmia classification using the phase space sorted by Poincare sections",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.005",
     "publication date": "01-2017",
     "abstract": "Many methods for automatic heartbeat classification have been applied and reported in literature, but methods, which used the basin geometry of quasi-periodic oscillations of electrocardiogram (ECG) signal in the phase space for classifying cardiac arrhythmias, frequently extracted a limited amount of information of this geometry. Therefore, in this study, we proposed a novel technique based on Poincare section to quantify the basin of quasi-periodic oscillations, which can fill the mentioned gap to some extent. For this purpose, we first reconstructed the two-dimensional phase space of ECG signal. Then, we sorted this space using the Poincare sections in different angles. Finally, we evaluated the geometric features extracted from the sorted spaces of five heartbeat groups recommend by the association for the advancement of medical instrumentation (AAMI) by using the sequential forward selection (SFS) algorithm. The results of this algorithm indicated that a combination of nine features extracted from the sorted phase space along with per and post instantaneous heart rate could significantly separate the five heartbeat groups (99.23% and 96.07% for training and testing sets, respectively). Comparing these results with the results of earlier work also indicated that our proposed method had a figure of merit (FOM) about 32.12%. Therefore, this new technique not only can quantify the basin geometry of quasi-periodic oscillations of ECG signal in the phase space, but also its output can improve the performance of detection systems developed for the cardiac arrhythmias, especially in the five heartbeat groups recommend by the AAMI.",
     "keywords": ["Phase space", "Poincare section", "ECG", "Cardiac arrhythmia"]},
    {"article name": "Human gait pattern changes detection system: A multimodal vision-based and novelty detection learning approach",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.002",
     "publication date": "01-2017",
     "abstract": "This paper proposes a novel gait rehabilitation analysis system, based on an innovative multimodal vision-based sensor setup, focused on detecting gait pattern changes over time. The proposed setup is based on inexpensive technologies, without compromising performance, and was designed to be deployed on walkers, which are a typical assistive aid used in gait rehabilitation. In the medical field the evaluation of a patient's rehabilitation progress is typically performed by a medical professional through subjective techniques based on the professional's visual perception and experience. In this context, we are proposing an automatic system to detect the progress of patients undergoing rehabilitation therapy. Our approach is able to perform novelty detection for gait pattern classification based on One-Class Support Vector Machines (OC-SVM). Using point-cloud and RGB-D data, we detect the lower limbs (waist, legs and feet) by using Weighted Kernel-Density Estimation and Weighted Least-Squares to segment the legs into several parts (thighs and shins), and by fitting 3D ellipsoids to model them. Feet are detected using k-means clustering and a Circular Hough Transform. A temporal analysis of the feet's depth is also performed to detect heel strike events. Spatiotemporal and kinematic features are extracted from the lower limbs’ model and fed to a classifier based on the fusion of several OC-SVMs. Experiments with volunteers using the robotic walker platform ISR-AIWALKER, where the proposed system was deployed, revealed a lower limbs tracking accuracy of 3° and that our novelty detection approach successfully identified novel gait patterns, evidencing an overall 97.89% sensitivity.",
     "keywords": ["Gait analysis", "Lower limbs rehabilitation", "Robotic walker", "Novelty detection"]},
    {"article name": "Fully automatic ROI extraction and edge-based segmentation of radius and ulna bones from hand radiographs",
     "doi": "https://doi.org/10.1016/j.bbe.2017.07.004",
     "publication date": "01-2017",
     "abstract": "Bone age is a reliable measure of person's growth and maturation of skeleton. The difference between chronological age and bone age indicates presence of endocrinological problems. The automated bone age assessment system (ABAA) based on Tanner and Whitehouse method (TW3) requires monitoring the growth of radius, ulna and short bones (phalanges) of left hand. In this paper, a detailed analysis of two bones in the bone age assessment system namely, radius and ulna is presented. We propose an automatic extraction method for the region of interest (ROI) of radius and ulna bones from a left hand radiograph (RUROI). We also propose an improved edge-based segmentation technique for those bones. Quantitative and qualitative results of the proposed segmentation technique are evaluated and compared with other state-of-the-art segmentation techniques. Medical experts have also validated the qualitative results of proposed segmentation technique. Experimental results reveal that these proposed techniques provide better segmentation accuracy as compared to the other state-of-the-art segmentation techniques.",
     "keywords": ["Automated bone age assessment", "Extraction of radius and ulna bones (RUROI)", "Hand bone segmentation", "Mathematical morphology", "Edge-based segmentation"]},
    {"article name": "The effect of zinc oxide doping on mechanical and biological properties of 3D printed calcium sulfate based scaffolds",
     "doi": "https://doi.org/10.1016/j.bbe.2017.08.007",
     "publication date": "01-2017",
     "abstract": "Fabrication of defect-matching scaffolds is the most critical step in bone tissue engineering. Three-dimensional (3D) printing is a promising technique for custom design scaffold fabrication due to the high controllability and design independency. The objective of this study is to investigate the effect of zinc oxide (ZnO) doping on mechanical and biological characteristics of 3D printed (3DP) calcium sulfate hemihydrate (CSHH) scaffolds. Crystalline phases, wettability, compressive strength and Young's modulus, human bone marrow derived mesenchymal stem cells (hMSCs) attachment, proliferation and morphology were investigated. XRD results showed that CSHH powder transformed into gypsum after the printing process due to the water content of binder. Contact angle measurements indicated that ZnO doped CSHH scaffolds have hydrophilic character, which stimulates cell attachment. The mechanical and cell culture studies demonstrated that increasing the ZnO doping concentration both mechanical strength and cell proliferation on CSHH scaffolds were enhanced.",
     "keywords": ["3D printing", "Bone tissue engineering", "Calcium sulfate hemihydrate", "Zinc oxide", "Mechanical properties"]},
    {"article name": "A retinal image authentication framework based on a graph-based representation algorithm in a two-stage matching structure",
     "doi": "https://doi.org/10.1016/j.bbe.2017.09.001",
     "publication date": "01-2017",
     "abstract": "Retinal vascular pattern has many valuable characteristics such as uniqueness, stability and permanence as a basis for human authentication in security applications. This paper presents an automatic rotation-invariant retinal authentication framework based on a novel graph-based retinal representation scheme. In the proposed framework, to replace the retinal image with a relational mathematical graph (RMG), we propose a novel RMG definition algorithm from the corresponding blood vessel pattern of the retinal image. Then, the unique features of RMG are extracted to supplement the authentication process in our framework. The authentication process is carried out in a two-stage matching structure. In the first stage of this scenario, the defined RMG of enquiry image is authenticated with enrolled RMGs in the database based on isomorphism theory. If the defined RMG of enquiry image is not isomorphic with none enrolled RMG in the database, in the second stage of our matching structure, the authentication is performed based on the extracted features from the defined RMG by a similarity-based matching scheme. The proposed graph-based authentication framework is evaluated on VARIA database and accuracy rate of 97.14% with false accept ratio of zero and false reject ratio of 2.85% are obtained. The experimental results show that the proposed authentication framework provides the rotation invariant, multi resolution and optimized features with low computational complexity for the retina-based authentication application.",
     "keywords": ["Human authentication", "Retinal image", "Relational mathematical graph", "Two-stage matching structure", "Isomorphism"]},
    {"article name": "Physical activity recognition by smartphones, a survey",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.004",
     "publication date": "01-2017",
     "abstract": "Human activity recognition (HAR) from wearable motion sensor data is a promising research field due to its applications in healthcare, athletics, lifestyle monitoring, and computer–human interaction. Smartphones are an obvious platform for the deployment of HAR algorithms. This paper provides an overview of the state-of-the-art when it comes to the following aspects: relevant signals, data capture and preprocessing, ways to deal with unknown on-body locations and orientations, selecting the right features, activity models and classifiers, metrics for quantifying activity execution, and ways to evaluate usability of a HAR system. The survey covers detection of repetitive activities, postures, falls, and inactivity.",
     "keywords": ["Accelerometer", "Gyroscope", "Activity recognition", "Smartphone"]},
    {"article name": "The autonomic nervous system and cancer",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.001",
     "publication date": "01-2017",
     "abstract": "Recent data have demonstrated extensive autonomic nervous system (ANS) neural participation in malignant tumors and infiltration of nerve fibers in and around malignant tumors. ANS cybernetic imbalances deriving from central nervous system (CNS) stress are associated with poorer patient outcome and may play a key role in tumor expansion. The ANS modulates and can destabilize tissue stem cells, and it drives the expression of neurotransmitter receptors on tumor cells. Disruption of tumor innervation and pharmacological ANS blockade have abrogated cancer growth in preclinical models.The present review interprets recent key findings with respect to the ANS and cancer. We highlight new data from animal models addressing specific cancers suggesting that unbalanced autonomic cybernetic control loops are associated with tissue instability which in turn promotes, (1) cancer stem cell based tumor initiation and growth, and (2) metastasis. We posit that identifying the sources of neural control loop dysregulation in specific tumors may reveal potential targets for antitumor therapy. Given the striking tumor regression results obtained with gastric vagotomy in gastric cancer models, and the effects of β-adrenergic blockade in pancreatic tumor models, it may be feasible to improve cancer outcomes with therapeutics targeted to the nervous system.",
     "keywords": ["Autonomic diseases", "Oncology", "Control theory", "Negative feedback loop", "Stem cell", "Cybernetics"]},
    {"article name": "Non-uniform viscosity caused by red blood cell aggregation may affect NO concentration in the microvasculature",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.004",
     "publication date": "01-2017",
     "abstract": "Aggregation of red blood cells in the micro vasculature may affect blood viscosity in the vessel. The purpose of this study was to investigate the potential effect of non-uniform viscosity caused by red blood cell (RBC) aggregation on nitric oxide (NO) concentration and distribution. A 3-D multi-physics model was established to simulate the production, transport and consumption of NO. Two non-uniform viscosity models caused by RBC aggregation were investigated: one assuming a linear and the other a step hematocrit distribution. In addition, the effect of the thickness of the plasma layer was tested. Simulation results demonstrate that non-uniform viscosity caused by RBCs aggregation influences NO concentration distribution. Compared with the uniform viscosity model, NO concentration using non-uniform viscosity is lower than that using uniform viscosity. Moreover, NO concentration calculated from the step hematocrit model is higher than that calculated from the linear hematocrit model. NO concentrations in the endothelium and the vascular wall decrease with the decline of the thickness of the plasma layer. The relative decrease differs between the linear and the step model. Our results suggest that non-uniform viscosity caused by red blood cell aggregation affects nitric oxide distribution in the micro vasculature. If uniform viscosity is assumed when performing numerical simulations, NO concentration values may be overestimated.",
     "keywords": ["Nitric oxide (NO)", "Microvasculature", "Viscosity", "Numerical simulation"]},
    {"article name": "Magnetic navigation and tracking of multiple ferromagnetic microrobots inside an arterial phantom setup for MRI guided drug therapy",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.002",
     "publication date": "01-2017",
     "abstract": "Magnetic steering of ferromagnetic microrobots facilitates active drug targeting and minimally invasive treatment of deep seated tumour cells. Several techniques for magnetic steering of nanostructured single microrobot in human vasculature exist but literatures on multirobot navigation are scarce. In the current work, preliminary experimental validation of a novel magnetic navigation model for multiple ferromagnetic microrobots is performed inside a bifurcated arterial phantom apparatus. The proposed model includes the formation of a single linear assembly of ferromagnetic microrobots inside the arterial setup placed under a magnetic field. This field is intended to mimic the magnetic field generated by a Magnetic Resonance Imaging (MRI) device which finds application in targeted drug therapy. The linear assembly process was studied with the help of Newtonian dynamics simulation including dipole–dipole and near field forces. As, the assembly was found to be structurally intact in a pulsatile flow, its simulated trajectory was controlled by manipulating a single microrobot present in the middle of the assembly. The trajectory convergence algorithm used for this purpose includes a fuzzy logic based nonlinear “Proportional-Integral-Derivative” (PID) control scheme with magnetic field gradient as its control input. Since most of the modern MRI devices are based on PID controller for manipulation of magnetic gradients, the proposed fuzzy PID based control scheme can easily be interfaced with these devices for the intended application.",
     "keywords": ["Multiple microrobots", "Newtonian dynamics", "Magnetic navigation"]},
    {"article name": "Ensemble of classifiers and wavelet transformation for improved recognition of Fuhrman grading in clear-cell renal carcinoma",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.005",
     "publication date": "01-2017",
     "abstract": "The paper presents an improved system to recognition of Fuhrman grading in clear-cell renal carcinoma using an ensemble of classifiers. The novelty of solution includes the segmentation applying wavelet transformation in preprocessing stage, application of few selection methods for feature generation and using the ensemble of classifiers in final recognition step. The wavelet transformation is a very efficient tool for image de-noising and enhancing the edges of cell nuclei. The important distinction to other approaches is that diagnostic features of nuclei, based on the texture, geometry, color and histogram, are selected by using few methods, each relying on different mechanism of selection. These different sets of features have enabled creating the ensemble of classifiers based on the support vector machine and random forest, both cooperating with them. Such approach has led to the significant increase of the quality factors in comparison to the best existing results: sensitivity (the average of this solution 94.3% compared to 91.5%) and specificity (the average 98.6% compared to 97.5%.",
     "keywords": ["Ensemble of classifiers", "Feature selection", "Fuhrman grading", "Wavelets", "SVM", "Random forest"]},
    {"article name": "Spatial and spatio-temporal filtering based on common spatial patterns and Max-SNR for detection of P300 component",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.001",
     "publication date": "01-2017",
     "abstract": "Recent advances in brain-computer interfaces (BCIs) have developed a new arena for designing systems to help disabled persons to communicate with the surrounding environment. P300 speller is one of the most famous BCI systems choosing the characters from a virtual keyboard through the analysis of EEG signals. P300 detection is an important processing step of these systems. The accuracy of P300 detection highly depends on the feature extraction method. In this study, the maximum signal to noise ratio (Max-SNR) has been used for feature extraction, which rarely applied in this area. This study presents a novel feature extraction technique, named spatio-temporal Max-SNR (ST.Max-SNR). Unlike the standard Max-SNR which only uses spatial patterns of a signal, the proposed method, separately consider the spatial and temporal patterns of the signal to enhance the accuracy of feature extraction. Due to the similarity of the common spatial pattern (CSP) and the Max-SNR algorithms, the performance of this technique and its extension, common Spatio-temporal pattern (CSTP), has been compared with the proposed method. Then, the LDA and SWLDA classifiers are used for classification of the features. Our experimental results show that the Max-SNR based spatio-temporal features lead to an average classification accuracy of 94.4 percent suggesting the best performance.",
     "keywords": ["BCI systems", "Common spatial pattern (CSP)", "Max-SNR", "P300 component"]},
    {"article name": "In-silico evaluation of left ventricular unloading under varying speed continuous flow left ventricular assist device support",
     "doi": "https://doi.org/10.1016/j.bbe.2017.03.003",
     "publication date": "01-2017",
     "abstract": "Continuous flow left ventricular assist device (cf-LVAD) operating speed modulation techniques are proposed to achieve different purposes such as improving arterial pulsatility, aortic valve function or ventricular unloading etc. Although it is possible to improve the left ventricular unloading by modulating the operating speed of a cf-LVAD, it is still unclear what type of pump operating mode should be applied to generate a better left ventricular unloading. This study presents a comparison of different heart pump support modes including constant speed support, copulsative and counterpulsative direct cf-LVAD speed modulation and pump flow rate control to regulate the cf-LVAD operating speed. The simulations were performed using a cardiovascular system model, which consists of active left atrium and ventricle, mitral and aortic valve leaflets, circulatory loop and a cf-LVAD. The cf-LVAD was operated between 7500 rpm and 12,500 rpm with 1000 rpm intervals to simulate constant speed support. The same mean pump operating speeds over a cardiac cycle were applied in the direct operating speed modulation for the copulsative and counterpulsative direct speed modulation cf-LVAD support as in the constant speed support while the same pump-output over a cardiac cycle was applied to drive the pump in flow rate controlled copulsative and counterpulsative cf-LVAD support modes as in the constant speed support. Simulation results show that flow rate controlled counterpulsative pump support mode generates lower end-diastolic left ventricular volume and pressure–volume loop area while generating more physiological left ventricular volume signals over a cardiac cycle with respect to the other pump operating modes.",
     "keywords": ["Left ventricular unloading", "cf-LVAD", "Flow-rate control"]},
    {"article name": "Artifacts removal from EEG signal: FLM optimization-based learning algorithm for neural network-enhanced adaptive filtering",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.003",
     "publication date": "01-2017",
     "abstract": "Electroencephalogram (EEG) denotes a neurophysiologic measurement, which observes the electrical activity of the brain through making a record of the EEG signal from the electrodes positioned on the scalp. The EEG signal gets mixed with other biological signals, called artifacts. Few artifacts include electromyogram (EMG), electrocardiogram (ECG) and electrooculogram (EOG). Removal of artifacts from the EEG signal poses a great challenge in the medical field. Hence, the FLM (Firefly + Levenberg Marquardt) optimization-based learning algorithm for neural network-enhanced adaptive filtering model is introduced to eliminate the artifacts from the EEG. Initially, the EEG signal was provided to the adaptive filter for yielding the optimal weights using the renowned optimization algorithms, called firefly algorithm and LM. These two algorithms are effectively hybridized and applied to the neural network to find the optimal weights for adaptive filtering. Then, the designed filtering process renders an improved system for artifacts removal from the EEG signal. Finally, the performance of the proposed model and the existing models regarding SNR, computation time, MSE and RMSE are analyzed. The results conclude that the proposed method achieves a high SNR of 42.042 dB.",
     "keywords": ["Electroencephalogram", "Levenberg Marquardt algorithm", "Firefly algorithm", "Artifacts signal", "Signal to noise ratio"]},
    {"article name": "Fast, accurate and robust retinal vessel segmentation system",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.001",
     "publication date": "01-2017",
     "abstract": "The accurate segmentation of the retinal vessel tree has become the prerequisite step for automatic ophthalmological and cardiovascular diagnosis systems. Aside from accuracy, robustness and processing speed are also considered crucial for medical purposes. In order to meet those requirements, this work presents a novel approach to extract blood vessels from the retinal fundus, by using morphology-based global thresholding to draw the retinal venule structure and centerline detection method for capillaries. The proposed system is tested on DRIVE and STARE databases and has an average accuracy of 95.88% for single-database test and 95.27% for the cross-database test. Meanwhile, the system is designed to minimize the computing complexity and processes multiple independent procedures in parallel, thus having an execution time of 1.677 s per image on CPU platform.",
     "keywords": ["Retinal images", "Vessel segmentation", "Morphological processing", "DoOG filter", "Automated analysis", "Thresholding"]},
    {"article name": "Multi-objective binary DE algorithm for optimizing the performance of Devanagari script-based P300 speller",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.006",
     "publication date": "01-2017",
     "abstract": "P300 speller-based brain-computer interface (BCI) allows a person to communicate with a computer using only brain signals. In order to achieve better reliability and user continence, it is desirable to have a system capable of providing accurate classification with as few EEG channels as possible. This article proposes an approach based on multi-objective binary differential evolution (MOBDE) algorithm to optimize the system accuracy and number of EEG channels used for classification. The algorithm on convergence provides a set of pareto-optimal solutions by solving the trade-off between the classification accuracy and the number of channels for Devanagari script (DS)-based P300 speller system. The proposed method is evaluated on EEG data acquired from 9 subjects using a 64 channel EEG acquisition device. The statistical analysis carried out in the article, suggests that the proposed method not only increases the classification accuracy but also increases the over-all system reliability in terms of improved user-convenience and information transfer rate (ITR) by reducing the EEG channels. It was also revealed that the proposed system with only 16 channels was able to achieve higher classification accuracy than a system which uses all 64 channel's data for feature extraction and classification.",
     "keywords": ["BCI", "Devanagari", "Multi-objective Optimization", "Binary DE", "P300-speller", "SVM"]},
    {"article name": "A new computer-based approach for fully automated segmentation of knee meniscus from magnetic resonance images",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.008",
     "publication date": "01-2017",
     "abstract": "Menisci are tissues that enable mobility and absorb excess loads on the knee. Problems in meniscus can trigger the disorder of osteoarthritis (OA). OA is one of the most common causes of disability, especially among young athlethes and elderly people. Therefore, the early diagnosis and treatment of abnormalities that occur in the meniscus are of significant importance. This study proposes a new computer-based and fully automated approach to support radiologists by: (i) the segmentation of medial menisci, (ii) enabling early diagnosis and treatment, and (iii) reducing the errors caused by MR intra-reader variability. In this study, 88 different MR images provided by the Osteoarthritis Initiative (OAI) are used. The histogram of oriented gradients (HOG) and local binary patterns (LBP) methods are used for feature extraction from these MR images along with the extreme learning machine (ELM) and random forests (RF) methods which are used for model learning (regression). As the first step of the pipeline, the most compact rectangular patches bounding the menisci are located. After this, meniscus boundaries are revealed by the morphological processes. Then, the similarities between these boundaries and the ground truth images are measured and compared with each other. The highest score is acquired with Dice similarity measurement with a success rate of 82%. A successful segmentation is performed on the diseased knee MR images. The proposed approach can be implemented as a decision support system for radiologists, while the segmented menisci can be used in classification of meniscal tear in future studies.",
     "keywords": ["Segmentation", "Knee-joint", "Meniscus", "Regression", "Morphological-operations", "Medical-images"]},
    {"article name": "ECG signals reconstruction in subbands for noise suppression",
     "doi": "https://doi.org/10.1016/j.bbe.2017.03.002",
     "publication date": "01-2017",
     "abstract": "In this study, we propose a combination of two methods for ECG noise suppression. The first one is the robust principal component analysis, applied to QRS complexes reconstruction. The second is the method of weighted averaging of nonlinearly aligned signal cycles. The novelty of the approach consists in the way these methods are combined. First, a processed ECG signal is decomposed into three spectral subbands, of high, medium and low frequency. Then both methods are applied in such a way that their operation is prevented from the most common unfavorable factors. RPCA reconstructs QRS complexes in a medium and high frequency subbands added. This makes the method more immune to low frequency artifacts that can be caused by electrodes motion. Dynamic time-warping is performed on the medium frequency subband which again prevents the procedure from the unfavorable influence of electrode motion artifacts. After the warping paths have been determined, the weighted addition of nonlinearly aligned signal cycles is executed, separately in the three subbands, with optimal weights estimated in each subband. Finally, by the appropriate addition of the obtained signals, the whole spectrum ECG is reconstructed.In the experimental section, the method was investigated with the use of real and artificially generated signals. In both cases, it allowed for effective suppression of noise, preserving important features of the processed signals. When it was applied to ECG enhancement prior to determination of the QT interval, the measurements appeared to be remarkably immune to different types of noise.",
     "keywords": ["ECG reconstruction", "Noise suppression", "QT interval"]},
    {"article name": "Robust and accurate optic disk localization using vessel symmetry line measure in fundus images",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.008",
     "publication date": "01-2017",
     "abstract": "Accurate optic disk (OD) localization is an important step in fundus image based computer-aided diagnosis of glaucoma and diabetic retinopathy. Robust OD localization becomes more challenging with the presence of common pathological variations which could alter its overall appearance. This paper presents a novel OD localization method by incorporating salient visual cues of retinal vasculature: (1) global vessel symmetry, (2) vessel component count and (3) local vessel symmetry inside OD region. In the proposed method, a new vessel symmetry line (VSL) measure is designed to demarcate the lines that divide the retinal vasculature into approximately similar halves. The initial OD center location is computed using the highest number of major blood vessel components in the skeleton image. The final OD center localization involves an iterative center of mass computation to exploit the local vessel symmetry in the OD region of interest. The proposed method shows effectiveness in diseased retinas having diverse symptoms like bright lesions, hemorrhages, and tortuous vessels that create potential ambiguity for OD localization. A total of ten publicly available retinal image databases are considered for extensive evaluation of the proposed method. The experimental results demonstrate high average OD detection accuracy of 99.49%, while achieving state-of-the-art OD localization error in all databases.",
     "keywords": ["Optic disk localization", "Symmetry", "Glaucoma", "Diabetic retinopathy", "Computer-aided diagnosis"]},
    {"article name": "A multi-layered incremental feature selection algorithm for adjuvant chemotherapy effectiveness/futileness assessment in non-small cell lung cancer",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.002",
     "publication date": "01-2017",
     "abstract": "Non-small cell lung cancer (NSCLC) is the most common type of lung cancer; and is one of the leading causes of death in the world. Surgery combined with chemotherapy is the recommended treatment for NSCLC. Since chemotherapy is an expensive treatment for either medical staff or patients suffering from pain, this study attempts to construct an intelligent predictive model to predict the adjuvant chemotherapy (ACT) effectiveness/futileness in the patients, in order to help futile cases for unnecessary applications. There is a 2-step method: preprocessing and predicting. First a purposefully preprocessing technique: chi-square test, SVM-RFE and correlation matrix, were employed in NSCLC gene expression dataset as a novel multi-layered feature selection method to defeat the curse of dimension and detect the chemotherapy target genes from tens of thousands features, based on which the patients can be classified into two groups, with NB classifier at second step. 10-Fold cross-validation was found with accuracy of 68.93% for 2 genes, TGFA (205015_s_at) and SEMA6C (208100_x_at), which is preferable compared to earlier studies, even though more than 2 input features are employed for the prediction. According to the results found in this study, one can concludes that the multi-layered feature selection approach has increased the classification accuracy in terms of finding the fitted patient for receiving ACT by reducing the number of features and has significant power to be used in medical datasets with small train samples and large number of features.",
     "keywords": ["Gene expression", "Na\u00efve Bayes", "Correlation", "Feature selection", "Classification", "Chemotherapy"]},
    {"article name": "An objective method to identify optimum clip-limit and histogram specification of contrast limited adaptive histogram equalization for MR images",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.006",
     "publication date": "01-2017",
     "abstract": "In contrast limited adaptive histogram equalization (CLAHE), the selection of tile size, clip-limit and the distribution which specify desired shape of the histogram of image tiles is paramount, as it critically influences the quality of the enhanced image. The optimal value of these parameters devolves on the generic of the image to be enhanced and usually they are selected empirically. In this paper, the degradation of intensity, textural and geometric features of the medical image with respect to the variation in clip-limit and specified histogram shape is analyzed. The statistical indices used to quantify the feature degradation are Absolute Mean Brightness Error (AMBE), Absolute Deviation in Entropy (ADE), Peak Signal to Noise Ratio (PSNR), Variance Ratio (VR), Structural Similarity Index Matrix (SSIM) and Saturation Evaluation Index (SEI). The images used for the analysis are axial plane MR images of magnetic resonance spectroscopy (MRS), under gradient recalled echo (GRE), diffusion weighted imaging (DWI) 1000b Array Spatial Sensitivity Encoding Technique (ASSET), T2 Fluid Attenuation Inversion Recovery (FLAIR) and T1 Fast Spin-Echo Contrast Enhanced (FS-ECE) series of pre-operative Glioblastoma-edema complex. The experimental analysis was performed using Matlab®. Results show that for MR images the exponential histogram specification with a clip-limit of 0.01 is found to be optimum. At optimum clip-limit, the mean of SSIM exhibited by the Rayleigh, uniform and exponential histogram specification were found to be 0.7477, 0.7946 and 0.8457, for ten sets of MR images and mean of variance ratio are 1.242, 2.0316 and 1.7711, respectively.",
     "keywords": ["Absolute deviation in entropy", "Absolute Mean Brightness Error", "Clip-limit", "Tile-size", "Peak signal to noise ratio", "Saturation Evaluation Index"]},
    {"article name": "Development of a real time emotion classifier based on evoked EEG",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.004",
     "publication date": "01-2017",
     "abstract": "Our quality of life is more dependent on our emotions than on physical comforts alone. This is motivation enough to classify emotions using Electroencephalogram (EEG) signals. This paper describes the acquisition of evoked EEG signals for classification of emotions into four quadrants. The EEG signals have been collected from 24 subjects on three electrodes (Fz, Cz and Pz) along the central line. The absolute and differential attributes of single trial ERPs have been used to classify emotions. The single trial ERP attributes collected from each electrode have been used for developing an emotion classifier for each subject. The accuracy of classification of emotions into four classes lies between 62.5–83.3% for single trials. The subject independent analysis has been done using absolute and differential attributes of single trial signals of ERP. An overall accuracy of 55% has been obtained on Fz electrode for multi subject trials. The methodology used to classify emotions by fixing the attributes for classification of emotions brings us a step closer to developing a real time emotion recognition system with benefits including applications like Brain-Computer Interface for locked-in subjects, emotion classification for highly sensitive jobs like fighter pilots etc.",
     "keywords": ["Electroencephalogram", "Brain\u2013computer interface", "Emotion", "ERP", "Differential ERP"]},
    {"article name": "Improving the accuracy of detecting steroid abuse in cattle by pairwise learning of serum samples",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.009",
     "publication date": "01-2017",
     "abstract": "Issues surrounding the misuse of illegal drugs in animals destined for food production have be an enormous challenge to regulatory authorities charged with enforcing their control. A method has been proposed recently which compared the bovine blood biochemistry profiles between control and treated animals, using the support vector machine (SVM) as the classification tool. Whether an animal has been treated is determined by the classification outcome of the SVM on an individual serum sample taken off the animal. However, the acquisition time of the serum sample is essential in the classification performance of the SVM. Thus, the paper proposed to collect and analyze a pair of samples, in order to obtain at least one sample whose acquisition time resulted in an SVM with the highest sensitivity. The power of the strategy in improving sensitivity was theoretically proven to be up to 0.25 and empirically confirmed on a bovine blood biochemistry data. Furthermore, classification rules of the SVM were proposed to be adapted to meet higher levels of demands on sensitivity. Schemes were described which optimized the time apart between the collection of the two samples and the impact of the proposed strategy on specificity was also investigated.",
     "keywords": ["Support vector machine", "Steroid abuse", "Screening methods"]},
    {"article name": "A description of hand matrices to extract various characteristics of human hand in three-dimensional space",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.003",
     "publication date": "01-2017",
     "abstract": "This study focuses on a description of hand matrices to extract various characteristics of human hand in three-dimensional space. A mathematical expression for human hand has scarcely been proposed so far, and the practical, versatile description has been required to analyze a gesture behavior in detail. In this study, the bones and joints of human hand were explained supplementarily. After that, a CG model of human hand was created according to the anatomical structure. With reference to the model's structure, hand matrices were proposed to investigate poses, positions, and postural orientations of human hand in a uniform manner. The several examples were also discussed with appropriate illustrations. As a result, the characteristics of hand matrices were revealed in practically-possible cases; moreover, the mathematical treatments were theoretically versatile and simple to find a difference or common feature of hand motion in three-dimensional space.",
     "keywords": ["Human hand", "Gesture", "Matrix description", "CG model", "Feature extraction"]},
    {"article name": "Blood flows in end-to-end arteriovenous fistulas: Unsteady and steady state numerical investigations of three patient-specific cases",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.006",
     "publication date": "01-2017",
     "abstract": "The arterio-venous fistula is a widely accepted vascular access for haemodialysis - a treatment for the end-stage renal disease. However, a significant number of complications (stenoses, thromboses, aneurysms) of fistulas can occur, which are related to the geometry of the anastomosis and the local abnormal hemodynamics. Local flow conditions, in particular the wall shear stress (WSS), are thought to affect sensitive endothelial cells on the inner vessel wall, which leads to intimal hyperplasia. This study presents the results obtained from numerical simulations of the blood flow through three patient-specific end-to-end fistulas which were assessed to be more likely dysfunctional than the end-to side ones. Unsteady and comparative steady-state simulations of blood flow were performed in ANSYS CFX. The obtained results show behaviour of the blood, velocity fields, shear strain, vorticity range, blood viscosity changes, a WSS distribution on vessel walls and give information about the flow rate in the veins receiving blood from fistulas. Blood flow animations are attached to the online version of the paper. Numerical methods seem to be the only opportunity to provide complete information on the distribution and range of the WSS for complicated shapes of blood vessels used to fistula creation, however the WSS is strongly dependent on the local geometry and mesh quality. High values of the shear strain, associated with elevated values of shear stress, found in each model, could increase a risk of haemolysis. High shear environment with raised vorticity can result in activation of platelets and further platelet aggregation and thrombosis.",
     "keywords": ["Anastomosis", "Fistula", "Thrombosis", "WSS", "Vascular access"]},
    {"article name": "Full-automatic computer aided system for stem cell clustering using content-based microscopic image analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2017.01.004",
     "publication date": "01-2017",
     "abstract": "Stem cells are very original cells that can differentiate into other cells, tissues and organs, which play a very important role in biomedical treatments. Because of the importance of stem cells, in this paper we propose a full-automatic computer aided clustering system to assist scientists to explore potential co-occurrence relations between the cell differentiation and their morphological information in phenotype. In this proposed system, a multi-stage Content-based Microscopic Image Analysis (CBMIA) framework is applied, including image segmentation, feature extraction, feature selection, feature fusion and clustering techniques. First, an Improved Supervised Normalized Cuts (ISNC) segmentation algorithm is newly introduced to partition multiple stem cells into individual regions in an original microscopic image, which is the most important contribution in this paper. Then, based on the segmented stem cells, 11 different feature extraction approaches are applied to represent the morphological characteristics of them. Thirdly, by analysing the robustness and stability of the extracted features, Hu and Zernike moments are selected. Fourthly, these two selected features are combined by an early fusion approach to further enhance the properties of the feature representation of stem cells. Finally, k-means clustering algorithm is chosen to classify stem cells into different categories using the fused feature. Furthermore, in order to prove the effectiveness and usefulness of this proposed system, we carry out a series of experiments to evaluate our methods. Especially, our ISNC segmentation obtains 92.4% similarity, 96.0% specificity and 107.8% ration of accuracy, showing the potential of our work.",
     "keywords": ["Stem cell", "Biomedical microscopic image", "Content-based Microscopic Image Analysis", "Image Segmentation", "Supervised Normalized Cuts", "Cell clustering"]},
    {"article name": "Investigation of opacity development in the human eye for estimation of the postmortem interval",
     "doi": "https://doi.org/10.1016/j.bbe.2017.02.001",
     "publication date": "01-2017",
     "abstract": "Estimation of the postmortem interval (PMI) has attracted the attention of many researchers. It is generally accepted as a challenging task in forensic medicine. Due to its difficulty, researchers have tried to estimate the PMI using different physical and chemical techniques. Since the PMI estimation accuracies of previous studies are not at the desired level, new methods should be developed to more accurately estimate the PMI. The development of opacity in the eye in the PMI might be an important breakthrough in this field. After death, corneal hydration occurs due to degenerated endothelial cells. The degenerated endothelial barrier of the cornea cannot prevent the flow of aqueous humor to the cornea, which results in opacity. The amount of aqueous humor in the cornea determines the level of opacity. Since the flow of aqueous humor to the cornea will continue for a while, opacity is expected to increase with the PMI. In this study, images of human eyes were investigated using computer-based image analysis. The corneal and non-corneal opacities of the recorded eye images increase during the experiment. The experimental results prove that there is a correlation between the elapsed time after death and the development of opacity in the corneal and non-corneal regions in human cases. Exponential curve fitting is employed to observe the decay of the opacity over time. A repeated ANOVA test is also used to show that the opacity development is statistically significant.",
     "keywords": ["Time of death estimation", "Forensic medicine", "Postmortem interval", "Corneal opacity", "Image feature extraction"]},
    {"article name": "An efficient wavelet-based automated R-peaks detection method using Hilbert transform",
     "doi": "https://doi.org/10.1016/j.bbe.2017.02.002",
     "publication date": "01-2017",
     "abstract": "Machine-aided detection of R-peaks is becoming a vital task to automate the diagnosis of critical cardiovascular ailments. R-peaks in Electrocardiogram (ECG) is one of the key segments for diagnosis of the cardiac disorder. By recognizing R-peaks, heart rate of the patient can be computed and from that point onwards heart rate variability (HRV), tachycardia, and bradycardia can also be determined. Most of the R-peaks detectors suffer due to non-stationary behaviors of the ECG signal. In this work, a wavelet transform based automated R-peaks detection method has been proposed. A wavelet-based multiresolution approach along with Shannon energy envelope estimator is utilized to eliminate the noises in ECG signal and enhance the QRS complexes. Then a Hilbert transform based peak finding logic is used to detect the R-peaks without employing any amplitude threshold. The efficiency of the proposed work is validated using all the ECG signals of MIT-BIH arrhythmia database, and it attains an average accuracy of 99.83%, sensitivity of 99.93%, positive predictivity of 99.91%, error rate of 0.17% and an average F-score of 0.9992. A close observation of the simulation and validation indicates that the suggested technique achieves superior performance indices compared to the existing methods for real ECG signal.",
     "keywords": ["Electrocardiogram (ECG)", "R-peak", "Wavelet transform", "Hilbert transform", "MIT-BIH database"]},
    {"article name": "Characterization of cardiac arrhythmias by variational mode decomposition technique",
     "doi": "https://doi.org/10.1016/j.bbe.2017.04.007",
     "publication date": "01-2017",
     "abstract": "Automatic detection of cardiac abnormalities in early stage is a popular area of research for decades. In this work a novel algorithm for detection of cardiac arrhythmia is proposed using variational mode decomposition (VMD). Arrhythmia is a crucial abnormality of heart in which the rhythmic disorder may lead to sudden cardiac arrest. Existing algorithms for arrhythmia detection are based on accuracy of detection of fiducial points, parameter selection and extraction, quality of classifier and other factors. Unlike other works, proposed method tries to characterize both atrial and ventricular arrhythmias simultaneously and independently from the segmented sections of the signal. VMD, being able to separate closely spaced frequencies, has a good potential to be useful to provide significant features in transformed domain. Unique feature combinations are also proposed to characterize different arrhythmic events.",
     "keywords": ["ECG", "Cardiac arrhythmia", "Ventricular mode decomposition (VMD)", "Centre frequency", "Characterization"]},
    {"article name": "Pure intrusion of a mandibular canine with segmented arch in lingual orthodontics: A numerical study with 3-dimensional finite element analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.005",
     "publication date": "01-2017",
     "abstract": "Approximately 50% patients with a deep bite possess anatomically extruded mandibular canines. The objective of this study was to specify the required toe (θ) of the vertical segment of a cantilever from the distal aspect to achieve pure intrusion of a mandibular canine with a segmented arch in lingual orthodontics. Additionally, the optimum magnitude of the required intrusive force by a cantilever was determined assuming non-linear, hyper-elastic behaviour of periodontal ligament (PDL).The geometrical model of a mandibular canine tooth was developed and the mathematical equation was devised to evaluate θ (positive value: toe-in, negative value: toe-out) based on certain input parameters. To verify this numerical study by finite element analysis (FEA), total eight different positions of point of force application (Pf) on bracket top (occlusal) surface were considered based on different values of input parameters.The results were displayed in terms of nature of tooth movement and Von-Mises (equivalent) stresses generated in the PDL. Additionally, the optimum magnitude of the required intrusive force within the biological limit of a mandibular canine was determined from FEA considering the strength of PDL and factor of safety.The numerical study was developed to compute the value of required toe angle (θ) of the vertical segment of a cantilever for different morphologies of a mandibular canine as well as different positions of Pf. From FEA, the optimum range of an intrusive force within the biological limit of a mandibular canine was found to be 20–30 g.",
     "keywords": ["Mandibular canine", "Pure intrusion", "LiO", "FEA"]},
    {"article name": "Denoising of ECG signal by non-local estimation of approximation coefficients in DWT",
     "doi": "https://doi.org/10.1016/j.bbe.2017.06.001",
     "publication date": "01-2017",
     "abstract": "This paper presents an ECG denoising technique using merits of discrete wavelet transform (DWT) and non-local means (NLM) estimation. The NLM-based approach is quite effective in removing low frequency noises but it suffers from the issue of under-averaging in the high-frequency QRS-complex region. In addition to that, the computational cost of NLM estimation is also high. The DWT, on the other hand, is effective in removing high-frequency noise but needs larger decomposition levels in order to denoise the low-frequency components. Thresholding lower-frequency components in the DWT domain often results in a loss of critical information. To overcome these drawbacks, in the proposed method, two-level DWT decomposition is first performed in order to decompose the noisy ECG signal into low- and high-frequency approximation and detail coefficients, respectively, at each level. The high frequency noise is removed by thresholding the detail coefficients at both the levels. The noise in the lower-frequency region is then removed by performing NLM estimation of Level 2 approximation coefficient. The Level 2 approximation coefficients actually represent the low-frequency envelope of the ECG. Thus, the proposed technique effectively combines the power of both NLM and DWT. At the same time, the computational cost of whole process is not more than the earlier existing techniques since NLM estimation is performed only on Level 2 approximation coefficients instead of the complete ECG signal. The proposed method is found to be superior to the existing state-of-the-art techniques when tested on the MIT-BIH arrhythmia database.",
     "keywords": ["Electrocardiogram", "Non-local means", "Discrete wavelet transform", "Approximation coefficient", "Detail coefficient"]},
    {"article name": "Construction of a bilirubin biosensor based on an albumin-immobilized quartz crystal microbalance",
     "doi": "https://doi.org/10.1016/j.bbe.2017.05.007",
     "publication date": "01-2017",
     "abstract": "Bilirubin, a bile pigment, is associated with several diseases and systemic pathologies. The measurement of bilirubin is important for diagnosis and therapy, and many expensive methods are used to measure the bilirubin amount in blood. In this study, a new bilirubin biosensor using quartz crystal microbalances immobilized with albumin is proposed. To measure the effectiveness of the biosensor, a series of experiments was realized with various concentrations of bilirubin, including 1 mg/dL, 2 mg/dL, 5 mg/dL and 10 mg/dL. Comparing blood gas analyzers, laboratory analyzers, skin test devices and nonchemical photometric devices, blood gas analyzers have a range of 0.5–35 mg/dL, laboratory analyzers have a range of 0–30 mg/dL, skin test devices could be used up to 11.7 mg/dL, and nonchemical photometric devices could be evaluated as reliable up to 14.6 mg/dL. The low limit range of the bilirubin detection is between 0.099 mg/dL and 0.146 mg/dL for some special commercial bilirubin measurement devices. Nevertheless, this study presents measurements with a high sensitivity and includes the advantage of reusability by using cheaper materials. To prove albumin immobilization and the bilirubin–albumin interaction atomic force microscopy (AFM) was used, and a good correlation was achieved from AFM images. In conclusion, considering the cost-effectiveness side of the proposed method, a low cost and more sensitive bilirubin measurement device which is effective and reusable was developed instead of the current commercial products.",
     "keywords": ["Bilirubin detection", "Quartz crystal microbalance", "Biosensor", "Biosensor based on albumin", "QCM", "Albumin"]},
    {"article name": "Classification of falling asleep states using HRV analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2017.02.003",
     "publication date": "01-2017",
     "abstract": "The article presents the results of studies on drowsiness and drowsiness detection performed using heart rate variability analysis (HRV). The results of those studies indicate that the most significant parameters, from the standpoint of classification of drowsiness are the following parameters of the HRV analysis: the low and high frequency band the ratio of the tachogram power in the LF and HF bands, and the total power distribution. The best detection results were obtained for the following methods, in the following order: the nearest neighborhood with metrics: standardized Euclides and Mahalanobis, the square discriminant analysis, and the Bayesian classifier. In order to classify drowsiness periods, a neural network was also used; it consisted of four inputs, six neurons in the hidden layer, and three outputs, one of which was assigned to one of the accepted classes. In order to obtain the most effective learning, a linear feed forward network was designed using back propagation of errors and the RPROP algorithm. In the case of this type of networks, the achieved accuracy of the individual classes was on the level of 98.7%.",
     "keywords": ["HRV analysis", "Falling asleep", "Discriminant analysis", "K-nearest neighbors", "Artificial Neural Networks"]},
    {"article name": "Finite element analysis of stresses generated in cortical bone during implantation of a novel Limb Prosthesis Osseointegrated Fixation System",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.001",
     "publication date": "01-2017",
     "abstract": "The aim of this study was a biomechanical evaluation of the stresses generated in bone during implantation of the implant designed for direct skeletal attachment of limb prosthesis and a typical interference-fit implant of the reference. Using the finite element method implantation processes of both implants were modelled. The influence of two factors on stresses generated in bone was analysed: first – the radial interference between the implant and reamed marrow cavity (0.05 mm up to 0.25 mm) and second – the three types of implant's surfaces: polished, beaded and flaked. Obtained results show that in the case of the smallest value of radial interference (0.05 mm), stresses generated in cortical bone are more appropriate for the reference implant than for the designed one. With the increase of both analysed factors generated stresses are in favour of the designed implant especially in longitudinal direction for both, implant-adjacent and deep cortical tissue (even 18 times lower) alike. Stresses patterns also present that stresses values are lower in overall volume of analysed bone's part, during implantation of the designed implant. Presented characteristics and patterns confirm that the implantation method of presented implant is safer than a method for typical interference-fit implants for direct skeletal attachment of limb prosthesis.",
     "keywords": ["Cementless implantation", "Direct skeletal attachment", "Prosthesis"]},
    {"article name": "A hierarchical classification method for automatic sleep scoring using multiscale entropy features and proportion information of sleep architecture",
     "doi": "https://doi.org/10.1016/j.bbe.2017.01.005",
     "publication date": "01-2017",
     "abstract": "Sleep scoring is a critical step in medical researches and clinical applications. Traditional visual scoring method is based on the processing of physiological signals, such as electroencephalogram (EEG), electrooculogram (EOG) and electromyogram (EMG), which is a time consuming and subjective procedure. It is an urgent task to develop an effective method for automatic sleep scoring.This paper presents a hierarchical classification method for automatic sleep scoring by combining multiscale entropy features with the proportion information of the sleep architecture. Based on a three-layer classification scheme, sleep is categorized into five stages (Awake, S1, S2, SWS and REM). Specifically, the first layer is a standard SVM which performs classification between Awake and Sleep, while the second and third layers are implemented by combining probabilistic output SVM with proportion-based clustering. Multiscale entropy (MSE) from electroencephalogram (EEG) is extracted to represent signal characteristics in multiple temporal scales.The proposed method is evaluated with 20 sleep recordings, including 10 subjects with mild difficulty falling asleep and 10 healthy subjects. The overall accuracy of the proposed method is 91.4%. Compared with traditional methods, the classification accuracy of the proposed method is more balanced and the global performance is much better. The dataset includes both healthy subjects and subjects with sleep disorders, which means the presented method has good generalization capacity. Experimental results demonstrate the feasibility of the attempt to introduce proportion information into automatic sleep scoring.",
     "keywords": ["Sleep scoring", "Polysomnographic", "Multiscale entropy", "Proportion information", "Hierarchical classification"]},
    {"article name": "Stress–strain characteristic of human trabecular bone based on depth sensing indentation measurements",
     "doi": "https://doi.org/10.1016/j.bbe.2017.01.002",
     "publication date": "01-2017",
     "abstract": "In the paper a relation between stress and strain for trabecular bone is presented. The relation is based on the results of depth sensing indentation (DSI) tests which were performed with a spherical indenter. The DSI technique allowed also to determine three measures of hardness, i.e. Martens hardness (HM), nanohardness (HIT), Vickers hardness (HV) and Young modulus EIT of the trabecular bone tissue. The bone samples were harvested from human femoral heads during orthopaedical procedures of hip joint implantation.In the research the Hertzian approach is undertaken. The constitutive relation is then formulated in the elastic domain. The values of hardness and the Young modulus obtained from the DSI tests are in good agreement with those found in literature. The stress–strain relation is formulated to implement it in the future in finite element analyses of trabecular bone. Such simulations allow to take into account the microstructural mechanical properties of the trabecular tissue as well as remodelling phenomenon. This will make it possible to analyse the stress and strain states in bone for engineering and medical purposes.",
     "keywords": ["Nanoindentation", "Constitutive relation", "Trabecular structure"]},
    {"article name": "Nephropathy forecasting in diabetic patients using a GA-based type-2 fuzzy regression model",
     "doi": "https://doi.org/10.1016/j.bbe.2017.01.003",
     "publication date": "01-2017",
     "abstract": "Choosing a proper method to predict and timely prevent the complications of diabetes could be considered a significant step toward optimally controlling the disease. Since in medical research only small sample sizes of data are available and medical data always includes high levels of uncertainty and ambiguity, a type-2 fuzzy regression model seems to be an appropriate procedure for finding the relationship between outcome and explanatory variables in medical decision-making. In this paper, a new type-2 fuzzy regression model based on type-2 fuzzy time series concepts is used to forecast nephropathy in diabetic patients. Results in two examples show model efficiency. The use of such models in diabetes clinics is proposed.",
     "keywords": ["Type-2 fuzzy logic", "Fuzzy time series", "Fuzzy regression", "Nephropathy", "Forecasting"]},
    {"article name": "A two dimensional approach for modelling of pennate muscle behaviour",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.004",
     "publication date": "01-2017",
     "abstract": "The purpose of this study was to elaborate a two-dimensional approach for unipennate and bipennate striated skeletal muscle modelling. Behavior of chosen flat pennate muscle is modelled as a rheological system composed of serially linked passive and active fragments having different mechanical properties. Each fragment is composed of three elements: mass element, elastic element and viscous element. Each active fragment furthermore contains the contractile element. Proposed approach takes into consideration that muscle force depends on a planar arrangement of muscle fibers. Paper presents results of numerical simulations, conclusions deduced on the base of these results and a concept of experimental verification of proposed models.",
     "keywords": ["Muscle", "Pennation", "Rheology", "Modelling", "Numerical Simulation"]},
    {"article name": "Stress response of patellofemoral joint subjected to femoral retroversion with various patellar kinematics and flexions – An FEA study",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.006",
     "publication date": "01-2017",
     "abstract": "The purpose of this study is to observe the stress response of the patellofemoral joint associated with three patellar kinematics: shift, spin and tilt under femoral retroversion conditions. By assigning various flexions and different loads, the stresses were quantified in the bones, tendons, cartilages and cartilage–bone interface. Four different loads of 600, 657, 706 and 753 N were applied on 12 models representing each of the various kinematics of shifts, spins and tilts of the patella with femoral flexions of 30°, 60°, 90° and 120° which gave results for 48 analyses. The ‘Q’ angle of the femur bone was maintained at 14° with femoral retroversion of 21°. Based on the patellar kinematics, three different cases were modeled as (a) 5 mm shift 10° spin 4° tilt, (b) 10 mm shift 13° spin 8° tilt, and (c) 15 mm shift 16° spin 12° tilt. Medial shift, spin and tilt with femoral retroversion were limited in this study. The femoral displacement for 30° flexion at 600 N was found to be same in all the (a), (b), and (c) cases. Similarly, respective same displacements were achieved in all three cases when subjected to 60° flex at 657 N, 90° flex at 706 N and 120° flex at 753 N. From the simulated results it is inferred that femoral retroversion with case (b) kinematics susceptibly dominated by the cartilages causes patellofemoral joint pain, arthritis and instability due to the larger contact areas between the patella and femur bone at flexions 60° and 90°.",
     "keywords": ["Femoral retroversion", "Patellofemoral joint", "Finite element modeling", "Patellar kinematics"]},
    {"article name": "Comparative evaluation of EMG signal features for myoelectric controlled human arm prosthetics",
     "doi": "https://doi.org/10.1016/j.bbe.2017.03.001",
     "publication date": "01-2017",
     "abstract": "Myoelectric controlled human arm prosthetics have shown a promising performance with regards to the supplementation of the basic manipulation requirements for amputated people over recent years. However these assistive devices still have important restrictions in enabling amputated people to perform rather sophisticated or functional movements. Surface electromyography (EMG) is used as the control signal to command such prosthetic devices to ensure the amputated people to compensate their fundamental movement patterns. The ability of extraction of clear and certain neural information from EMG signals is a critical issue in fine control of hand prosthesis movements. Various signal processing methods have been employed for feature extraction from EMG signals. In this study, it was aimed to comparatively evaluate the widely used time domain EMG signal features, i.e., integrated EMG (IEMG), root mean square (RMS), and waveform length (WL) in estimation of externally applied forces to human hands. Once the signal features were extracted, classification process was applied to predict the external forces using artificial neural networks (ANN). EMG signals were recorded during two types of muscle contraction: (i) isometric and isotonic, and (ii) anisotonic and anisometric contractions. Experiments were implemented by six healthy subjects from the muscles that are proximal to the upper body, i.e., biceps brachii, triceps brachii, pectorialis major and trapezius. The force prediction results obtained from the ANN were statistically evaluated and, merits and shortcomings of the features were discussed. Findings of the study are expected to provide better insight regarding control structure of the EMG-based motion assistive devices.",
     "keywords": ["Electromyography", "Prosthetics", "Feature", "Classification", "Prediction"]},
    {"article name": "Analyzing effects of ELF electromagnetic fields on removing bacterial biofilm",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.005",
     "publication date": "01-2017",
     "abstract": "Use of extremely low frequency electromagnetic field (ELF-EMF) to prevent and/or remove bacterial biofilm formation is rather a new research area. However the technique is becoming popular as the conventional methods such as antimicrobial surfaces, quorum-sensing and usage of phage are mostly insufficient. In this work, 1 mT–50 Hz and 100 Hz magnetic fields are applied on bacterial biofilm produced locally in our MOBGAM laboratory and found reasonable level of success of its removal.",
     "keywords": null},
    {"article name": "Trends and perspectives in modification of zirconium oxide for a dental prosthetic applications – A review",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.005",
     "publication date": "01-2017",
     "abstract": "Full-ceramic dental restorations made from ZrO2 have become increasingly popular due to their aesthetics and mechanical strength, and are gradually replacing prostheses made of porcelain fused to metal. Nevertheless, due to the variability in the physicochemical properties in a wet environment at elevated temperature, zirconia is quite a controversial material, the use of which in the environment of the mouth is questionable and raises many concerns. The reason for the variability in the physicochemical changes is the martensitic transformation in which metastable phases (β, γ) change into the stable phase (α). For biomedical applications, the most desired is the β-phase. A very unfavourable phenomenon accompanying the martensitic transformation in a wet environment is low temperature degradation, which is an autocatalytic process accelerating negative changes in ZrO2. The aim of this review is a comprehensive study of the degradation phenomenon problems according to prosthetic treatment with a fixed prosthesis and ways to reduce it.",
     "keywords": ["Zirconia", "All ceramic restorations", "Low thermal degradation", "Zirconia stabilisation", "Oxide dopants"]},
    {"article name": "An analytical method for the adaptive computation of threshold of gradient modulus in 2D anisotropic diffusion filter",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.002",
     "publication date": "01-2017",
     "abstract": "In spite of the extensive application of Anisotropic Diffusion (AD) filter in software packages for medical image analysis, denoising and edge preservation offered by it depends exclusively on the selection of the value of Threshold of Gradient Modulus (TGM). Tuning the TGM to its optimum value through trial and error is subjective and tiring. An analytical model to compute the optimum value of TGM adaptively from the mean gradient of the image itself is proposed in this article. The qualitative examination of the gradient and true edge maps of the original and restored Magnetic Resonance images revealed that analytically computed TGM ensures best trade-off between noise suppression and edge preservation.",
     "keywords": ["Anisotropic diffusion", "Threshold of gradient modulus", "Non-linear spatial filter", "Restoration", "Denoising"]},
    {"article name": "In vitro test method for the development of intelligent lower limb prosthetic devices",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.003",
     "publication date": "01-2017",
     "abstract": "In recent decades, the technological progress has contributed to the development of appliances that significantly improve human life. The biomedical field has benefited more than others from this innovation process. In particular, robotics advances have led to the development of prostheses that allow who suffered the amputation of a lower limb to walk almost like a healthy person. Although sophisticated, the current solutions are not yet able to completely reestablish the function of their biological counterpart. According to authors’ opinion this deficiency is principally due to the lack of suitable development and verification methods rather than of appropriate technology resources. Therefore, an innovative bench for testing lower limb prostheses considering working conditions more realistic than those defined by the legislation in force is presented in this paper. The mechanical setup is composed of a 6-axis industrial robot and a custom 2-axis active force plate. The first one is used to replicate the movements of the limb residual segment in space. The second one to load the prosthetic foot both in longitudinal and vertical direction, that is, in the sagittal plane. Both the design choices and the operation procedure are illustrated. Then, a numerical model of the bench is developed in order to assess the merits and the limits of the proposed solution.",
     "keywords": ["Active Prostheses", "Test bench", "Gait simulator", "Force plate"]},
    {"article name": "Automatic contrast enhancement of brain MR images using Average Intensity Replacement based on Adaptive Histogram Equalization (AIR-AHE)",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.003",
     "publication date": "01-2017",
     "abstract": "Medical imaging is the most established technique of visualizing the interior of the human body without the risk of the non-invasive effect. This technology is designed to produce images, and it is also capable of representing information about the screening location. In MRI imaging, the poor image quality particularly the low contrast image may provide insufficient data for the visual interpretation of such affected locations. Therefore, the need of image enhancement arises to improve image visions and also to computationally support the image processing technique. In general, conventional contrast enhancement methods may work well for some images. However, in MRI brain image, there are often more complex situations where the WMH signal is high but it may mistakenly be considered as other brain tissues such as CSF. With the motivation to classify the most possible WMH regions, this paper proposes a novel image contrast algorithm of WMH enhancement for MRI image. This algorithm is also known as the Average Intensity Replacement – Adaptive Histogram Equalization (AIR-AHE). The proposed algorithm is applied to the FLAIR image based on the intensity adjustment and contrast mapping techniques. The proposed algorithm for the image enhancement is superior to the existing methods by using image evaluation quantitative methods of PSNR, average gradient values and MSE. Furthermore, the edge information pertaining to the potential WMH regions can effectively increase the accuracy of the results.",
     "keywords": ["MRI", "Enhancement", "Algorithm", "WMH", "Intensity-based"]},
    {"article name": "The intima with early atherosclerotic lesions is load-bearing component of human thoracic aorta",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.008",
     "publication date": "01-2017",
     "abstract": "The aim of the study was to evaluate the mechanical properties of the adventitia, media, and especially intima of the human thoracic aortic wall in the early stages of atherosclerosis (stage I to III according to the Stary's classification). Histological and immunohistochemical techniques were used to evaluate the severity of atherosclerosis and the correctness of separation of the respective layers. Circumferential specimens of the adventitia, media, and intima (n = 193) were prepared from 27 arteries. The mechanical properties, i.e. the ultimate tensile strength, the maximum strain, and the maximum tangential elastic moduli, were determined in uniaxial tensile test and presented as a median (Me). The tensile strength of the intima (Me = 105 kPa) is comparable to the media (Me = 123 kPa) and lower than for the adventitia (Me = 808.5 kPa). The intima also undergoes the lowest maximum strain (Me = 0.008), and its elastic modulus (Me = 11510 kPa) is significantly higher compared to the media (Me = 5280 kPa). Therefore, presented results indicate that even in the early stages of atherosclerotic development the intima takes part in the process of mechanical loads bearing.",
     "keywords": ["Atherosclerosis", "Intima", "Mechanical properties"]},
    {"article name": "Bayesian network aided grasp and grip efficiency estimation using a smart data glove for post-stroke diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.005",
     "publication date": "01-2017",
     "abstract": "Stroke is one of the major causes behind the increased mortality rate throughout the world and disability among the survivors. Such disabilities include several grasp and grip related impairment in daily activities like holding a glass of water, counting currency notes, producing correct signature in bank, etc., that seek serious attention. Present therapeutic facilities, being expensive and time-consuming, fail to cater the poverty stricken rural class of the society. In this paper, on the basis of an investigation, we developed a smart data glove based diagnostic device for better treatment of such patients by providing timely estimation of their grasp quality. Data collected from a VMG30 motion capture glove for six patients who survived stroke and two other healthy subjects was fused with suitable hypothesis obtained from a domain expert to reflect the required outcome on a Bayesian network. The end result could be made available to a doctor at a remote location through a smart phone for further advice or treatment. Results obtained clearly distinguished a patient from a healthy subject along with supporting estimates to study and compare different grasping gestures. The improvement in mobility could be assessed after physiotherapeutic treatments using the proposed method.",
     "keywords": ["Stroke", "Data glove", "Bayesian network", "Probabilistic estimates", "Grasping gestures"]},
    {"article name": "Use of siliconised infant endotracheal tubes reduces work of breathing under turbulent flow",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.002",
     "publication date": "01-2017",
     "abstract": "The high resistance of an infant endotracheal tube (ETT) can markedly impair ventilation and gas exchange. Since some manufacturers cover the inner surface of their ETTs with a silicon layer in order to diminish deposition and ease mucous evacuation from airway, via surface roughness decrease, we assessed whether the silicon layer may affect tube resistance, work of breathing and other parameters of ventilation.We compared SUMI (Poland) non-siliconised and siliconised polyvinyl chloride ETTs (2.5, 3.0 and 4.0 mm ID), twenty of each type and size combination. Simulating volume-controlled ventilation with the hybrid (numerical–physical) lung models of a premature infant and a 3-month-old baby peak inspiratory pressure (PIP), peak inspiratory and expiratory flow (PIF, PEF), (patient + ETT) inspiratory and expiratory airway resistance (Rins, Rexp) and work of breathing by ventilator (WOBvt) were measured. Additionally, images of the both type surfaces were taken using Hitachi TM-1000 electron microscope.When 2.5 and 3.0 mm ID ETTs were examined, laminar flow (Re <2300) across the tube was observed, and there were no clinically significant differences in the ventilation parameters between non-siliconised and siliconised tubes. Whereas, when 4 mm ID ETTs were tested, turbulent flow was observed, and PIP, Rins, Rexp and WOBvt were significantly lower (5%, 17%, 17%, and 7%, respectively) (P < 0.05), but PIF and PEF were significantly higher (8%, 14%) (P < 0.05). Thus, the silicone inner surface of ETT offers less resistance and WOBvt in presence of turbulent flow. However, artifacts observed on the surface of non-siliconised and siliconised ETTs can potentially impair ventilation.",
     "keywords": ["Laminar/ turbulent gas flow", "Endotracheal tube resistance", "Work of breathing"]},
    {"article name": "3D vascular tree segmentation using a multiscale vesselness function and a level set approach",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.003",
     "publication date": "01-2017",
     "abstract": "The paper presents a method aimed at segmentation of a vascular network in 3D medical data. The method implements an extended version of a vesselness function that considers multiscale image filtering to emphasize vessels of different diameters. This function is combined with a level set approach based on a Chan–Vese model. The proposed method was evaluated on medical images of the brain and hand vasculature. These images were obtained by different modalities, including angio-CT and two MR acquisition protocols. The proposed technique was quantitatively validated for the tree phantom image by assessing segmentation accuracy and for the angio-CT images by estimating diameters of vessel fragments. Two radiologists provided also qualitative evaluation of this approach. It was demonstrated that this method ensures correct segmentation of a vessel tree in the analyzed images. Moreover, it enables detection of thinner vessel branches when compared to single scale vesselness function approaches.",
     "keywords": ["3D vascular network", "Magnetic resonance and computed tomography angiography", "Level set segmentation"]},
    {"article name": "Optimization of multi-slot coaxial antennas for microwave thermotherapy based on the S11-parameter analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.001",
     "publication date": "01-2017",
     "abstract": "The underlying aim of presented article is to determine the optimal location and sizes of the air gaps inside a multi-slot coaxial antenna with 50-ohm feed based on the S11-parameter characteristics of microwave applicator to get the best antenna impedance matching to the treated tissue. The next step is the selection of the limit levels of the antenna input power, for which temperature of the tissue do not exceed known therapeutic elevations for microwave therapies at hyperthermic and ablation temperatures. The proposed approach provides a relatively simple method for optimization of the location and size of slots in the antenna structure. The proper choice of limit values of total antenna input power enables appropriate adjustment of temperature of the target tissue to preserve optimal cancer treatment.",
     "keywords": ["Hyperthermia", "Ablation", "Microwave antennas", "Scattering parameters", "Finite element method (FEM)"]},
    {"article name": "Grafting of oxidized carboxymethyl cellulose with hydrogen peroxide in presence of Cu(II) to chitosan and biological elucidation",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.003",
     "publication date": "01-2017",
     "abstract": "The chemical interaction of chitosan (CS) is performed in the presence of sodium carboxymethyl cellulose (CMC) and/or oxidized CMC. The latter is obtained by the action of H2O2/CuSO4 to generate carbonyl and carboxyl groups which were increased with CuSO4 concentration. The characterization of these new materials is made by FTIR, TGA, XRD and SEM. Examination of the hemolytic potential showed that the hydrogels were non hemolytic in nature. The hydrogels were non-toxic and blood-compatible. The antibacterial and antioxidant activities of samples were investigated.",
     "keywords": ["Chitosan", "CMC", "Hydrogen peroxide", "Oxidized CMC", "Antibacterial and antioxidant activities"]},
    {"article name": "Electromyography and mechanomyography signal recognition: Experimental analysis using multi-way array decomposition methods",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.004",
     "publication date": "01-2017",
     "abstract": "In this study, we considered the problem of controlling a prosthetic hand with noisy electromyography (EMG) and mechanomyography (MMG) signals. Several dimensionality reduction methods were analyzed to assess their efficiency at classifying these signals, which were registered during the performance of grasping movements with various objects. Using the cross-validation technique, we compared various dimensionality reduction methods, such as principal components analysis, nonnegative matrix factorization, and some tensor decomposition models. The experimental results demonstrated that the highest classification accuracy (exceeding 95% for all subjects when classifying 11 grasping movements) and lowest computational complexity were obtained when higher-order singular value decomposition was applied to a multi-way array of multi-channel spectrograms, where the temporal EMG/MMG signals from all channels were concatenated.",
     "keywords": ["Biosignal processing", "Electromyography", "Mechanomyography", "Multi-array decomposition method", "Supervised classification"]},
    {"article name": "Reliability of stiffness measurement device during passive isokinetic spastic wrist movements of healthy subjects and hemiplegics",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.001",
     "publication date": "01-2017",
     "abstract": "The consistency of torque measurements during repetitive moving arm movements and also during passive wrist movements at two angular velocities of slow (∼6°/s) and moderate (∼120°/s) was investigated. The designed and developed device was applied to 3 cases, to a spring, to 8 able-bodied subjects and to 2 hemiplegic patients. While the mean of the intra-class correlation coefficient of subjects were 0.65 and 0.75 for slow and moderate angular velocities, those of the hemiplegic patients and the spring respectively ranged between excellent values of 0.93–1 and 0.91–1. The Pearson's product-moment correlation coefficients of the 3 cases for the 2 slow and moderate angular velocities ranged between 0.80 and 1. We could verify that the device can be used in our future researches and it can (1) reliably rotate a moving arm horizontally with angular velocities between 3 and 350°/s constantly in a range of motion between −60 and 60° and (2) simultaneously capture the data of angular displacement, torque, and two electromyogram activities. For the standardization of our future studies with the device, we could verify the stability of the last two repeated passive wrist movements in case of patients. The results of the study with the able-bodied subjects are also important as a reference for our studies with the hemiplegic.",
     "keywords": ["Mechatronics", "Instrumentation", "Measurement", "Spasticity"]},
    {"article name": "Bat optimization based neuron model of stochastic resonance for the enhancement of MR images",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.006",
     "publication date": "01-2017",
     "abstract": "Stochastic resonance (SR) performs the enhancement of the low in contrast image with the help of noise. The present paper proposes a modified neuron model based stochastic resonance approach applied for the enhancement of T1 weighted, T2 weighted, fluid-attenuated inversion recovery (FLAIR) and diffusion-weighted imaging (DWI) sequences of magnetic resonance imaging. Multi objective bat algorithm has been applied to tune the parameters of the modified neuron model for the maximization of two competitive image performance indices contrast enhancement factor (F) and mean opinion score (MOS). The quality of processed image depends on the choice of these image performance indices rather the selection of SR parameters. The proposed approach performs well on enhancement of magnetic resonance (MR) images, as a result there is improvement in the gray-white matter differentiation and has been found helpful in the better diagnosis of MR images.",
     "keywords": ["Neuron model of stochastic resonance", "Mesial temporal sclerosis", "Cortical dysplasia", "Image enhancement", "Bat algorithm", "MR images"]},
    {"article name": "Classification of tactile event-related potential elicited by Braille display for brain–computer interface",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.007",
     "publication date": "01-2017",
     "abstract": "To construct brain–computer interface (BCI), an event-related potential (ERP) induced by a tactile stimulus is investigated in this paper. For ERP-based BCI, visual or auditory information is frequently used as the stimulus. In the present study, we focus on tactile sensations to reserve their visual and auditory senses for other activities. Several patterns of mechanical tactile stimulation were applied to the index fingers of both hands using two piezo actuators that were used as a braille display. Human experiments based on the oddball paradigm were carried out. Subjects were instructed to pay attention to unusual target stimuli while avoiding other frequent non-target stimuli. The extracted features were classified by applying stepwise linear discriminant analysis. As a result, an accuracy of 85% and 60% were obtained for 2- and 4-class classification, respectively. The accuracy was improved by increasing the number of electrodes even when short stimulus intervals were used.",
     "keywords": ["Tactile stimulus", "Event-related potential", "Brain\u2013computer interface", "Braille display", "P300"]},
    {"article name": "Automatic segmentation of infant brain MR images: With special reference to myelinated white matter",
     "doi": "https://doi.org/10.1016/j.bbe.2016.11.004",
     "publication date": "01-2017",
     "abstract": "Automatic segmentation of infant brain images is faced with numerous challenges like poor image contrast, motion artifacts, and changes caused by progressive myelination of the infant brain. Since timely myelination points to normal brain maturity, monitoring the progress and degree of myelination is clinically significant. However, most of the existing segmentation methods do not segment myelinated portions of the infant brain. In this paper, we propose a segmentation approach focused on segmenting the myelinated white matter tissue in T1-weighted magnetic resonance images of the infant brain. The novelty of the algorithm lies in the introduction of a weighted localized Tsallis entropy based thresholding method. The proposed method is also tested on older babies beyond the one-year age mark to verify its utility and robustness. It is seen that the mean Dice coefficients obtained for myelin segmentation by the proposed weighted localized method are higher than that of the other methods, namely, the conventional Tsallis entropy thresholding and modified localized method.",
     "keywords": ["Automatic segmentation", "Infant brain", "MRI", "Myelination"]},
    {"article name": "A full reference Morphological Edge Similarity Index to account processing induced edge artefacts in magnetic resonance images",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.008",
     "publication date": "01-2017",
     "abstract": "An objective measure of edge similarity between the original and processed images to quantify the processing induced artefacts in medical image computing is proposed in this article. Globally accepted Image Quality Analysis (IQA) indices such as Peak Signal Noise Ratio (PSNR) and Structural Similarity Index Metric (SSIM) measure the structural similarity between the original and processed image and do not specifically reflect the resemblance of the edge content. Most of the IQA indices either do not comply with the subjective quality ratings or they are prone to noise level. In the proposed Morphological Edge Similarity Index (MESI), the binary edge maps of the reference and processed images are generated via gradient based threshold and these edge maps are objectively compared to yield a reliable edge quality metric. The index is found superior to Edge Preservation Index (EPI), Edge Strength Similarity based Image quality Metric (ESSIM) and SSIM in terms of dynamic variability, correlation with subjective quality ratings, robustness to noise and sensitivity to degradation in edge quality caused by blockiness artefacts in image compression. MESI exhibits a correlation of 0.9985, very close to unity, with the subjective quality ratings. It is useful for objectively evaluating the performance of denoising, sharpening and enhancement schemes and for the selection of optimum value of the arbitrary parameters used in them.",
     "keywords": ["Edge Similarity Index", "Blur metric", "Image Quality Analysis", "Pratt's Figure of Merit", "Edge strength"]},
    {"article name": "Verification of the new ‘all ages’ spirometric reference values for use in young Polish children of Caucasian origin",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.006",
     "publication date": "01-2017",
     "abstract": "Interpretation of the spirometric results in young children aged 3 years and onward was a difficult task, because existing reference values usually covered age range of 7–18 years. Recently two big studies concerning ‘all ages’ reference equations were published: the study of The Asthma UK Initiative (Stanojevic et al. AJRCCM 2009) and the so called GLI2012 values (Quanjer et al. ERJ 2012); both providing equations with LMS approach for spirometric reference values for age range of 3–95 years. The aim of the study was to test the applicability of the new sets of equations in a group of healthy Polish children of Caucasian descent.The analysis was performed on a data gathered from children admitted to outpatient department for diagnostic reasons. Children performed impulse oscillometry (IOS) measurements and spirometry. Elevated value of oscillometric resistance at 5 Hz (R5) eliminated children from analysis as well as forced expiratory time less than 1.5 s. Final analysis was performed on results obtained from 142 children aged 4–10 years.Z-scores and percent of predicted values were calculated for FEV1, FVC and FEV1/FVC using both sets; additionally z-score and percent predicted was also calculated for FEV0.75/FVC using Stanojevic's equation. The distribution of all calculated z-scores was normal. For FEV1/FVC mean ± SD of z-score was 0.01 ± 0.80 using GLI2012 and −0.15 ± 0.79 using Stanojevic's set. Mean value of percent predicted values using GLI2012 was 100.2 ± 5.5% for FEV1/FVC, 107.4 ± 9.4% for FEV1 and 106.6 ± 10.1% for FVC. Our results confirm applicability of the new sets of reference values in young Caucasian children from Poland and point out the potential diagnostic value of FEV0.75/FVC.",
     "keywords": ["Spirometry", "Children", "Reference values", "Impulse oscillometry"]},
    {"article name": "Ictal EEG classification based on amplitude and frequency contours of IMFs",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.005",
     "publication date": "01-2017",
     "abstract": "Electroencephalogram (EEG) signal serves is a powerful tool in epilepsy detection. This study decomposes intrinsic mode functions (IMFs) into amplitude envelope and frequency functions on a time-scale basis using the analytic function of Hilbert transform. IMFs results from the empirical mode decomposition of EEG signals. Features such as energy and entropy parameters were calculated from the amplitude contour of each IMF. Other features, such as interquartile range, mean absolute deviation and standard deviation are also computed for their instantaneous frequencies. Discriminative features were extracted using a large database to classify healthy and ictal EEG signals. Normal EEG segments were differentiated from the seizure attack in individual IMF features, multiple features with individual IMF, and individual features with multiple IMFs. Discriminating capability of three Cases was tested. (i) Artificial neural network and (ii) adaptive neuro-fuzzy inference system classification were used to identify EEG segments with seizure attacks. ANOVA was used to analyze statistical performance. Energy and entropy-based features of instantaneous amplitude and standard deviation of instantaneous frequency of IMF2 and IMF1 have 100% accuracy, sensitivity, and specificity. Good performance with a single feature that represents information of the whole data was obtained. The result involved less complicated computation than other time–frequency analysis techniques.",
     "keywords": ["ANN", "ANOVA", "EEG", "EMD", "HHT", "Seizure"]},
    {"article name": "A generalized method for the detection of vascular structure in pathological retinal images",
     "doi": "https://doi.org/10.1016/j.bbe.2016.09.002",
     "publication date": "01-2017",
     "abstract": "Variations in blood vasculature morphology of retinal fundus images is one of the dominant characteristic for the early detection and analysis of retinal abnormalities. Therefore the accurate interpretation of blood vasculature is useful for ophthalmologists to diagnose patients that suffer from retinal abnormalities. A generalized method to detect and segment blood vasculature using retinal fundus images has been proposed in this work using (i) preprocessing for quality improvement of retinal fundus images, (ii) initial segmentation of vasculature map to find vascular and non vascular structures, (iii) extraction of relevant set of geometrical based features from the vasculature map and intensity based features from original retinal fundus image that differentiate vascular and non vascular structures efficiently, (iv) supervised classification of vascular and non vascular structures using the extracted features, and (v) joining of candidate vascular structures to create connectivity. The proposed method is evaluated on clinically acquired dataset and different publically available standard datasets such as DRIVE, STARE, ARIA and HRF. The clinically acquired dataset consists of 468 retinal fundus images comprising of healthy images, images with mild, intermediate and severe pathologies. Test results of the proposed method shows average sensitivity/specificity/accuracy of 85.43/97.94/95.45 on the 785 retinal fundus images. The proposed method shows an improvement of 14.01% in sensitivity without degrading specificity and accuracy in comparison to the recently published methods.",
     "keywords": ["Blood vasculature", "Retinal fundus image", "Segmentation", "Neural network", "Geometrical features", "Intensity features"]},
    {"article name": "Development of the deterministic and stochastic Markovian model of a dendritic neuron",
     "doi": "https://doi.org/10.1016/j.bbe.2016.10.002",
     "publication date": "01-2017",
     "abstract": "In this study, we propose a model of the dendritic structure of the neuron (referred to as a neural network – NN), which can be viewed as an extension of the models that are currently used in the description of the potential on the neuron's membrane. The proposed extensions augment the generic model and offer a fuller description of the neuron's nature. The common assumption being used in most of the previous models stating a single channel (forming component of the neuron's membrane) can be positioned in only one of the two states (permissive – open and non-permissive – closed), is now relaxed by allowing the channel to be positioned in more states (five or eight states). The relationship between these states is expressed in terms of Markov kinetic schemes. In the paper, we demonstrate that the new approach is more suitable for a larger number of applications than the conventional Hodgkin–Huxley model.The study, by providing the mathematical background of the new extended model, forms a significant step towards a hardware implementation of the biologically realistic neural network (NN) of this type. To reduce the number of components required in such implementation, we propose a new optimization technique that significantly reduces the computational complexity of a single neuron.",
     "keywords": ["Model of dendritic neuron", "Hodgkin\u2013Huxley model", "Markov kinetic scheme", "Hardware simplification"]},
    {"article name": "A classification framework for prediction of breast density using an ensemble of neural network classifiers",
     "doi": "https://doi.org/10.1016/j.bbe.2017.01.001",
     "publication date": "01-2017",
     "abstract": "The present work proposes a classification framework for the prediction of breast density using an ensemble of neural network classifiers. Expert radiologists, visualize the textural characteristics of center region of a breast to distinguish between different breast density classes. Accordingly, ROIs of fixed size are cropped from the center location of the breast tissue and GLCM mean features are computed for each ROI by varying inter-pixel distance ‘d’ from 1 to 15. The proposed classification framework consists of two stages, (a) first stage: this stage consists of a single 4-class neural network classifier NN0 (B-I/B-II/B-III/B-IV) which yields the output probability vector [PB-I PB-II PB-III PB-IV] indicating the probability values with which a test ROI belongs to a particular breast density class. (b) second stage: this stage consists of an ensemble of six binary neural network classifiers NN1 (B-I/B-II), NN2 (B-I/B-III), NN3 (B-I/B-IV), NN4 (B-II/B-III), NN5 (B-II/B-IV) and NN6 (B-III/B-IV).The output of the first stage of the classification framework, i.e. output on NN0 is used to obtain the two most probable classes for a test ROI. In the second stage this test ROI is passed through one of the binary neural networks, i.e. NN1 to NN6 corresponding to the two most probable classes predicted by NN0. After passing the entire test ROIs through the second stage, the overall accuracy increases from 79.5% to 90.8%. The promising results achieved by the proposed classification framework indicate that it can be used in clinical environment for differentiation between breast density patterns.",
     "keywords": ["ROI region of interest", "region of interest", "FELM fuzzy-extreme learning machine", "fuzzy-extreme learning machine", "NN neural network classifier", "neural network classifier", "BIRADS breast imaging-reporting and data system", "breast imaging-reporting and data system", "DDSM digital database for screening mammography", "digital database for screening mammography", "MIAS Mammographic Image Analysis Society", "Mammographic Image Analysis Society", "ST segmented tissue", "segmented tissue", "ANN artificial neural network classifier", "artificial neural network classifier", "k-NN k-nearest neighbors", "k-nearest neighbors", "MI misclassified instances", "misclassified instances", "SVM support vector machine classifier", "support vector machine classifier", "SFS sequential forward search", "sequential forward search", "MLO/CC mediolateral oblique/cranial-caudal", "mediolateral oblique/cranial-caudal", "TFV texture feature vector", "texture feature vector", "CM confusion matrix", "confusion matrix", "OCA overall classification accuracy", "overall classification accuracy", "NGTDM neighborhood gray tone difference matrix", "neighborhood gray tone difference matrix", "TI testing instance", "testing instance", "ICA individual class accuracy", "individual class accuracy", "FOS first order statistics", "first order statistics", "GLCM gray level co-occurrence matrix", "gray level co-occurrence matrix", "GLDS gray-level difference statistics", "gray-level difference statistics", "SFM statistical feature matrix", "statistical feature matrix", "GLRLM gray level run length matrix", "gray level run length matrix", "Mammography", "Breast density classification", "Gray level co-occurrence matrix", "Neural network classifier", "Ensemble classifier"]},
    {"article name": "Automatic parameters selection of Gabor filters with the imperialism competitive algorithm with application to retinal vessel segmentation",
     "doi": "https://doi.org/10.1016/j.bbe.2016.12.007",
     "publication date": "01-2017",
     "abstract": "Retinal images play an important role in the early diagnosis of diseases such as diabetes. In the present study, an automatic image processing technique is proposed to segment retinal blood vessels in fundus images. The technique includes the design of a bank of 180 Gabor filters with varying scale and elongation parameters. Furthermore, an optimization method, namely, the imperialism competitive algorithm (ICA), is adopted for automatic parameter selection of the Gabor filter. In addition, a systematic method is proposed to determine the threshold value for reliable performance. Finally, the performance of the proposed approach is analyzed and compared with that of other approaches on the basis of the publicly available DRIVE database. The proposed method achieves an area under the receiver operating characteristic curve of 0.953 and an average accuracy of up to 0.9392. Thus, the results show that the proposed method is well comparable with alternative methods in the literature.",
     "keywords": ["Retinal images", "Gabor filter", "Blood vessel detection", "Image segmentation", "Parameter selection"]},
    {"article name": "Simplification of breast deformation modelling to support breast cancer treatment planning",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.001",
     "publication date": "01-2016",
     "abstract": "The exact delineation of tumour boundaries is of utmost importance in the planning of cancer therapy, either surgery or pre- or post-operative radiation treatment. In the case of breast cancer one of the most advanced modalities is magnetic resonance imaging (MRI). Although MRI scans provide wealth of information about the structure of a tumour and the surrounding tissues, the data obtained represent the patient in a prone position, with breast, in a coil while surgery is performed in a supine position, on lying breast. There is no doubt that a patient's breast in both positions has a different shape and that this influences the intra-breast relations. Our present preliminary study introduces a simple breast model developed from prone images. The model should be built rapidly and by a simple procedure, based only on essential structures, and the goal is to prove its usefulness in treatment planning.",
     "keywords": ["Breast deformation", "Modelling", "Treatment planning", "MRI"]},
    {"article name": "Multi-sequence texture analysis in classification of in vivo MR images of the prostate",
     "doi": "https://doi.org/10.1016/j.bbe.2016.05.002",
     "publication date": "01-2016",
     "abstract": "The aim of the study is to investigate the potential of multi-sequence texture analysis in the characterization of prostatic tissues from in vivo Magnetic Resonance Images (MRI). The approach consists in simultaneous analysis of several images, each acquired under different conditions, but representing the same part of the organ. First, the texture of each image is characterized independently of the others. Then the feature values corresponding to different acquisition conditions are combined in one vector, characterizing a combination of textures derived from several sequences. Three MRI sequences are considered: T1-weighted, T2-weighted, and diffusion-weighted. Their textures are characterized using six methods (statistical and model-based). In total, 30 tissue descriptors are calculated for each sequence. The feature space is reduced using a modified Monte Carlo feature selection, combined with wrapper methods, and Principal Components Analysis.Six classifiers were used in the work. Multi-sequence texture analysis led to better classification results than single-sequence analysis. The subsets of features selected with the Monte Carlo method guaranteed the highest classification accuracies.",
     "keywords": ["Computer-aided diagnosis", "Tissue characterization", "Multi-image texture analysis", "Feature extraction", "Feature selection", "Classification"]},
    {"article name": "Generative Model-Driven Feature Learning for dysarthric speech recognition",
     "doi": "https://doi.org/10.1016/j.bbe.2016.05.003",
     "publication date": "01-2016",
     "abstract": "Recognition of speech uttered by severe dysarthric speakers needs a robust learning technique. One of the commonly used generative model-based classifiers for speech recognition is a hidden Markov model. Generative model-based classifiers do not do well for overlapping classes and due to insufficient training data. Dysarthric speech is normally partial or incomplete that leads to improper learning of temporal dynamics. To overcome these issues, we focus on learning features for dysarthric speech recognition that involves recognizing the sequential patterns of varying length utterances. We propose a Generative Model-Driven Feature Learning based discriminative framework that maps the sequence of feature vectors to fixed dimension vector spaces induced by the generative models. The discriminative classifier is built in that vector space. The proposed HMM-based fixed dimensional vector representation provides better discrimination for dysarthric speech than the conventional HMM. We examine the performance of the proposed method to recognize the isolated utterances from the UA-Speech database. The recognition accuracy of the proposed model is better than the conventional hidden Markov model-based approach.",
     "keywords": ["Generative Model-Driven Feature Learning", "Dysarthric speech recognition", "Support vector machine", "Varying length sequences", "Feature vector representation"]},
    {"article name": "Evaluating the fetal heart rate baseline estimation algorithms by their influence on detection of clinically important patterns",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.003",
     "publication date": "01-2016",
     "abstract": "A correctly estimated component of fetal heart rate signal (FHR) – so called baseline – is a precondition for proper recognition of acceleration and deceleration patterns. A number of various algorithms for estimating the FHR baseline was proposed so far. However, there is no reference standard enabling their objective evaluation, and thus no methodology of comparing the different algorithms still exists. In this paper we propose a method for evaluation of automatically determined baseline in reference to a set of experts, based on ten separate groups of signals comprising typical variability patterns observed in the fetal heart rate. As it was proposed earlier [1], the given algorithm is evaluated based on the characteristic patterns detected using the obtained baseline, instead of direct analysis of the baseline shape. For the purpose of quantitative assessment of the estimated baseline a new synthetic inconsistency coefficient was applied. The proposed methodology enabled to evaluate eleven well-known algorithms. We believe that the method will be a valuable tool for assessment of the existing algorithms, as well as for developing the new ones.",
     "keywords": ["Fetal monitoring", "Fetal heart rate", "Baseline estimation", "Acceleration", "Deceleration"]},
    {"article name": "Early predicting a risk of preterm labour by analysis of antepartum electrohysterograhic signals",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.004",
     "publication date": "01-2016",
     "abstract": "This study is aimed at evaluation of the capability to indicate the preterm labour risk by analysing the features extracted from the signals of electrical uterine activity. Free access database was used with 300 signals acquired in two groups of pregnant women who delivered at term (262 cases) and preterm (38 cases). Signal features comprised classical time domain description, spectral parameters and nonlinear measures of contractile activity. Their mean values were calculated for all the contraction episodes detected in each record and their statistical significance for recognition of two groups of recordings was provided. Obtained results were related to the previous study where the same features were applied but they were determined for entire signals. Influence of electrodes location, band-pass filter settings and gestation week was investigated. The obtained results showed that a spectral parameter – the median frequency was the most promising indicator of the preterm labour risk.",
     "keywords": ["Electrical uterine activity", "Electrohysterography", "Preterm labour prediction", "Uterine contraction detection"]},
    {"article name": "Automatic segmentation of cell nuclei using Krill Herd optimization based multi-thresholding and Localized Active Contour Model",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.005",
     "publication date": "01-2016",
     "abstract": "Analysis of tissue components in histopathology image stays on as the gold standard in detecting different types of cancers. Active Contour Models (ACM) serve as a widely useful tool in object segmentation in pathology images. Since the ACMs are susceptible to initial contour placement, efficiency of object detection is very much influenced by the selection of primary curve placement technique. In this paper, in order to handle diffused intensities present along object boundaries in histopathology images, segmentation of nuclei from breast histopathology images are carried out by Localized Active Contour Model (LACM) utilizing bio-inspired optimization techniques in the detection stage. Krill Herd Algorithm (KHA) based optimal curve placement provides better initial boundaries compared with other detection techniques. The segmentation performance is investigated based on Housdorff (HD) and Maximum Absolute Distance (MAD) measures. The algorithm also shows comparable performance with other state-of-the-art techniques in terms of quantitative measures such as Precision, Accuracy and Touching Nuclei Resolution when applied to complex images of stained breast biopsy slides.",
     "keywords": ["Histopathology", "Cell nuclei segmentation", "Krill Herd optimization", "Localized Active Contour Model", "Multi-thresholding", "Bio-inspired computing"]},
    {"article name": "MIAP – Web-based platform for the computer analysis of microscopic images to support the pathological diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.006",
     "publication date": "01-2016",
     "abstract": "The aim of the project is to design and to implement a web-based platform for the computer analysis of microscopic images which support the pathological diagnosis. The use of the platform will be free of charge. It offers: quantitative analysis of staining tissue sample’ images, archiving microscopic images, peer consultation, and join work independently from distance between scientific collaborating centers to registered doctors, scientists and students. The use of proposed platform allows: (i) to save pathologists’ time spend on quantitative analysis, (ii) to reduce consulting costs by replacing sending of the physical preparations by placing their images (mostly virtual slide) on the platform server, (iii) to increase reproducibility, comparability and objectivity of quantitative evaluations. These effects have a direct impact on improving the effectiveness and decreasing the costs of patients’ treatment. This paper presents the main ideas of the project which deliver web-based system working as multi-functional, integrated, modular and scalable computer system. The details of hardware solutions, concept of the workflow in the platform, the programming language and interpreters, the specific tools and algorithms, and the user interfaces are described below. The practical solutions for web-based services in the area of medical image analysis, storage and retrieval are also presented and discussed.",
     "keywords": ["Image processing and analysis", "Digital pathology", "Virtual microscopy", "Whole-slide imaging", "Immunohistochemistry", "Web platform"]},
    {"article name": "Automated detection of uterine contractions in tocography signals – Comparison of algorithms",
     "doi": "https://doi.org/10.1016/j.bbe.2016.08.005",
     "publication date": "01-2016",
     "abstract": "Monitoring of uterine contractile activity enables to control the progress of labor. Automated detection of contractions is an integral part of the signal analysis implemented in computer-aided fetal surveillance system. Comparison of four algorithms for automated detection of uterine contractions in the signal of uterine mechanical activity is presented. Three algorithms are based generally on analysis of the frequency distribution of signal values. The fourth method relies on analyzing the rate of changes of the uterine activity signal. The reference data in form of beginning and end of contraction episodes were provided by human experts. Obtained results show that all algorithms were capable to detect above 91% reference contractions, and less than 7% of recognized patterns were false. Two algorithms can be distinguished as providing a higher performance expressed by the sensitivity of 95% and the positive predictive value of 97%. Such results could be obtained by optimization of contraction validation criteria.",
     "keywords": ["Uterine contractile activity", "Tocography", "Automated contraction detection", "Fetal monitoring"]},
    {"article name": "Multiclassifier systems applied to the computer-aided sequential medical diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.08.001",
     "publication date": "01-2016",
     "abstract": "The diagnosis of patient's state based on results of successive examinations is common task in the medicine. In computer-aided algorithms taking into account the patient's history in order to improve the quality of classification seems to be very reasonable solution. In this study, two original multiclassifier systems (MC) for the computer-aided sequential diagnosis are developed, which differ with decision scheme and the methods of combining of base classifiers. The first MC system is based on dynamic ensemble selection scheme and works in two-level structure. The second MC system in combining procedure uses original concept of meta-Bayes classifier and produces decision according to the Bayes rule.Both MC systems were practically applied to the diagnosis of human acid–base equilibrium states and compared with some state-of-the-art sequential diagnosis methods. Results obtained in experimental investigations imply that MC system is effective approach, which improves recognition accuracy in sequential diagnosis scheme.",
     "keywords": ["Multiclassifier systems", "Sequential medical diagnosis", "Dynamic ensemble selection", "Meta-Bayes classifier", "Acid\u2013base equilibrium states"]},
    {"article name": "Early stage of chronic kidney disease by using statistical evaluation of the previous measurement results",
     "doi": "https://doi.org/10.1016/j.bbe.2016.08.004",
     "publication date": "01-2016",
     "abstract": "Chronic kidney disease (CKD) that causes the progressive losses in kidney functions is one of the major public health problems. Expert medical doctors can diagnose the CKD through symptoms, blood and urine tests in its early stages. However, the diagnosis of CKD might be difficult for expert medical doctors in case of the questionable measurement result. Therefore a new mathematical method that would be helpful to the expert medical doctors is required. It can be said that there is no studies related with automatic diagnosis of CKD in the literature. This study aims to remedy this shortcoming in the literature. In this study, for each of test and symptom values, averages of measurement results were calculated separately for healthy subjects and patients. Then the measured values were marked as “0” or “1” (healthy or patient) according to closeness to average values. Finally, the classification was performed by averaging the values marked for each subject. The success rate of the proposed method is between 96% and 98% according to the age ranges. In conclusion section of the study, how to implement the proposed method in real life is offered.",
     "keywords": ["Chronic kidney disease", "Chronic renal failure", "Statistical evaluation", "Signal processing", "CKD"]},
    {"article name": "Development of a fuzzy-driven system for ovarian tumor diagnosis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.08.003",
     "publication date": "01-2016",
     "abstract": "In this paper we present OvaExpert, an intelligent system for ovarian tumor diagnosis. We give an overview of its features and main design assumptions. As a theoretical framework the system uses fuzzy set theory and other soft computing techniques. This makes it possible to handle uncertainty and incompleteness of the data, which is a unique feature of the developed system. The main advantage of OvaExpert is its modular architecture which allows seamless extension of system capabilities. Three diagnostic modules are described, along with examples. The first module is based on aggregation of existing prognostic models for ovarian tumor. The second presents the novel concept of an Interval-Valued Fuzzy Classifier which is able to operate under data incompleteness and uncertainty. The third approach draws from cardinality theory of fuzzy sets and IVFSs and leads to a bipolar result that supports or rejects certain diagnoses.",
     "keywords": ["Supporting medical diagnosis", "Ovarian tumor", "Soft computing", "Imprecise and incomplete data", "Fuzzy methods"]},
    {"article name": "Feature projection k-NN classifier model for imbalanced and incomplete medical data",
     "doi": "https://doi.org/10.1016/j.bbe.2016.08.002",
     "publication date": "01-2016",
     "abstract": "Many datasets, especially various historical medical data are incomplete. Various qualities of data can significantly hamper medical diagnosis and are bottlenecks of medical support systems. Nowadays, such systems are often used in medical diagnosis. Even great number of data can be unsuitable when data is imbalanced, missing or corrupted. In some cases these troubles can be overcome by machine learning algorithms designed for predictive modeling.Proposed approach was tested on real medical data and some benchmarks dataset form UCI repository. The liver fibrosis disease from a medical point of view is difficult to treatment and has a significant social and economic impact. Stages of liver fibrosis are diagnosed by clinical observation and evaluations, coupled with a so-called METAVIR rating scale. However, these methods may be insufficient, especially in the recognition of phase of the disease. This paper describes a newly developed algorithm to non-invasive fibrosis stage recognition using machine learning methods – a classification model based on feature projection k-NN classifier. This solution allows extracting data characteristics from the historical data which may be incomplete and may contain imbalance (unequal) sets of patients. Proposed novel solution is based on peripheral blood analysis without using any specialized biomarkers, and can be successfully included to medical diagnosis support systems and might be a powerful tool for effective estimation of liver fibrosis stages.",
     "keywords": ["Liver disease", "Fibrosis stages", "Computer aided diagnosis", "Classifiers", "Features selection methods"]},
    {"article name": "Multi-step process in computer assisted diagnosis of posterior cruciate ligaments",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.007",
     "publication date": "01-2016",
     "abstract": "A multi-step methodology resulting in a three-dimensional visualization and construction of feature vector of posterior cruciate ligament is presented. In the first step the location of the posterior cruciate ligament is established using the fuzzy image concept. The fuzzy image concept is based on the entropy measure of fuzziness extended to two dimensions. In order to reduce the area of analysis, the region of interest including the ligament structures is detected. In this case, the fuzzy C-means algorithm with median modification helping to reduce blurred edges was implemented. After finding the region of interest, the fuzzy connectedness procedure was performed. This procedure permitted to extract the ligament structures. On the basis of the extracted posterior cruciate ligament structures, the three-dimensional visualization of this ligament was built and, with the support of experts’ knowledge, an appropriate feature vector was constructed and its values assigned for normal and pathological cases. Correct results were obtained for over 88% of 97 cases.",
     "keywords": ["Computer-aided diagnosis", "Entropy measure of fuzziness", "Fuzzy C-means algorithm with median modification", "Fuzzy connectedness", "Posterior cruciate ligament", "Segmentation"]},
    {"article name": "Automated object and image level classification of TB images using support vector neural network classifier",
     "doi": "https://doi.org/10.1016/j.bbe.2016.06.008",
     "publication date": "01-2016",
     "abstract": "In this work, digital Tuberculosis (TB) images have been considered for object and image level classification using Multi Layer Perceptron (MLP) neural network activated by Support Vector Machine (SVM) learning algorithm. The sputum smear images are recorded under standard image acquisition protocol. The TB objects which include bacilli and outliers in the considered images are segmented using active contour method. The boundary of the segmented objects is described by fifteen Fourier Descriptors (FDs). The prominent FDs are selected using fuzzy entropy measures. These selected FDs of the TB objects are fed as input to the SVM learning algorithm of the MLP Neural Network (SVNN) and the result is compared with the state-of-the-art approach, Back Propagation Neural Network (BPNN). Results show that the segmentation method identifies the bacilli which retain their shape in-spite of artifacts present in the images. The methodology adopted has significantly enhanced the SVNN accuracy to 91.3% for object and 92.5% for image level classification than BPNN.",
     "keywords": ["Tuberculosis", "Sputum smear images", "Fourier descriptors", "Fuzzy entropy measures", "Support vector neural network", "Back propagation neural network"]},
    {"article name": "Detection of hard exudates using mean shift and normalized cut method",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.001",
     "publication date": "01-2016",
     "abstract": "As diabetic retinopathy (DR) is one of the main causes of loss of vision among diabetic patients, an early detection using automated detection techniques can prevent blindness among diabetic patients. Hard exudates constitute one of the early symptoms of DR and this paper describes a method for its detection using fundus images of retina, employing a combination of morphological operations, mean shift (MS), normalized cut (NC) and Canny's operation. This combined technique avoids over segmentation and at the same time reduces the time complexity while clearly delineating the exudates. Output of the proposed method is evaluated using public databases and produces sensitivity, specificity and accuracy as 98.80%, 98.25% and 98.65%, respectively. The ROC curve gives 0.984 as area under curve. The sensitivity, specificity, accuracy and area under curve of ROC indicate the effectiveness of the method.",
     "keywords": ["Mean shift", "Normalized cut", "Image segmentation", "Retina", "Hard exudates"]},
    {"article name": "An attempt to localize brain electrical activity sources using EEG with limited number of electrodes",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.002",
     "publication date": "01-2016",
     "abstract": "A very interesting research goal is to find underlying sources generating the EEG signal – referred to as the “EEG inverse problem”. Its aim is to determine spatial distribution of brain activity, described by local brain currents density, on the basis of potentials measured on the scalp as EEG signal. The purpose of the research presented in the article was to check whether the results of the inverse problem solution, obtained by the LORETA algorithm for the reduced set of 8 electrodes selected by the authors will be close to the results for the initial set of 32 electrodes. EEG signals were registered during the BCI operation based on ERD/ERS potentials. Obtained results showed no significant differences in the location of the most important sources in both cases. It is worth emphasizing that reducing the number of electrodes would have a significant impact on an BCI ergonomics.",
     "keywords": ["LORETA", "Feature extraction", "Feature selection", "EEG inverse problem", "Brain-computer interface", "BCI"]},
    {"article name": "Hierarchical classification of normal, fatty and heterogeneous liver diseases from ultrasound images using serial and parallel feature fusion",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.003",
     "publication date": "01-2016",
     "abstract": "This study presents a computer-aided diagnostic system for hierarchical classification of normal, fatty, and heterogeneous liver ultrasound images using feature fusion techniques. Both spatial and transform domain based features are used in the classification, since they have positive effects on the classification accuracy. After extracting gray level co-occurrence matrix and completed local binary pattern features as spatial domain features and a number of statistical features of 2-D wavelet packet transform sub-images and 2-D Gabor filter banks transformed images as transform domain features, particle swarm optimization algorithm is used to select dominant features of the parallel and serial fused feature spaces. Classification is performed in two steps: First, focal livers are classified from the diffused ones and second, normal livers are distinguished from the fatty ones. For the used database, the maximum classification accuracy of 100% and 98.86% is achieved by serial and parallel feature fusion modes, respectively, using leave-one-out cross validation (LOOCV) method and support vector machine (SVM) classifier.",
     "keywords": ["Wavelet packet transform", "Gabor filter bank", "Gray level co-occurrence matrix", "Completed local binary pattern", "Feature fusion", "Fatty liver"]},
    {"article name": "Automatic epilepsy detection using wavelet-based nonlinear analysis and optimized SVM",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.004",
     "publication date": "01-2016",
     "abstract": "Aiming at the problems of low accuracy, poor universality and functional singleness for seizure detection, an effective approach using wavelet-based non-linear analysis and genetic algorithm optimized support vector machine (GA-SVM) is proposed to deal with five challenging classification problems in this study. Instead of the traditional discrete wavelet transform (DWT), we attempt to explore the ability of double-density discrete wavelet transform (DD-DWT) to decompose the original EEG into specific sub-bands. The Hurst exponent (HE) and fuzzy entropy (FuzzyEn) are extracted as input features and then fed into two classifiers. On using these ranking non-linear features, the GA-SVM configured with fewer features is found to achieve the prominent classification performance for various combinations such as AB-CD-E, A-D-E, ABCD-E, C-E and D-E, achieving accuracies of 99.36%, 99.60%, 99.40%, 100% and 100%, respectively. The results have indicated that our scheme is not only appropriate in solving problems with multiple classes but also of lower complexity and better expansibility. These characteristics would make this method become an attractive alternative for actual clinical diagnosis.",
     "keywords": ["DD-DWT", "Non-linear", "HE", "FuzzyEn", "GA-SVM"]},
    {"article name": "Customized porous implants by additive manufacturing for zygomatic reconstruction",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.005",
     "publication date": "01-2016",
     "abstract": "Moderate to severe facial esthetic problems challenge the surgeons to discover alternate ways, to rehabilitate the patients using customized porous designs. Porous metal implants are available for over 30 years, but the pore architecture, is constantly changing to improve the stability and longevity of the implant.To evaluate a customized porous implant produced from electron beam melting and to restore the zygomatic functionality.Two customized zygomatic reconstruction implants-bulk and porous, are designed based on the bone contours and manufactured using state of art-electron beam melting technology. The two designed implants are evaluated based on strength, weight and porosity for the better osseointegration and rehabilitation of the patient.Porous structures due to their light weight, low volume and high surface area provided better specific strength and young's modulus closer to the bone. Microscopic and CT scanning confirmed that the EBM produced porous structures are highly regular and interconnected without any major internal defects.The customized porous implants satisfies the need of lighter implants with an adequate mechanical strength, restoring better functionality and esthetic outcomes for the patients.",
     "keywords": ["Zygomatic reconstruction implants", "Electron beam melting (EBM)", "Fused depositing modeling (FDM)", "Image based surgery", "Porous titanium", "3D modeling"]},
    {"article name": "Analysis of the parameters of respiration patterns extracted from thermal image sequences",
     "doi": "https://doi.org/10.1016/j.bbe.2016.07.006",
     "publication date": "01-2016",
     "abstract": "Remote estimation of vital signs is an important and active area of research. The goal of this work was to analyze the feasibility of estimating respiration parameters from video sequences of faces recorded using a mobile thermal camera. Different estimators were analyzed and experimentally verified. It was demonstrated that the respiration rate, periodicity of respiration, and presence and length of apnea periods could be reliably estimated from signals recorded using a portable thermal camera. The size of the camera and efficiency of the methods allow the implementation of this method in smart glasses.",
     "keywords": ["Respiration rate", "Respiration patterns", "Image processing", "Thermal imaging"]},
    {"article name": "Computer simulation of mucosal waves on vibrating human vocal folds",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.004",
     "publication date": "01-2016",
     "abstract": "A three-dimensional (3D) finite element (FE) fully parametric model of the human larynx based on computer tomografy measurements was developed and specially adapted for numerical simulation of vocal folds vibrations with collisions.The complex model consists of the vocal folds, arytenoids, thyroid and cricoid cartilages. The vocal fold tissue is modeled as a three layered transversal isotropic material composed of the cover, ligament and muscle and compared with a four layered material where part of the cover was substituted by a liquid layer modelling the superficial layer of lamina propria.First, the basic frequency-modal properties of the model are presented for a given pretension of the vocal folds. The results of numerical simulation of the vocal folds oscillations excited by a prescribed intraglottal aerodynamic pressure are then presented. The results computed in time domain show the 3D motion of the vocal folds in all three directions (horizontal, vertical and anterior-posterior) and the mucosal waves are clearly modeled in the medial cross-section of the vocal folds. The proper orthogonal decomposition (POD) analysis of the excited modes of vibration shows that when taking account of the superficial sub-layer inside the lamina propria with liquid like properties the POD modes are in better agreement with the empirical eigenfunctions (EEF) obtained from measurements performed on excised human larynges.Finally, the usability of the POD analysis for simulation of pathological situations is demonstrated considering a vocal fold nodule located on the upper cranial margin of the right vocal fold.",
     "keywords": ["Biomechanics of human voice", "3D FE model of human larynx", "Finite element method", "Proper orthogonal decomposition analysis"]},
    {"article name": "Using support vector regression in gene selection and fuzzy rule generation for relapse time prediction of breast cancer",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.003",
     "publication date": "01-2016",
     "abstract": "Gene expression profiles have been recently used in survival analysis, tumor classification and ER status identification. The prediction of breast cancer recurrence based on gene expression profile has been regarded in some previous studies in which the procedures were based on the concept of regression functions and fuzzy systems. In this study, a method based on the combination of these two concepts is presented; not only a method for gene selection, but also a systematic way to create fuzzy rules are going to be offered. Due to the ability of type-2 fuzzy systems in handling of uncertain systems, the proposed model is developed to type-2. The results show that this model has been improved in comparison to previous ones.",
     "keywords": ["Support vector regression", "Type 2 fuzzy logic", "Relapse time"]},
    {"article name": "Hybrid cardiovascular simulator as a tool for physical reproduction of the conditions prevailing in the apex of the heart",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.006",
     "publication date": "01-2016",
     "abstract": "This paper presents the results of research focused on the adaptation of a hybrid simulator of the human circulatory system to the physical reproduction of the haemodynamic conditions prevailing in the apex of the heart. This report describes the principle of operation of the hybrid simulator and presents two methods of its modification. The work includes analysis of the algorithm verification and describes problems that appeared during research. A comparison of the results obtained for both modification methods is shown, as well as preliminary simulation results for a constant-flow ventricle assist device joined to the hybrid simulator operating in the apex of the heart-aorta configuration.",
     "keywords": ["Cardiovascular system model", "Ventricle assist device (VAD)", "Parallel apex of the heart-aortic assistance", "Constant-flow rotary pumps"]},
    {"article name": "Percutaneous double lumen cannula for right ventricle assist device system: A computational fluid dynamics study",
     "doi": "https://doi.org/10.1016/j.bbe.2016.04.002",
     "publication date": "01-2016",
     "abstract": "Our goal is to develop a double lumen cannula (DLC) for a percutaneous right ventricular assist device (pRVAD) in order to eliminate two open chest surgeries for RVAD installation and removal. The objective of this study was to evaluate the performance, flow pattern, blood hemolysis, and thrombosis potential of the pRVAD DLC.Computational fluid dynamics (CFD), using the finite volume method, was performed on the pRVAD DLC. For Reynolds numbers <4000, the laminar model was used to describe the blood flow behavior, while shear-stress transport k–ω model was used for Reynolds numbers >4000. Bench testing with a 27 Fr prototype was performed to validate the CFD calculations.There was <1.3% difference between the CFD and experimental pressure drop results. The Lagrangian approach revealed a low index of hemolysis (0.012% in drainage lumen and 0.0073% in infusion lumen) at 5 l/min flow rate. Blood stagnancy and recirculation regions were found in the CFD analysis, indicating a potential risk for thrombosis.The pRVAD DLC can handle up to 5 l/min flow with limited potential hemolysis. Further modification of the pRVAD DLC is needed to address blood stagnancy and recirculation.",
     "keywords": ["Heart failure", "Computational fluid dynamics", "Ventricular assist device", "Double lumen cannula", "Percutaneous"]},
    {"article name": "Non-linear viscoelastic constitutive model for bovine cortical bone tissue",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.005",
     "publication date": "01-2016",
     "abstract": "In the paper a constitutive law formulation for bovine cortical bone tissue is presented. The formulation is based on experimental studies performed on bovine cortical bone samples. Bone tissue is regarded as a non-linear viscoelastic material. The constitutive law is derived from the postulated strain energy function. The model captures typical viscoelastic effects, i.e. hysteresis, stress relaxation and rate-dependence. The elastic and rheological constants were identified on the basis of experimental tests, i.e. relaxation tests and monotonic uniaxial tests at three different strain rates, i.e. λ ˙ = 0.1 min − 1 , λ ˙ = 0.5 min − 1 and λ ˙ = 1.0 min − 1 . In order to numerically validate the constitutive model the fourth-order stiffness tensor was analytically derived and introduced to Abaqus® finite element (FE) software by means of UMAT subroutine. The model was experimentally validated. The validation results show that the derived constitutive law is adequate to model stress–strain behaviour of the considered bone tissue. The constitutive model, although formulated in the strain rate range λ ˙ = 0.1 − 1.0 min − 1 , is also valid for the strain rate values slightly higher than λ ˙ = 1.0 min − 1 .The work presented in the paper proves that the formulated constitutive model is very useful in modelling compressive behaviour of bone under various ranges of load.",
     "keywords": ["Constitutive model", "Non-linear viscoelasticity", "Stiffness tensor", "Experimental validation", "FE simulation"]},
    {"article name": "An efficient algorithm of ECG signal denoising using the adaptive dual threshold filter and the discrete wavelet transform",
     "doi": "https://doi.org/10.1016/j.bbe.2016.04.001",
     "publication date": "01-2016",
     "abstract": "This paper proposes an efficient method of ECG signal denoising using the adaptive dual threshold filter (ADTF) and the discrete wavelet transform (DWT). The aim of this method is to bring together the advantages of these methods in order to improve the filtering of the ECG signal. The aim of the proposed method is to deal with the EMG noises, the power line interferences and the high frequency noises that could perturb the ECG signal. This algorithm is based on three steps of denoising, namely, the DWT decomposition, the ADTF step and the highest peaks correction step. This paper presents certain applications of this algorithm on some of the MIT-BIH Arrhythmia database's signals. The results of these applications allow observing the high performance of the proposed method comparing to some other techniques recently published.",
     "keywords": ["ECG signal denoising", "Wavelet coefficients", "Dual threshold", "Adaptive filtering"]},
    {"article name": "Prediction of binding peptides to class I Major Histocompatibility Complex using modified scoring matrices and data splitting strategies",
     "doi": "https://doi.org/10.1016/j.bbe.2016.04.003",
     "publication date": "01-2016",
     "abstract": "Predicting peptides that can bind to MHC class I molecules is an important step in the vaccine design process. Computational approaches have potential to provide good predictive models that save both time and cost of the process. Position Specific Scoring Matrix (PSSM) is a reliable approach when dealing with amino acid sequences. PSSM formation involves carefully selecting its constructing data and parameters. In this work, we apply three different data splitting strategies and propose alternative values for the embedded PSSM parameters. The basic principle of data splitting is to choose train data that is able to represent the whole data. We propose using the Kennard–Stone algorithm to highlight the importance of choosing the data constituting the PSSM. Furthermore, this work proposes modifications to PSSM parameters and studies the model behavior in response to each change. The model is applied to experimental data for the Major Histocompatibility Complex of class I. Performance of modified parameters show either comparable or better results to conventional parameters. Moreover, Kennard–Stone data splitting algorithm contributed to significant model performance enhancement.",
     "keywords": ["Data splitting", "Epitope prediction", "Major Histocompatibility Complex", "Position specific scoring matrix", "Vaccine design"]},
    {"article name": "A novel feature extraction approach based on ensemble feature selection and modified discriminant independent component analysis for microarray data classification",
     "doi": "https://doi.org/10.1016/j.bbe.2016.05.001",
     "publication date": "01-2016",
     "abstract": "Microarray data play critical role in cancer classification. However, with respect to the samples scarcity compared to intrinsic high dimensionality, most approaches fail to classify small subset of genes. Feature selection techniques can reduce the dimension of the problem, which can reduce computational cost of the microarray data classification. However, previous studies have shown that feature extraction methods can also be useful in improving the performance of data classification. In this paper, we propose an ensemble schema for cancer diagnosis and classification that has three stages. At first, a hybrid filter-based feature selection method using modified Bayesian logistic regression (BLogReg), Ttest and Fisher ratio is applied for selecting genes. In the second stage, selected genes are mapped via the proposed PSO-dICA method which is a modification of dICA. Finally, mapped features are classified using SVM classifier. To demonstrate the effectiveness of the proposed method, some traditional microarray data including Colon, Lung cancer, DLBCL, SRBCT, Leukemia-ALL and Prostate Tumor datasets are used. Experimental results show the efficiency and effectiveness of the proposed method.",
     "keywords": ["Discriminant independent component analysis", "Feature selection", "Microarray classification", "Particle swarm optimization", "Bayesian logistic regression"]},
    {"article name": "Knee bone segmentation from MRI: A classification and literature review",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.007",
     "publication date": "01-2016",
     "abstract": "Segmentation of cartilage from Magnetic Resonance (MR) images has evolved as a tool for the diagnosis of knee joint pathologies. However, accuracy and reproducibility of automated methods of cartilage segmentation may require the prior extraction of bone surfaces from MR imaging sequences specifically designed to evidence the cartilage and not the bone. Thus a priori knowledge of knee joint structures and fully automated segmentation methods are adopted to provide reliable detection of bone surfaces. In this paper, we review knee bone segmentation methods from MR images. We classified the methods proposed in literature according to the level of a priori knowledge, the level of automation and the level of manual user interaction. Furthermore we discuss the segmentation results in literature in relation to the MR sequences used to image the bone.",
     "keywords": ["Magnetic resonance imaging", "Segmentation methods", "A priori knowledge", "Magnetic resonance sequences", "Knee bone images"]},
    {"article name": "Automatic voice pathology detection and classification using vocal tract area irregularity",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.004",
     "publication date": "01-2016",
     "abstract": "In this paper, an automatic voice pathology detection (VPD) system based on voice production theory is developed. More specifically, features are extracted from vocal tract area, which is connected to the glottis. Voice pathology is related to a vocal fold problem, and hence the vocal tract area which is connected to vocal folds or glottis should exhibit irregular patterns over frames in case of a sustained vowel for a pathological voice. This irregular pattern is quantified in the form of different moments across the frames to distinguish between normal and pathological voices. The proposed VPD system is evaluated on the Massachusetts Eye and Ear Infirmary (MEEI) database and Saarbrucken Voice Database (SVD) with sustained vowel samples. Vocal tract irregularity features and support vector machine classifier are used in the proposed system. The proposed system achieves 99.22% ± 0.01 accuracy on the MEEI database and 94.7% ± 0.21 accuracy on the SVD. The results indicate that vocal tract irregularity measures can be used effectively in automatic voice pathology detection.",
     "keywords": ["Voice pathology detection", "Vocal tract area", "Voice disorders", "Support vector machine"]},
    {"article name": "Human impedance parameter estimation using artificial neural network for modelling physiotherapist motion",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.002",
     "publication date": "01-2016",
     "abstract": "Physiotherapy (physical therapy) is a form of therapy aimed at regaining patients their bodily limb motor functions. The use of what are called therapeutic exercise robots for such purposes is gradually increasing. Therapeutic exercise robots have been developed for lower and upper limbs. These robots lighten the workload of physiotherapists (PTs) by providing the movements on patients’ relevant limbs. In order to get robots to perform the movements that the PT expects the patient to perform, it is required to determine the mechanical impedance parameters (inertia, stiffness and damping) due to the contact between the PT and patient's limb's, and to ensure that the robot moves according to these parameters. The aim of this study is to estimate these impedance parameters by using artificial neural networks (ANNs). Data from experiments on real subjects were used to train the network, and success was obtained using new data not presented to the network before. Subsequently, the previously acquired output was re-directed to the network with the purpose of developing a network, which can learn more accurately. Results have provided the designed ANN structure can generate necessary impedance parameter value to imitate PT motions.",
     "keywords": ["Impedance parameter estimation", "Rehabilitation robotics", "Artificial neural network"]},
    {"article name": "Numerical prediction of the effect of aortic Left Ventricular Assist Device outflow-graft anastomosis location",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.005",
     "publication date": "01-2016",
     "abstract": "A Left Ventricular Assist Device (LVAD) is used to provide haemodynamic support to patients with critical cardiac failure. As LVADs generate continuous flow to better understand the haemodynamic effects of these devices under different working conditions, and particularly in relation to possible outflow-graft anastomosis location, we performed 3D one-way-coupled fluid–structure-interaction (FSI) for three different LVAD working conditions and with the anastomosis location in the ascending aorta and in the descending aorta. The anatomical model used in this study is a patient-specific geometry reconstructed from computed tomography images and the mechanical support considered is similar to the Jarvik 2000® Heart LVAD. Endothelial cells can be influenced by wall stress generated from the blood flow in the artery, so they can produce vascular complications. For this reason, the second aim of this study is to evaluate and analyse, using different mechanical indicators, the wall shear distribution upon the luminal surface of the aorta generated by an LVAD. These numerical investigations demonstrate the utility of one-way-coupled FSI models to compare the haemodynamic conditions for the two LVAD outflow-grafts anastomosis locations and how both affect the aorta and its wall stress. Furthermore, the mechanical indicators allow the identification of wall regions at greater risk of atherosclerosis. The results of this study indicate that an LVAD outflow-graft anastomosis location in the ascending aorta is the optimal configuration.",
     "keywords": ["Left Ventricular Assist Device", "Cardiovascular simulation", "Fluid\u2013structure-interaction", "Wall shear stress", "Human aorta", "3D reconstruction"]},
    {"article name": "A new diagnostic IR-thermal imaging method for evaluation of cardiosurgery procedures",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.007",
     "publication date": "01-2016",
     "abstract": "Two methods for monitoring the state of the myocardium during cardiosurgical interventions based on thermal IR imaging are presented below. These methods, called static thermography and active dynamic thermography (ADT), use information about the distribution of temperature on the surface, and an external excitation source to induce thermal transient processes in a tested object. Recording the time series of thermograms allows calculating parametric images – the distribution of the thermal time constant on the visible surface of the myocardium – correlated with the physiological state of the tested tissues. The temperature allows monitoring of vascularization in each phase of cardiosurgical interventions. This is a perfect method for the evaluation of the quality of the inserted graft, as well as the efficiency of cardioplegia, and the quality of many surgical procedures in clinical practice. Such monitoring is prompt, easy and objective, especially if dynamic processes are investigated. During LAD occlusion, the ADT procedure was applied using a cooling external excitation source. In summary, the calculated time constant images provide data of the tested structure and functional information of myocardium infarct. This allows tracking changes in the blood flow in the myocardium and enables the inspection of the quality of the intervention during cardiosurgical procedures.",
     "keywords": ["Cardiosurgery", "Dynamic thermography", "Image processing", "Thermal excitation"]},
    {"article name": "A new baroreflex sensitivity index based on improved Hilbert–Huang transform for assessment of baroreflex in supine and standing postures",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.006",
     "publication date": "01-2016",
     "abstract": "The aim of this study is to propose a new baroreflex sensitivity (BRS) index using improved Hilbert–Huang transform (HHT) using weighted coherence (CW) criterion and apply it to assess baroreflex in supine and standing postures. Improved HHT is obtained by addressing the mode mixing and end effect problems associated with empirical mode decomposition which is a required step in the computation of HHT and thus mitigating the unwanted low frequency component from the power spectrum. This study was first performed on synthetic signals generated using integral pulse frequency model and further extended to real RR interval and systolic blood pressure records of 50 healthy subjects, 20 post acute myocardial infarction patients undergoing postural stress from supine to standing position. Evaluation is also performed on standard EuroBaVar database, comprising of 21 subjects, under supine and standing positions. The results are (i) enhanced values of supine-to-standing low frequency BRS index (α-LF) equal to 1.78 and high frequency BRS index (α-HF) equal to 2.48 are obtained using improved HHT compared to standard HHT (α-LF = 1.54, α-HF = 2.36) and traditional power spectral density (α-LF = 1.55, α-HF = 2.34) for healthy subjects, (ii) there is an increased rate of change of LF/HF power ratios from supine to standing positions, and (iii) number of BRS responses obtained using CW criterion are greater than those obtained by using mean coherence criterion. In conclusion, the new BRS index takes into consideration the non-linear nature of interactions between heart rate variability and systolic blood pressure variability.",
     "keywords": ["Baroreflex sensitivity (BRS)", "Power spectral density (PSD)", "Hilbert\u2013Huang transform (HHT)", "Empirical mode decomposition (EMD)", "Hilbert marginal spectrum (HMS)", "Weighted coherence (CW)"]},
    {"article name": "A portable system for autoregulation and wireless control of sensorized left ventricular assist devices",
     "doi": "https://doi.org/10.1016/j.bbe.2016.02.001",
     "publication date": "01-2016",
     "abstract": "End stage heart failure patients could benefit from left ventricular assist device (LVAD) implantation as bridge to heart transplantation or as destination therapy. However, LVAD suffers from several limitations, including the presence of a battery as power supply, the need for cabled connection from inside to outside the patient, and the lack of autonomous adaptation to the patient metabolic demand during daily activity. The authors, in this wide scenario, aim to contribute to advancement of the LVAD therapy by developing the hardware and the firmware of a portable autoregulation unit (ARU), able to fulfill the needs of sensorized VAD in terms of physic/physiological data storing, continuous monitoring, wireless control from the external environment and automatic adaptation to patient activities trough the implementation of autoregulation algorithms. Moreover, in order to answer the rules and safety requirements for implantable biomedical devices, a user control interface (UCI), was developed and associated to the ARU for an external manual safe control. The ARU and UCI functionalities and autoregulation algorithms have been successfully tested on bench and on animal, with a response time of 1 s for activating autoregulation algorithms.Animal experiments showed as the presence of the ARU do not affect the animal cardiovascular system, giving a proof of concept of its applicability in vivo.",
     "keywords": ["Heart failure", "Sensorized LVADs", "Portable monitoring and autoregulation unit", "Safety unit", "Wireless monitoring"]},
    {"article name": "Epileptic seizure detection based on improved wavelet neural networks in long-term intracranial EEG",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.001",
     "publication date": "01-2016",
     "abstract": "Automatic seizure detection is of great importance for speeding up the inspection process and relieving the workload of medical staff in the analysis of EEG recordings. In this study, a method based on an improved wavelet neural network (WNN) is proposed for automatic seizure detection in long-term intracranial EEG. WNN combines the traditional back propagation neural network (BPNN) with wavelet transform. Compared with classic WNN architectures, a modified point symmetry-based fuzzy c-means (MSFCM) algorithm is applied to the initialization of wavelet transform's translations, which has been successful in multiclass cancer classification. In addition, Fast-decaying Morlet wavelet is chosen as the activation function to make the WNN learn faster. Relative amplitude and relative fluctuation index are extracted as a feature vector to describe the variation of EEG signals, and the feature vector is then fed into WNN for classification. At last, post-processing including smoothing, channel fusion and collar technique is adopted to achieve more accurate and stable results. This system performs efficiently with the average sensitivity of 96.72%, specificity of 98.91% and false-detection rate of 0.27 h−1. The proposed approach achieves high sensitivity and low false detection rate, which demonstrates its potential for clinical usage.",
     "keywords": ["Seizure detection", "EEG", "Modified point symmetry-based fuzzy c-means", "Wavelet neural network"]},
    {"article name": "Three-dimensional finite element simulation of intrusion of the maxillary central incisor",
     "doi": "https://doi.org/10.1016/j.bbe.2016.02.003",
     "publication date": "01-2016",
     "abstract": "The aim of this study is to generate a global digital model of treatment, analysis of stress distribution and displacements: in a construction of the bracket, in the incisor with bonded bracket, in tissues of the incisor, in a periodontal membrane and in an alveolus.An orthodontic therapy was provided with a three-dimensional model of a unique Cannon Ultra bracket. The placement of the bracket to the incisor was provided according to clinical standards. Composite material was placed between the rough surface of the bracket's base and labial incisor surface – which, in a digital model, resulted in contact without displacement. The bracket was loaded. An orthodontic arch wire was free to move in a wing slot of the bracket. For simplification, a force vector was parallel to the longitudinal axis of the incisor. A clamper was set on the surface of the cortical bone of the alveolus. The model was divided into a finite number of tetrahedral elements. To calculate the distribution of stress Ansys Workbench software was used.The stress values indicate that there were no tissue overloaded areas. The stress distribution was regular in the periodontal ligament. Slight movements were observed with maximal values in the area of apex.This study simulation proves that tissues surrounding the tooth were influenced mechanically by the force loaded on the bracket. According to the results of the study, the simulated treatment should be successful. The bracket transferred the load from the wire to the alveolar ridge.",
     "keywords": ["CBCT cone beam computed tomography", "cone beam computed tomography", "FEM finite element method", "finite element method", "PDL periodontal ligament", "periodontal ligament", "Finite element method", "Cone beam computed tomography", "Modelling", "Intrusion"]},
    {"article name": "Gait patterns classification based on cluster and bicluster analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2016.03.002",
     "publication date": "01-2016",
     "abstract": "Gait patterns of hemiplegia patients have many potential applications such as assistance in diagnosis or clinical decision-making. Many techniques were developed to classify gait patterns in past years; however, these methods have some limitations. The main goal of the study was to present the performance evaluation results of the new biclustering algorithm called KMB. The second objective was to compare clustering and biclustering methods. The study was performed based on the gait patterns of 41 hemiplegia patients over 12 months post-stroke, at the age of 48.6 ± 19.6 years. Spatial–temporal gait parameters and joint moments were measured using motion capture system and force plates. Clustering and biclustering algorithms were applied for data consisting of joint moments of lower limbs. The obtained results of this study based on joint moments, clustering, and biclustering can be applied to evaluate patient condition and treatment effectiveness. We suggest that the biclustering algorithm compared to clustering algorithms better characterizes the specific traits and abnormalities of the joint moments, especially in case of hemiplegia patients.",
     "keywords": ["Hemiplegia", "Gait patterns", "Clustering", "Biclustering", "Joints moments", "Spatial\u2013temporal gait parameters"]},
    {"article name": "Altered modular organization in schizophrenia patients and analysis using supervised association rule mining",
     "doi": "https://doi.org/10.1016/j.bbe.2016.02.002",
     "publication date": "01-2016",
     "abstract": "Complex neuro-degenerative disorders affect the intrinsic topological architecture of brain connectivity. There are very few studies concentrating on the occurrence of modular changes in the structural and functional connectome of people diagnosed with Schizophrenia. In this study, group averaged analysis on modular organization of 15 healthy and 12 Schizophrenic subjects were performed to understand the topological alterations occurring in brain networks of diseased against normal. The major contributing regions for changes in optimal brain architecture were also identified. It also involves the investigation of individual subject's functional connectivity and the attempts were made to extract the modular specific roles of brain regions through supervised association rule mining. On comparison with group average measurements, it was found to produce similar results and it was understood that inter and intra-module connections evidently varied in Schizophrenia because of alterations in extremely organized modular architecture. This is believed to provide new insights in understanding the complex neuro-degenerative disorder through analysis on modular organization of functional brain networks. Highly influential regions were also determined. These regions were found to be potential biomarkers for Schizophrenia diagnosis.",
     "keywords": ["Schizophrenia", "Graph theory", "Data mining", "Resting state fMRI", "Functional connectome", "Modularity"]},
    {"article name": "Segmentation of brain MR images using rough set based intuitionistic fuzzy clustering",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.001",
     "publication date": "01-2016",
     "abstract": "Intuitionistic fuzzy sets and rough sets are widely used for medical image segmentation, and recently combined together to deal with uncertainty and vagueness in medical images. In this paper, a rough set based intuitionistic fuzzy c-means (RIFCM) clustering algorithm is proposed for segmentation of the magnetic resonance (MR) brain images. Firstly, we proposed a new automated method to determine the initial values of cluster centroid using intuitionistic fuzzy roughness measure, obtained by considering intuitionistic fuzzy histon as upper approximation of rough set and fuzzy histogram as lower approximation of rough set. A new intuitionistic fuzzy complement function is proposed for intuitionistic fuzzy image representation to take into account intensity inhomogeneity and noise in brain MR images. The results of segmentation of proposed algorithm are compared with the existing rough set based fuzzy clustering algorithms, intuitionistic fuzzy clustering and bias corrected fuzzy clustering algorithm. Experimental results demonstrate the superiority of proposed algorithm.",
     "keywords": ["Segmentation", "Magnetic resonance", "Brain image", "Rough set", "Intuitionistic fuzzy set", "Fuzzy c-means clustering"]},
    {"article name": "Classification of auditory brainstem response using wavelet decomposition and SVM network",
     "doi": "https://doi.org/10.1016/j.bbe.2016.01.003",
     "publication date": "01-2016",
     "abstract": "In electrophysiological hearing assessment and diagnosis of brain stem lesions are most often used auditory brainstem evoked potentials of short latency. They are characterized by successively arranged maxima as a function of time, called waves. Morphology of the course, in particular, the timing and amplitude of each wave, allow neurologist diagnosis, which is not an easy task. Neurologist requires experience, attention and very good perception. In order to support the diagnostic process, the authors have developed an algorithm implementing the automated classification of auditory evoked potentials to the group of pathological and physiological cases. The sensitivity and specificity of group numbering of 130 cases are respectively 95% and 98% and classification accuracy is equal to 97%. The procedures developed by the authors for generation of distinctive features based on wavelet decomposition with a SVM network-based classifier have been integrated into a diagnostic application directly interoperable with Nicolet Viking Select (Natus Medical Inc., USA) system data files.",
     "keywords": ["Auditory brainstem response", "Brainstem auditory evoked potentials", "Wavelet decomposition", "Support vector machine"]},
    {"article name": "Treatment of patients with type 1 diabetes – Insulin pumps or multiple injections?",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.002",
     "publication date": "01-2016",
     "abstract": "In theory, the continuous subcutaneous insulin infusion (CSII) has a few advantages over the multiple daily insulin injections (MDI) that should lead to improved glycemic control and lower risk of hypoglycemia. In practice, both treatment regimens allow for adequate control of glycemia. The objective of this review is to discuss the most important factors contributing to this situation. We made a comprehensive evidence-based review of the factors affecting effectiveness of CSII and MDI, with a special attention to algorithms for insulin dose adjustments and the automatic bolus calculators. Regardless of the treatment regimen that is used a few different interdependent factors influence the final result of the intensive insulin therapy. These factors comprise: patients’ education, attitude, emotional stability and compliance, and careful analysis of the treatment results by a physician establishing the appropriate rate of basal insulin infusion or the basal dose of insulin and adjusting insulin doses to: the meals, the planned physical activity and the actual and target glucose levels. Our study implies that good glycemic control in patients with type 1 diabetes requires not only a thorough patient education and complying with medical recommendations, but also an individual determination of therapy goals and ways of achieving them. That is why, regardless of the treatment method that is applied, it is the choice of appropriate algorithms and adjusting them to the patient's way of life what allow for achieving pre-specified therapeutic goals. Technical means such as automatic bolus calculators might supplement but they cannot replace patients education and compliance.",
     "keywords": ["ABC automatic bolus calculator", "automatic bolus calculator", "ADA American Diabetes Association", "American Diabetes Association", "BGa actual blood glucose concentration", "actual blood glucose concentration", "BGt target blood glucose concentration", "target blood glucose concentration", "BW body weight", "body weight", "CAMIT Computer Assisted Meal Related Insulin Therapy", "Computer Assisted Meal Related Insulin Therapy", "CF glucose correction factor", "glucose correction factor", "CHO carbohydrates", "carbohydrates", "CSII continuous subcutaneous insulin infusion", "continuous subcutaneous insulin infusion", "cTDD corrected total daily insulin dose", "corrected total daily insulin dose", "DCCT Diabetes Control and Complications Trial", "Diabetes Control and Complications Trial", "GL glucose load", "glucose load", "HbA1c glycated hemoglobin A1c", "glycated hemoglobin A1c", "ICR insulin to glucose (carbohydrates) ratio", "insulin to glucose (carbohydrates) ratio", "Ins preprandial insulin dose", "preprandial insulin dose", "IOB insulin on board", "insulin on board", "MAGE mean amplitude of glycemic excursions", "mean amplitude of glycemic excursions", "MDI multiple daily insulin injections", "multiple daily insulin injections", "PFC protein-fat coefficient", "protein-fat coefficient", "TBD total basal insulin dose", "total basal insulin dose", "TDD total daily insulin dose", "total daily insulin dose", "Diabetes mellitus", "Type 1 diabetes", "Continuous subcutaneous insulin infusion", "Multiple daily insulin injections", "Automatic bolus calculator"]},
    {"article name": "Effects of various typical electrodes and electrode gels combinations on MRI signal-to-noise ratio and safety issues in EEG-fMRI recording",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.007",
     "publication date": "01-2016",
     "abstract": "To compare the effects of typical Ag/AgCl electrodes and electrode gels on MR images and assess safety hazards for patients during the electroencephalogram (EEG) data simultaneously with functional MRI (fMRI) recordings. So the measurements were conducted to compare the effects of three electrodes, three electrode gels and their combinations on the signal-to-noise ratio (SNR) of MR images at 3 T. Local temperature variation of the phantom for all conditions was also measured in the scanner. Results show that combination of silver-plated copper electrode and electrode gel (composed of carbomer as its main ingredient, with 85% moisture) is best for EEG-fMRI experiments. A sintered Ag/AgCl electrode could also be used as the material of EEG cap if infra-slow EEG-events need to be acquired in EEG-fMRI recording. Additionally, there is no significant heat induction detected. Overall, the methods and results of this study can be used for selecting appropriate EEG electrodes and electrode gels in EEG-fMRI experiments.",
     "keywords": ["EEG electroencephalograms", "electroencephalograms", "fMRI functional magnetic resonance imaging", "functional magnetic resonance imaging", "EEG-fMRI electroencephalograms combined with functional magnetic resonance imaging", "electroencephalograms combined with functional magnetic resonance imaging", "SNR signal-to-noise ratio", "signal-to-noise ratio", "ROI region of interest", "region of interest", "EEG-fMRI", "SNR", "Safety", "Electrode", "Electrode gel"]},
    {"article name": "On ultrasound classification of stroke risk factors from randomly chosen respondents using non-invasive multispectral ultrasonic brain measurements and adaptive profiles",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.004",
     "publication date": "01-2016",
     "abstract": "In this paper, we present a new brain diagnostic method based on a computer aided multispectral ultrasound diagnostics method (CAMUD). We explored the standard values of the relative time of flight (RIT), as well as the attenuation, ATN, of multispectral longitudinal ultrasound waves propagated non-invasively through the brains of a standard Caucasian volunteer population across different ages and genders. For the interpretation of the volunteers health questionnaire and ultrasound data we explored various clustering and classification algorithms, such as PCA and ANOVA. We showed that the RIT and ATN values provide very good estimators of possible physiological changes in the brain tissue and can differentiate the possible high-risk groups obtained by other groups and methods (Russo et al. [1]; Lloyd-Jones et al. [2]; Medscape [3]).Special attention should be given to the subgroup which included almost 39% of the volunteers. Respondents in this group have a significantly increased minimum ATN value (see Classification Trees). These values are strongly correlated with the identified risk of stroke factors being: age, increased alcohol consumption, cases of heart disease and stroke in the family as already shown by Rusco and as incorporated into Lloyd-Jones et al., “Heart Disease and Stroke Statistics – 2009 Update”, by the American Heart Association (AHA) and American Stroke Association (ASA), as updated recently in the 2015 “Stroke Prevention Guidelines”.",
     "keywords": ["Ultrasounds", "Dispersion", "Brain", "Atrial fibrillation", "Stroke"]},
    {"article name": "Immunosensors for human cardiac troponins and CRP, in particular amperometric cTnI immunosensor",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.008",
     "publication date": "01-2016",
     "abstract": "In this paper, the review of immunosensors for selected cardiovascular disease markers: human cardiac troponins and human C-reactive protein (CRP) is presented. In particular, (cTnI) amperometric immunosensor for cTnI measurements in the concentration range useful in medical diagnostics, based on the developed earlier human CRP amperometric immunosensor, is described. The human cTnI is recommended as one of specific myocardial damage biomarkers, and is considered as the “gold standard”, whereas the human CRP is used as the powerful, nonspecific, supplementary biomarker of cardiovascular disease. Carbon, graphite and platinum pastes, used for fabrication of our immunosensor working electrode (WE), were investigated. In the developed simple measuring procedure, based on a direct solid phase enzyme-linked immunosorbent assay (ELISA), for the first time ascorbic acid monophosphate was used for cTnI detection as a substrate in enzymatic reaction of alkaline phosphatase labelling antibodies. Disposable amperometric graphite immunosensors, made on polyester film by means of microdispensing robot, suitable for determination of cTnI in the concentration range 0–35 μg/L with the sensitivity 0.67 μA/(μg/L) and linear correlation coefficient 0.91 were obtained.",
     "keywords": ["Cardiac troponin I", "Human CRP", "Immunosensor", "Amperometry", "Ascorbic acid monophosphate"]},
    {"article name": "Computer aided diagnosis system for abdomen diseases in computed tomography images",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.008",
     "publication date": "01-2016",
     "abstract": "In this paper, a computer aided diagnostic (CAD) system for classification of abdomen diseases from computed tomography (CT) images is presented. The methodology used in this paper is to select the most appropriate machine learning technique of segmentation, feature extraction and classification for each module of proposed CAD. The methodology of selecting appropriate machine learning technique for each module of CAD results in accurate and efficient system. Regions of interest are segmented from CT images of tumor, cyst, calculi and normal liver using active contour models, region growing and thresholding. The CAD presented in this research work exploits the discriminating power of features for classifying abdominal diseases. Therefore, feature extraction module extracts statistical texture descriptors using three kinds of feature extraction methods i.e. Gray-Level co-occurrence matrices (GLCM), Discrete Wavelet Transform (DWT) and Discrete Curvelet Transform (DCT). At the next stage, effective and optimum features of ROIs are selected using Genetic Algorithm (GA). Further, Support Vector Machine (SVM) and Artificial Neural Network (ANN) are used to assess the capability of features for classification of diseases of abdomen. The study is performed on 120 CT images of abdomen (30 normal, 30 tumor, 30 cyst and 30 calculi). It is observed from the results that proposed CAD consists of edge based active contour model combined with optimized statistical texture descriptors using DCT along with ANN as classifier achieves the best diagnostic performance of 95.1%. It is also shown in results that proposed CAD achieves highest sensitivity, specificity of 95% and 98% respectively.",
     "keywords": ["Artificial neural network", "Computer aided diagnosis", "Discrete curvelet transform", "Discrete wavelet transform", "Genetic algorithm", "Image segmentation"]},
    {"article name": "Classification of abnormalities in mammograms by new asymmetric fractal features",
     "doi": "https://doi.org/10.1016/j.bbe.2015.07.002",
     "publication date": "01-2016",
     "abstract": "In this paper we use fractal method for detection and diagnosis of abnormalities in mammograms. We have used 168 images that were carefully selected by a radiologist and their abnormalities were also confirmed by biopsy. These images included asymmetric lesions, architectural distortion, normal tissue and mass lesion where in case of mass lesion they included circumscribed benign, ill-defined and spiculated malignant masses. At first, by using wavelet transform and piecewise linear coefficient mapping, image enhancement were done. Secondly detection of lesions was done by fractal method as a ROI. Since in investigation of breast cancer, it is important that fibroglandular tissues in both breasts be symmetric and for each asymmetric density, evaluation for malignancy is necessary, we define new fractal features based on extracting asymmetric information from lesions. The fractal features were evaluated on 5 data sets using SVM classifier which enabled to achieve high accuracy in classification of mammograms and diagnostic results. We have also investigated the performance of image enhancement in classification of each data set which shows different effects of enhancement on different lesion types.",
     "keywords": ["Fractal features", "Asymmetric features", "Abnormal lesion", "Classification", "Wavelet", "Image enhancement"]},
    {"article name": "Automatic tracking of neural stem cells in sequential digital images",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.001",
     "publication date": "01-2016",
     "abstract": "Neural stem cells are the cells that give rise to the main cell types of the nervous system. Due to their varying size and shape, and random movement, the tracking of these cells in suspension in video sequences is challenging. This paper develops an automatic tracking system for neural stem cells. The system first detects and localizes cells in the image sequence, followed by a feature extraction step for the subsequent cell tracking. Then, the system tracks inactive cells using an improved mean shift algorithm, divisive cells through a context-based technique, and active cells by means of dynamic local prediction (DLP) and gray prediction (GP) algorithms. Experimental results show that the proposed system not only improves the accuracy of fast moving tracking, but also constructs accurately the trajectories of the cell movement and reduces the iterations during the center searching.",
     "keywords": ["Cell tracking", "Improved mean shift", "Dynamic local prediction (DLP)", "Gray prediction (GP)", "Neural stem cells"]},
    {"article name": "A novel approach for detection and delineation of cell nuclei using feature similarity index measure",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.002",
     "publication date": "01-2016",
     "abstract": "Accurate image segmentation of cells and tissues is a challenging research area due to its vast applications in medical diagnosis. Seed detection is the basic and most essential step for the automated segmentation of microscopic images. This paper presents a robust, accurate and novel method for detecting cell nuclei which can be efficiently used for cell segmentation. We propose a template matching method using a feature similarity index measure (FSIM) for detecting nuclei positions in the image which can be further used as seeds for segmentation tasks. Initially, a Fuzzy C-Means clustering algorithm is applied on the image for separating the foreground region containing the individual and clustered nuclei regions. FSIM based template matching approach is then used for nuclei detection. FSIM makes use of low level texture features for comparisons and hence gives good results. The performance of the proposed method is evaluated on the gold standard dataset containing 36 images (∼8000 nuclei) of tissue samples and also in vitro cultured cell images of Stromal Fibroblasts (5 images) and Human Macrophage cell line (4 images) using the statistical measures of Precision and Recall. The results are analyzed and compared with other state-of-the-art methods in the literature and software tools to prove its efficiency. Precision is found to be comparable and the Recall rate is found to exceed 92% for the gold standard dataset which shows considerable performance improvement over existing methods.",
     "keywords": ["Microscopic images", "Feature similarity index measure", "Macrophages", "Cell nuclei", "Seed detection", "Cell segmentation"]},
    {"article name": "MicroRNA expression prediction: Regression from regulatory elements",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.010",
     "publication date": "01-2016",
     "abstract": "MicroRNAs are known as important actors in post-transcriptional regulation and relevant biological processes. Their expression levels do not only provide information about their own activities but also implicitly explain the behaviors of their targets, thus, in turn, the circuitry of underlying gene regulatory network. In this study, we consider the problem of estimating the expression of a newly discovered microRNA with known promoter sequence in a certain condition where the expression values of some known microRNAs are available. To this end, we offer a regression model to be learnt from the expression levels of other microRNAs obtained through a microarray experiment. To our knowledge, this is the first study that evaluates the predictability of microRNA expression from the regulatory elements found in its promoter sequence. The results obtained through the experiments on real microarray data justify the applicability of the framework in practice.",
     "keywords": ["MicroRNA", "Microarray", "Gene expression"]},
    {"article name": "Recognition of images of finger skin with application of histogram, image filtration and K-NN classifier",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.005",
     "publication date": "01-2016",
     "abstract": "In this paper, non-invasive method of recognition of finger skin was proposed. A plan of study of images of finger skin was proposed. Researches were carried out for three kinds of images: 60 h after injury, 160 h after injury, 450 h after injury. Proposed technique of recognition used methods of signal processing: extraction of magenta color, calculation of histogram, image filtration, calculation of perimeter, and K-NN classifier. A pattern creation process was conducted using 15 training images of finger skin. In the identification process 60 test images were used. The advantage of the presented method is analysis of the finger skin using a smartphone. The proposed approach will help to diagnose pathologies of human skin.",
     "keywords": ["Finger skin", "Recognition", "K-NN classifier", "Histogram", "Image filtration"]},
    {"article name": "Retinal blood vessel segmentation employing image processing and data mining techniques for computerized retinal image analysis",
     "doi": "https://doi.org/10.1016/j.bbe.2015.06.004",
     "publication date": "01-2016",
     "abstract": "Most of the retinal diseases namely retinopathy, occlusion etc., can be identified through changes exhibited in retinal vasculature of fundus images. Thus, segmentation of retinal blood vessels aids in detecting the alterations and hence the disease. Manual segmentation of vessels requires expertise. It is a very tedious and time consuming task as vessels are only a few pixels wide and extend almost throughout entire span of the fundus image. Employing computational approaches for this purpose would help in efficient retinal analysis. The methodology proposed in this work involves sequential application of image pre-processing, supervised and unsupervised learning and image post-processing techniques. Image cropping, color transformation and color channel extraction, contrast enhancement, Gabor filtering and halfwave rectification are sequentially applied during pre-processing stage. A feature vector is formed from the pre-processed images. Principal component analysis is performed on the feature vector. K-means clustering is executed on this outcome to group pixels as either vessel or non-vessel cluster. Out of the two groups, the identified non-vessel group undergoes an ensemble classification process employing root guided decision tree with bagging, while vessel group is left unprocessed as further processing might increase misclassifications of vessels as non-vessels. The resultant segmented image is formed through combining the results of clustering and ensemble classification process. The vessel segmented output from previous phase is post-processed through morphological techniques. The proposed technique is validated on images from publicly available DRIVE database. The proposed methodology achieves an accuracy of 95.36%, which is comparable with the existing blood vessel segmentation techniques.",
     "keywords": ["Retina", "Blood vessels", "Gabor filtering", "Classification", "Clustering", "Fundus images"]},
    {"article name": "New Binary Hausdorff Symmetry measure based seeded region growing for retinal vessel segmentation",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.005",
     "publication date": "01-2016",
     "abstract": "Automated retinal vessel segmentation plays an important role in computer-aided diagnosis of serious diseases such as glaucoma and diabetic retinopathy. This paper contributes, (1) new Binary Hausdorff Symmetry (BHS) measure based automatic seed selection, and (2) new edge distance seeded region growing (EDSRG) algorithm for retinal vessel segmentation. The proposed BHS measure directly provides a binary symmetry decision at each pixel without the computation of continuous symmetry map and image thresholding. In a multiscale mask, the BHS measure is computed using the distance sets of opposite direction angle bins with sub-pixel resolution. The computation of the BHS measure from the Hausdorff distance sets involves point set matching based geometrical interpretation of symmetry. Then, we design a new edge distance seeded region growing (EDSRG) algorithm with the acquired seeds. The performance evaluation in terms of sensitivity, specificity and accuracy is done on the publicly available DRIVE, STARE and HRF databases. The proposed method is found to achieve state-of-the-art vessel segmentation accuracy in three retinal databases; DRIVE-sensitivity (0.7337), specificity (0.9752), accuracy (0.9539); STARE-sensitivity (0.8403), specificity (0.9547), accuracy (0.9424); and HRF-sensitivity (0.8159), specificity (0.9525), accuracy (0.9420).",
     "keywords": ["Vessel segmentation", "Glaucoma", "Diabetic retinopathy", "Seeded region growing", "Symmetry", "Hausdorff distance"]},
    {"article name": "Exposure of the human eye to wind",
     "doi": "https://doi.org/10.1016/j.bbe.2015.07.001",
     "publication date": "01-2016",
     "abstract": "We report an investigation of the exposure of the human eye to wind. The study was carried out at wind speeds of 40, 80, and 160 km/h. The pressure and forces acting on the eye were examined using the ANSYS CFX software package. The results highlight the necessity of using glasses, contact lens, or protective equipment when, for example, riding a motorcycle, skiing, parachuting, and paragliding.",
     "keywords": ["Human eye", "Protective material", "Numerical analysis", "Computational fluid dynamics", "Contact lens"]},
    {"article name": "A biomechanical comparison between tissue stiffness meter and shore type 00 durometer using fresh human fetal membrane cadavers",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.007",
     "publication date": "01-2016",
     "abstract": "A manual palpation is traditionally used on soft tissue stiffness evaluation in clinical practices. However, the palpation is a subjective technique, so quantitative tissue stiffness measurement would be a more reliable method on diagnosing disorders instead of a palpation in medicine. The purpose of this study was to emphasize a new medical device that was capable of measuring soft tissue stiffness.An in vitro investigation with a soft tissue stiffness meter (STSM) was presented and it is compared with a shore type 00 durometer in this study. Soft materials were needed for in vitro experiments to show feasibility of the STSM, so fetal membranes were decided to use on experiments. Five fetal membranes undergoing normal birth (NB) (35 samples, 105 measurements) and four fetal membranes undergoing pre-term birth (PRB) (20 samples, 60 measurements) were collected immediately after delivery. Samples were examined on custom designed tissue holder.Resu*lts of the STSM were in correlation with results of the durometer for NB and PRB (r2 = 0.995 and r2 = 0.996 respectively). Moreover, a tissue stiffness difference between NB and PRB was statistically significant by using STSM (p ≤ 0.001), whereas it was not statistically significant by using durometer (p = 0.360).In conclusion, newly produced device, STSM is more sensitive than durometer even for very small stiffness differences as between NB and PRB fetal membranes.",
     "keywords": ["Stiffness", "Palpation", "Biomechanics", "Biomedical engineering", "Biomedical device design"]},
    {"article name": "Numerical analysis of stent expansion process in coronary artery stenosis with the use of non-compliant balloon",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.009",
     "publication date": "01-2016",
     "abstract": "In the paper the authors present an applied methodology, data and numerical results for numerical analysis of the stent crimping process and stent implantation in the coronary artery stenosis with the use of a non-compliant angioplasty balloon. The authors focused on the modeling methodology of balloon angioplasty with minimum possible simplification, i.e.: a full load path (compression and inflation in single analysis), 3D unsymmetrical geometry and discretization, highly nonlinear material models (hyperelasticity, plastic kinematic formulation, crushable foam) and sophisticated contact models (bodies with highly different stiffness). The use of a highly compressible crushable foam material model for an arterial plaque is considered as the most original part of the work. The presented results allow for better understanding of the mechanisms governing stent crimping and implementation.",
     "keywords": ["Stent", "Angioplasty", "Coronary", "Fea", "Numerical", "Balloon"]},
    {"article name": "DIFFRACT: DIaphyseal Femur FRActure Classifier SysTem",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.003",
     "publication date": "01-2016",
     "abstract": "Determining the types of fractured bones is the most important step of fracture treatment. Different fracture cases may be observed in daily life and each of them may require a specific treatment. It is not possible for a physician to know all fracture types and treatment methods by heart. Therefore, it is needed an effective solution to facilitate such a tedious process.Based on this need, we propose an auxiliary tool called a DIaphyseal Femur FRActure Classifier SysTem (DIFFRACT). The DIFFRACT can automatically classify diaphyseal femur fractures according to the Müller AO Classification system on X-ray images. In DIFFRACT, we have used the Niblack thresholding method to segment X-ray images. We have observed that Niblack is the most effective method for the segmentation of fractured bones since it does not lose information related to the fracture region. Moreover, we have developed a novel pre-processing method called a support vector machine (SVM) based sensitive noise remover to remove the noises occurring in the segmentation step. In addition, we have innovatively proposed two combined feature extraction methods, the bone completeness indicator (BCI) and fractured region mapping (FRM), to classify different types of fractures. We have used a multi-class SVM to determine the type of bone fractures.Based on the detailed experiments, 196 X-ray images were classified into nine classes according to AO-32 with 89.87% success rate. The DIFFRACT may be used as supplementary tool for the determination of fractured femur bones by physicians. It may facilitate decision making process of the physicians.",
     "keywords": ["Femoral diaphyseal fracture", "Computer aided diagnosis", "Classification", "Image processing", "Support vector machine"]},
    {"article name": "Predictive geometrical model of the upper extremity of human fibula",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.003",
     "publication date": "01-2016",
     "abstract": "Computer assisted preoperative planning in orthopedic surgery, as well as designing and manufacturing of personalized fixators, implants and scaffolds requires a good three-dimensional model of bone(s) of the treated patients. Existing methods that convert the Computer Tomography (CT) images into the polygonal three-dimensional models are time-consuming and inefficient. Therefore, we propose a predictive model that allows quick creation of three-dimensional (3D) surface model of a particular bone by measuring the relevant parameters from an X-ray or CT image.In this paper, we present the process of creating a predictive geometrical model using the case of proximal end of fibula as an example. The predictive model is built by defining the referential geometric entities that correspond to anatomical features, based on which appropriate points, axes, planes and curves are created. Using the method of linear and nonlinear regression with four different parameters, which can be measured from X-ray images or anterior-posterior projection of fibula at CT scans, the equations for X, Y and Z coordinates of the selected 168 points are obtained and their predictive values are calculated. These values are used for creating 3D surface model with the aim of two different methods: using loft function and converting these coordinates into point cloud. These models were compared and verified through analysis of deviations and distances between initial model and predictive models. The resulting 3D model has satisfactory accuracy, and the process of its building is much shorter.",
     "keywords": ["Geometrical model", "Parameters", "Fibula", "Prediction", "Regression model"]},
    {"article name": "Recognizing the surgical situs in minimally invasive hip arthroplasty: A comparison of different filtering techniques",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.006",
     "publication date": "01-2016",
     "abstract": "Detecting the soft tissue envelope and determining the work space available of the surgical situs during surgery is important for advanced instrument navigation techniques, wound care treatment, augmented reality, and instrument design. Different filtering techniques were evaluated to increase detectability of the soft tissue envelope.An algorithm was built for a time of flight (TOF) camera which recognizes the boarders of the soft tissue envelope. Different filtering techniques were tested on a dataset of eight surgical siti.By using a median filter, a temporal filter and combining different input information provided by the time of flight camera by a logic operation the proposed algorithm was able to recognize the surgical situs in 73% of the images on average.The use of a TOF camera can introduce a new tool for recognizing the soft tissue envelope of a surgical approach.",
     "keywords": ["Time of flight cameras", "Feature evaluation and selection", "Minimally invasive hip surgery", "Recognizing the surgical situs", "Pattern recognition"]},
    {"article name": "A neuromechanical modeling of spinal cord injury locomotor system for simulating the rehabilitation effects",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.002",
     "publication date": "01-2016",
     "abstract": "Gait recovering after spinal cord injury (SCI) is a regular attempt in neurorehabilitation. For this purpose, various clinical techniques have been proposed until now. However, the feasibility of these techniques has not been theoretically investigated so much. This has been mainly for difficulties of gait modeling in SCI patients. Involving these problems, recently neuromechanical models of gait locomotion have been proposed for examining rehabilitation methods. However, these models were so simple that could not properly express rehabilitation effects. Notably, lesion intensity is a concern that was never attended in prior simulations. Due to this limitation, in this paper a new neuromechanical model is proposed that classifies patients based on intensity of trauma. Explicitly, the complete, severe and non-severe incomplete SCIs are imitated and effects of related clinical rehabilitations are explored. Remarkably, the model indicates an incredible performance in explaining the rehabilitation effects through presenting the compliant results with clinical information. The suitability of this model is mainly for the applied neuromuscular plan that consists of a combined plan of central pattern generator (CPG) and neural reflexes that controls a double segment limb. The validity of this model is further proved by comparing the kinematic and kinetic results to the experimental data.",
     "keywords": ["Neuromechanical modeling", "Neurorehabilitation", "Spinal cord injury", "Gait locomotion", "Central pattern generator"]},
    {"article name": "Quantitative tests-based assessment of biomedical image enhancement procedures",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.011",
     "publication date": "01-2016",
     "abstract": "This paper describes a novel method of images enhancement procedures evaluation. A necessity of such method follows from the fact that the results of morphological or statistical image analysis in medical and/or technological applications strongly depend on the effectiveness of image preprocessing. The proposed method is based on standard images called testing sets composed of several basic patterns. Filtered testing sets are compared to basic patterns and the averaged distances between them are used as primary filtering quality scores. Then, they are used to calculation of several secondary parameters called image restoration errors. The image restoration errors make possible separate characterization of filters’ ability to improve image contrast, discrimination of small details or neglect the influence of image parallel shifts on the visibility of image details. Practical application of the proposed method is illustrated by example of comparison of the quality of three exemplary filters: a one based on second-level morphological spectra, Laplace and Sobel, filters. Similar comparison has been performed on the same filters combined with image binary thresholding procedures. At last, the numerical evaluation is compared to visual filters evaluation based on the results of NMR brain image enhancement reached by using different filtering methods.",
     "keywords": ["Computer-aided image processing", "Biomedical image enhancement", "Image filtering", "Multi-aspect filters evaluation"]},
    {"article name": "Automatic brain hemorrhage segmentation and classification algorithm based on weighted grayscale histogram feature in a hierarchical classification structure",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.001",
     "publication date": "01-2016",
     "abstract": "Brain hemorrhage is the first cause of death in ages between 15 and 24, and the third after heart diseases and cancers in other ages. Saving the lives of such patients completely depends on detecting the correct location and type of the hemorrhage in an early stage. In this paper, an automatic brain hemorrhage detection and classification algorithm on CT images is proposed. To achieve this purpose, after preprocessing, a modified version of Distance Regularized Level Set Evolution (MDRLSE) is used to detect and separate the hemorrhage regions. Then a perfect set of shape and texture features from each detected hemorrhage region are extracted. Moreover, we define a synthetic feature that is called weighted grayscale histogram feature. In this feature, valuable information from shape, position and area of the hemorrhage are integrated with the grayscale histogram of hemorrhage region. After that a synthetic feature selection algorithm is applied to select the most convenient features. Eventually, the segmented regions are classified into four types of the hemorrhages such as EDH, ICH, SDH and IVH by a hierarchical structure of classification. Our proposed algorithm is evaluated on a perfect set of CT-scan images and obtains the accuracy rate of 96.15%, 95.96% and 94.87% for the segmentation of the EDH, ICH, and SDH types, respectively. Also our proposed classification structure provides the accuracy rate of 92.46% and 94.13% for the first and second classifiers of the hierarchical classification structure for classifying the IVH from normal class and the EDH, ICH and SDH hemorrhage classes, respectively.",
     "keywords": ["Brain hemorrhage segmentation and classification", "Level set", "Weighted grayscale histogram", "Hierarchical classification"]},
    {"article name": "Fully automated speaker identification and intelligibility assessment in dysarthria disease using auditory knowledge",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.004",
     "publication date": "01-2016",
     "abstract": "Millions of children and adults suffer from acquired or congenital neuro-motor communication disorders that can affect their speech intelligibility. The automatically characterization of speech impairment can contribute to improve the patient's life quality, and assist experts in assessment and treatment design. In this paper, we present new approaches to improve the analysis and classification of disordered speech. First, we propose an automatic speaker recognition approach especially adapted to identify dysarthric speakers. Secondly, we suggest a method for the automatic assessment of the dysarthria severity level. For this purpose, a model simulating the external, middle and inner parts of the ear is presented. This ear model provides relevant auditory-based cues that are combined with the usual Mel-Frequency Cepstral Coefficients (MFCC) to represent atypical speech utterances. The experiments are carried out by using data of both Nemours and Torgo databases of dysarthric speech. Gaussian Mixture Models (GMMs), Support Vector Machines (SVMs) and hybrid GMM/SVM systems are tested and compared in the context of dysarthric speaker identification and assessment. The experimental results achieve a correct speaker identification rate of 97.2% which can be considered promising for this novel approach; also the existing assessment systems are outperformed with a 93.2% correct classification rate of dysarthria severity levels.",
     "keywords": ["Dysarthria", "Speech processing", "Auditory cues", "GMM", "SVM", "Hybrid GMM/SVM"]},
    {"article name": "Automatic sleep scoring using statistical features in the EMD domain and ensemble methods",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.001",
     "publication date": "01-2016",
     "abstract": "An automatic sleep scoring method based on single channel electroencephalogram (EEG) is essential not only for alleviating the burden of the clinicians of analyzing a high volume of data but also for making a low-power wearable sleep monitoring system feasible. However, most of the existing works are either multichannel or multiple physiological signal based or yield poor algorithmic performance. In this study, we propound a data-driven and robust automatic sleep staging scheme that uses single channel EEG signal. Decomposing the EEG signal segments using Empirical Mode Decomposition (EMD), we extract various statistical moment based features. The effectiveness of statistical features in the EMD domain is inspected. Statistical analysis is performed for feature selection. We then employ Adaptive Boosting and decision trees to perform classification. The performance of our feature extraction scheme is studied for various choices of classification models. Experimental outcomes manifest that the performance of the proposed sleep staging algorithm is better than that of the state-of-the-art ones. Furthermore, the proposed method's non-REM 1 stage detection accuracy is better than most of the existing works.",
     "keywords": ["EEG", "AdaBoost", "Ensemble learning", "Sleep scoring", "EMD"]},
    {"article name": "Computer-aided obstructive sleep apnea screening from single-lead electrocardiogram using statistical and spectral features and bootstrap aggregating",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.003",
     "publication date": "01-2016",
     "abstract": "Automatic sleep apnea screening is important to alleviate the onus of the physicians of analyzing a large volume of data visually. Again, the push towards low-power, portable and wearable sleep quality monitoring systems necessitates the use of minimum number of recording channels to enhance battery life. So, there is a dire need of an automated apnea detection scheme based on single-lead electrocardiogram (ECG). Most of the existing works are based on multiple channels of physiological signals or yield poor performance. The effect of various classification models on algorithmic performance is also poorly explored. In the present work, we propose a statistical and spectral feature based sleep apnea identification scheme that utilizes single-lead ECG signals. Bootstrap aggregating is employed to perform classification. The efficacy of the selected features is demonstrated by intuitive, statistical and graphical analyses. Optimal choices of classifier parameters are also expounded. The performance of the proposed algorithm is evaluated for various classifiers. The performance of our method is also compared to that of the state-of-the-art ones. The proposed method yields accuracy, sensitivity and specificity of 85.97%, 84.14% and 86.83% respectively on a widely used benchmark data-set. Experimental findings backed by statistical and graphical analyses suggest that the proposed method performs better than the existing ones in terms of accuracy, sensitivity, specificity and computational cost.",
     "keywords": ["Sleep apnea", "Classification", "Statistical features", "Spectral features", "Bagging"]},
    {"article name": "Cardiac arrhythmia alarm from optical interferometric signals during resting or sleeping for early intervention",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.006",
     "publication date": "01-2016",
     "abstract": "Diagnostics of cardiac arrhythmias and frequent interventions may contribute to early detection of diseases or even prevent sudden death. Generally electrocardiograph with several on body electrodes at outpatient clinic is applied and the procedure requires a medical expert. We propose cardiac arrhythmia estimation on the basis of heartbeat detection with optical fibers integrated in the bedding. The modified Michelson's interferometer with error detection was used to measure and maximum a-posteriori probability was used to estimate the beat-to-beat intervals. The consistency of heartbeat intervals was examined with simultaneous measurement with clinical electrocardiograph in 10 healthy volunteers and 10 patients with diagnosed heart arrhythmias. Heart beat interval data obtained in patients were examined and irregularities/arrhythmias were identified from the medical guidelines. The current system enables assessment also in home environment without any on-body sensor placement or required assistance. Thus early intervention is possible as the irregularities are submitted to the nurse on duty and stored in the database for subsequent more detailed analysis.",
     "keywords": ["Cardiac arrhythmia", "Interferometer", "Remote monitoring", "Elderly", "Health care", "Medical informatics"]},
    {"article name": "An application of wireless brain–computer interface for drowsiness detection",
     "doi": "https://doi.org/10.1016/j.bbe.2015.08.001",
     "publication date": "01-2016",
     "abstract": "Wirelessly networked systems of sensors could enable revolutionary applications at the intersection of biomedical science, networking and control systems. It has a strong potential to take ahead the applications of wireless sensor networks. In this paper, a wireless brain computer interface (BCI) framework for drowsiness detection is proposed, which uses electroencephalogram (EEG) signals produced from the brain wave sensors. The proposed BCI framework comprises of a braincap containing EEG sensors, wireless signal acquisition unit and a signal processing unit. The signal processing unit continuously monitor the preprocessed EEG signals and to trigger a warning tone if a drowsy state happens. This experimental setup provides longer time EEG monitoring and drowsiness detection by incorporating the clustering mechanism into the wireless networks.",
     "keywords": ["Wireless network", "Clustering", "Drowsiness", "Brain\u2013computer interface"]},
    {"article name": "Application of empirical mode decomposition and artificial neural network for the classification of normal and epileptic EEG signals",
     "doi": "https://doi.org/10.1016/j.bbe.2015.10.006",
     "publication date": "01-2016",
     "abstract": "Epilepsy is a neurological disorder affecting more than 50 million individuals in the world. Analysis of the electroencephalogram (EEG) is a powerful tool to assist neurologists for diagnosis and treatment. In this paper a new feature extraction method based on empirical mode decomposition (EMD) is proposed. The EEG signal is decomposed into intrinsic mode functions (IMFs) by the EMD algorithm and four statistical parameters are calculated over these IMFs constituting the input feature vector to be fed to a multilayer perceptron neural network (MLPNN) classifier. Experimental results carried out on the publicly available Bonn dataset show that an accurate classification rate of 100% is achieved in the discrimination between normal and ictal EEG, and an accuracy of 97.7% is reached in the classification of interictal and ictal EEG signals. Our results are equivalent or outperform recent studies published in the literature.",
     "keywords": ["Electroencephalogram (EEG)", "Seizure detection", "Epilepsy", "Empirical mode decomposition (EMD)", "Statistics", "Artificial neural network (ANN)"]},
    {"article name": "A new approach for the classification of event related potentials for valid and paradox reasoning",
     "doi": "https://doi.org/10.1016/j.bbe.2015.12.004",
     "publication date": "01-2016",
     "abstract": "In the present paper, a novel approach is introduced for comparing and classifying recorded ERP signals from subjects applying valid (Aristotle's) and paradox (Zeno's) syllogisms. In fact, the authors conceived and realized a corresponding experiment, as well as a new method for processing, fitting and classifying the corresponding captured ERP signals into groups according to their similarity. Subsequently, for each such group, an ideal curve that represents all signals of the group has been evaluated for valid and paradox reasoning separately. These “ideal representatives” manifest essential statistical differences per subject for a considerable number of electrodes (5 electrodes with 99% level of confidence, 14 electrodes with 95% level of confidence, 17 electrodes with 90% level of confidence). These results support the assumption that the obtained ideal representatives may indeed reflect essential differences in the underlying brain functions which generated the obtained ERPs. Equivalently, one may claim that the performed experiment and the associated results manifest statistically essential differences between the mental functions during valid and paradox reasoning.",
     "keywords": ["Event related potentials (ERPs)", "Curve fitting", "Valid reasoning", "Paradox syllogism", "Aristotle's reasoning", "Zeno's paradoxes"]},
    {"article name": "Early diagnosis of threatened premature labor by electrohysterographic recordings – The use of digital signal processing",
     "doi": "https://doi.org/10.1016/j.bbe.2015.11.005",
     "publication date": "01-2016",
     "abstract": "Prevention and early diagnosis of imminent preterm labor are considered to be the most important perinatal challenge nowadays. Significant progress has been observed on postnatal care of premature infants, but without reducing the prevalence of preterm delivery.Our study was focused on comparison of three methods of spectral analysis of electrohysterographic (EHG) signals: fast Fourier transform (FFT), wavelet transform (WT) and autoregressive modeling (AR). Complexity of the electrohysterographic signals was analyzed by using: the approximate entropy (ApEn), Lempel–Ziv complexity measure (L–Z). Additionally, the work evaluated the applicability of EHG in diagnosing imminent premature labor.EHG signals were recorded among 60 patients with threatened preterm labor symptoms between the 24th and 34th week of pregnancy. Patients included to the study had a shortened cervix (less than 20 mm) without regular uterine contractions recorded on regular cardiotocography (CTG). The women were divided into two groups: those delivering within 7 days – group A (n = 15) and women delivering after 7 days – group B (n = 45).The study confirmed differences in bioelectrical activity of uterus between patients delivering prematurely within 7 days and after from the EHG registration for all analyzed methods.",
     "keywords": ["Uterine contraction", "Electrohysterography", "Preterm labor", "Spectral analysis", "Complexity measures"]},
    {"article name": "Analysis of heart rate variability as a predictor of mortality in cardiovascular patients of intensive care unit",
     "doi": "https://doi.org/10.1016/j.bbe.2015.05.004",
     "publication date": "01-2015",
     "abstract": "Dynamic changes of heart rate variability (HRV) reflect autonomic dysfunction in cardiac disease. Some studies suggest the role of HRV in predicting intensive care unit (ICU) mortality. The main object of this study was analyzing the HRV to design an algorithm to predict mortality risk.We evaluated 80 cardiovascular ICU patients (45 males and 45 females), ranging from 45 to 70 years. Common time and frequency domain analysis, non-linear Poincaré plot and recurrence quantification analysis (RQA) were used to study the HRV in two episodes. The episodes include 8–4 h before death, and 4 h before death to death. Independent sample t-test was used as statistical analysis.Statistical analysis indicates that frequency domain and Poincaré parameters such as LF/HF and SD2/SD1 show changes in transition to death episode (p < 0.05). Moreover, Lmean, vmax and RT measures showed meaningful changes (p < 0.01) in closer segments to the death.Analysis of physiological variables shows that there are significant differences in RQA measures in episodes close to death. These changes can be interpreted as more stability and determinism behavior of HRV in episodes close to death. RQA parameters can be used together with HRV parameters for description and prediction of mortality risk in ICU patients.",
     "keywords": ["HRV heart rate variability", "heart rate variability", "ICU intensive care unit", "intensive care unit", "RQA recurrence quantification analysis", "recurrence quantification analysis", "RP recurrence plots", "recurrence plots", "REC recurrence rate", "recurrence rate", "ENTR entropy", "entropy", "TT trapping time", "trapping time", "RT recurrence trend", "recurrence trend", "Mortality", "ICU", "HRV", "Linear analysis", "Non-linear Poincar\u00e9 analysis", "RQA"]},
    {"article name": "Estimation of light detection efficiency for different light guides used in time-resolved near-infrared spectroscopy",
     "doi": "https://doi.org/10.1016/j.bbe.2015.05.003",
     "publication date": "01-2015",
     "abstract": "Time-resolved near-infrared spectroscopy is a technique enabling the assessment of changes in oxygenation and perfusion of tissue with depth discrimination. A challenge in time-resolved measurements remains to provide sufficiently high efficiency of photons detection together with high temporal resolution of the setup. The aim of this study was to compare the performance of different fiber bundles and liquid light guides which can be used in time-resolved near-infrared spectroscopy measurements. The comparison was carried out by measurements of the instrument response function and of the responsivity of the optical detection system equipped with different types of light guides. The responsivity was estimated employing a test phantom with known diffuse transmittance factor. The results suggest that application of liquid light guides provides higher efficiency of photon collection in comparison to fiber bundles which are typically used in tissue optics instrumentation.",
     "keywords": ["Diffuse reflectance", "Time-resolved optical measurements", "Optical fiber bundles", "Liquid light guides"]},
    {"article name": "Computer based real time systems for analyzing cardiovascular response to orthostatic stress",
     "doi": "https://doi.org/10.1016/j.bbe.2015.01.001",
     "publication date": "01-2015",
     "abstract": "The cardiovascular response to orthostatic (gravitational) stress has been the focus of several researches in the past. Average values of hemodynamic variables, such as arterial pressure or heart rate are recorded during changes in posture for diagnosing orthostatic stress clinically. Different methods based on varied physical principles have been developed to measure these hemodynamic variables. Carotid artery is responsible for direction of blood flow to brain and provides a vital physiological parameter which can be used to construe cardiac information. A noninvasive system has been built in which a piezoelectric sensor is positioned on the carotid artery of the subject and carotid signals of fifteen human subjects are acquired in various body postures using application softwares. RR intervals and pulse amplitudes are computed after filtering and analyzing the carotid signal recordings using these softwares. The developed system is validated by determining the percentage change in RR interval and pulse amplitude of all the subjects which is found almost same. The technique used in the proposed system may be applied to measure and manage the orthostatic stress.",
     "keywords": ["Carotid pulse", "MATLAB software", "LABVIEW software", "Orthostatic stress", "Piezoelectric sensor"]},
    {"article name": "Verification of the functionality of device for monitoring human tremor",
     "doi": "https://doi.org/10.1016/j.bbe.2015.02.002",
     "publication date": "01-2015",
     "abstract": "Tremor accompanying the Parkinson's disease is perceived as one of its most disturbing symptoms. Among available treatments there is a deep brain stimulation, which effectively reduces unwanted oscillations of patient's muscles. Nevertheless, setting parameters of the stimulation is a highly empirical process and the final outcome depends primarily on the experience of involved medical personnel. We present a device which is meant to provide a clinician with feedback based on the measurable parameters of tremor, monitored in many points of the body simultaneously. Functionality of the device was verified at a basic level. During the verification, the vibrations were recorded: (1) in a relaxed arm, (2) during voluntary contraction of muscles and (3) after being damped by tissues (in this case the vibrations were introduced from an external generator). Moreover, a method of selecting optimal place for mounting vibration probes is presented.",
     "keywords": ["Tremor measurement", "Multi-channel MMG", "Mechanomyography", "Parkinson's disease", "Deep brain stimulation"]},
    {"article name": "Pulsed near infrared laser stimulates the rat visual cortex in vivo",
     "doi": "https://doi.org/10.1016/j.bbe.2015.02.003",
     "publication date": "01-2015",
     "abstract": "Pulsed infrared irradiation is an alternative neural stimulation with the advantages of being non-contact, spatially precise and artifact-free. Although infrared neural stimulation (INS) is well characterized in the peripheral nervous system, research has been limited in the central nervous system (CNS), especially the near infrared with wavelength around 800 nm. To establish feasibility of INS in the CNS, pulsed near infrared laser (λ = 808 nm, pulse duration = 300–1000 μs, radiant exposure = 0.73–2.45 J/cm2, fiber size = 105 μm, repetition rate = 2 Hz) was used to stimulate the primary visual cortex (V1) of anesthetized Long Evans (LE) rats and the near-infrared-evoked neural activities in V1 was recorded. The impact of the duration of infrared pulse on the intensity and the latency of evoked potentials was assessed. We found that V1 was activated by 808 nm laser and the optical evoked potential (OEP) included a descending wave (D1) and an ascending wave (A1) after optical stimuli. Furthermore, with the increase of the stimulation pulse duration, both the amplitude of D1 and the latency of A1 were increased. The results from this paper will facilitate the applications of near infrared neural stimulation on central nervous system.",
     "keywords": ["Near infrared pulse", "Neural stimulation", "Laser diode", "Visual cortex", "Central nervous system"]},
    {"article name": "Strain examinations of the left ventricle phantom by ultrasound and multislices computed tomography imaging",
     "doi": "https://doi.org/10.1016/j.bbe.2015.03.001",
     "publication date": "01-2015",
     "abstract": "The main aim of this study was to verify the suitability of the hydrogel sonographic model of the left ventricle (LV) in the computed tomography (CT) environment and echocardiography and compare the radial strain calculations obtained by two different techniques: the speckle tracking ultrasonography and the multislices computed tomography (MSCT). The measurement setup consists of the LV model immersed in a cylindrical tank filled with water, hydraulic pump, the ultrasound scanner, hydraulic pump controller, pressure measurement system of water inside the LV model, and iMac workstation. The phantom was scanned using a 3.5 MHz Artida Toshiba ultrasound scanner unit at two angle positions: 0° and 25°. In this work a new method of assessment of RF speckles’ tracking. LV phantom was also examined using the CT 750 HD 64-slice MSCT machine (GE Healthcare). The results showed that the radial strain (RS) was independent on the insonifying angle or the pump rate. The results showed a very good agreement, at the level of 0.9%, in the radial strain assessment between the ultrasound M-mode technique and multislice CT examination. The study indicates the usefulness of the ultrasonographic LV model in the CT technique. The presented ultrasonographic LV phantom may be used to analyze left ventricle wall strains in physiological as well as pathological conditions. CT, ultrasound M-mode techniques, and author's speckle tracking algorithm, can be used as reference methods in conducting comparative studies using ultrasound scanners of various manufacturers.",
     "keywords": ["LV left ventricular", "left ventricular", "CT computed tomography", "computed tomography", "MSCT multislices computed tomography", "multislices computed tomography", "RF radio frequency", "radio frequency", "DTI Doppler tissue imaging", "Doppler tissue imaging", "US ultrasound", "ultrasound", "PVA polyvinyl alcohol", "polyvinyl alcohol", "PR pump rate", "pump rate", "SV stroke volume", "stroke volume", "S strain", "strain", "SR strain rate", "strain rate", "RS radial strain", "radial strain", "RSR radial strain rate", "radial strain rate", "ECG electrocardiograph", "electrocardiograph", "Computed tomography", "Echocardiography", "Left ventricle", "Speckles tracking", "Strain", "Ultrasound phantoms"]},
    {"article name": "An automatic aneurysm extraction algorithm in fused brain digital subtraction angiography images",
     "doi": "https://doi.org/10.1016/j.bbe.2015.06.003",
     "publication date": "01-2015",
     "abstract": "Brain aneurysm is one of the most life-threatening events, which is associated with a high rate of mortality and disability. There are many factors, which specify the best treatment option for each particular patient. In this paper, an automatic computer-aided extraction algorithm for brain aneurysm, from fused digital subtraction angiography (DSA) images is proposed. In this algorithm, firstly, to remove vessel structure, morphological operations based on multi-directional structure elements and nonlinear diffusion filtering are used. Then, by applying circular Hough transform and region growing algorithms, the aneurysm extraction procedure is performed. In this step, to overcome to poor edge gradient of aneurysm, we define a labeled diffused image which specifies the region growing conditions. Finally, by using morphological operators, the aneurysm extraction performance of our algorithm is improved. In addition, the radius of extracted aneurysm is defined and reported as a geometric feature. The experimental results indicate that our proposed algorithm obtains accuracy rate of 77.5% for the aneurysm extraction on 30 abnormal cases.",
     "keywords": ["Digital subtraction angiography", "Brain aneurysm extraction", "Circular Hough transform", "Labeled diffused image", "Nonlinear diffusion filtering"]},
    {"article name": "Assembly of repetitive regions using next-generation sequencing data",
     "doi": "https://doi.org/10.1016/j.bbe.2014.12.001",
     "publication date": "01-2015",
     "abstract": "High read depth can be used to assemble short sequence repeats. The existing genome assemblers fail in repetitive regions of longer than average read.I propose a new algorithm for a DNA assembly which uses the relative frequency of reads to properly reconstruct repetitive sequences. The mathematical model for error-free input data shows the upper limits of accuracy of the results as a function of read coverage. For high coverage, the estimation error depends linearly on repetitive sequence length and inversely proportional to the sequencing coverage. The model depicts, the smaller de Bruijn graph dimensions, the more accurate assembly of long repetitive regions.The algorithm requires high read depth, provided by the next-generation sequencers and could use the existing data. The tests on errorless reads, generated in silico from several model genomes, pointed the properly reconstructed repetitive sequences, where existing assemblers fail.The C++ sources, the Python scripts and the additional data are available at http://dnaasm.sourceforge.net.",
     "keywords": ["Genome assembler", "Repetitive sequences", "Mathematical model", "Next generation sequencing", "de Bruijn graph parameters"]},
    {"article name": "Pupillometric sleepiness measurements PST with concurrent video optic sensor of pupillary size",
     "doi": "https://doi.org/10.1016/j.bbe.2015.04.001",
     "publication date": "01-2015",
     "abstract": "The article describes the design solutions of a mobile headset device used for the assessment of involuntary and oscillatory movements of the pupils. The pupillographic sleepiness test (PST) is used to assess the human psychophysiological state influenced by the level of drowsiness or alertness by observing the so-called fatigue wave. Since the overall size of the pupil is controlled predominantly by sympathetic inhibition of the parasympathetic Edinger–Westphal nuclei, spontaneous changes in its size are considered to be the result of decreasing central sympathetic activity. In the state of reduced alertness, changes in pupil size recorded in the dark show slow rhythmic oscillations, called fatigue waves. PST must be carried out in complete darkness (infrared goggles) and silence for a duration of 11 min. Authors used the results of studies conducted before the development of the device. Those results played a significant role in shaping the structural assumptions on the sensor in its function as an indicator of the level of human fatigue. The article includes the results of the experimental research on the sensor's testing process involving variable frequency parameters of light, luminance and chrominance excitations. The obtained results revealed that the type of light stimulating the retina has significant impact on the oscillation parameters of pupils.",
     "keywords": ["Pupillographic sleepiness test", "Video sensor", "Fatigue", "Measurement system"]},
    {"article name": "Evaluation of the biocompatibility of a hydroxyapatite-CaTiO3 coating in vivo",
     "doi": "https://doi.org/10.1016/j.bbe.2015.05.001",
     "publication date": "01-2015",
     "abstract": "This study was designed to evaluate the biocompatibility and osteointegrative activity of hydroxyapatite (HA)-CaTiO3, titanium substrate, traditional HA coating and CaTiO3 coating via an animal experiment.Four types of screws (type 1: coated with HA; type 2: coated with CaTiO3; type 3: coated with HA-CaTiO3; type 4: untreated titanium screws) were implanted into femur bone of 48 New Zealand rabbits. Histological and mechanical investigations were employed at the end of 2, 4, 8 and 12 weeks to evaluate the material osteointegration.(1) All of the experimental rabbits were healthy during the experiment process. (2) Histological investigation showed fully regenerated and well integrated bone tissue surrounding the screws coated with HA, HA-CaTiO3 and CaTiO3. (3) Mechanical investigation showed that the bonding strength of HA-CaTiO3 coating was significantly higher than that of CaTiO3 coating or titanium materials without coating, but was lower than those coated with HA.HA-CaTiO3 coating possesses similar admirable biocompatibility and osteointegration activity with HA coating, indicating a promising coating material for implants in orthopedics.",
     "keywords": ["Biological evaluation", "Biomechanics testing", "Coatings", "HA-CaTiO3", "Hydroxyapatite"]},
    {"article name": "Real-time estimation of the spectral parameters of Heart Rate Variability",
     "doi": "https://doi.org/10.1016/j.bbe.2015.05.002",
     "publication date": "01-2015",
     "abstract": "Spectral Heart Rate Variability (HRV) parameters, LF (low frequency) and HF (high frequency), have an important role in interpreting slower and faster heart rate modulations. An online analysis method of HRV spectral parameters based on the modified Hilbert–Huang Transform (HHT) is proposed in the paper. A number of novel methods have been put forward to meet the demand of causal pre-processing of interbeat time intervals (IBI) series prior to application of HHT. Also in the real-time implementation of the HHT which is the combination of the Empirical Mode Decomposition and Hilbert spectral analysis an original extrapolation method of intrinsic mode function related to LF and HF spectral parameters was applied. The proposed algorithm allows temporal estimation of HRV spectral parameters in real-time with delays being reduced up to 60% with respect to the Short Time Fourier Transform (STFT) analysis. Such reduction in analysis delay can have an important significance in a number of cardiologic invasive procedures, e.g. in cardio-resynchronisation therapy (CRT).",
     "keywords": ["Heart Rate Variability", "HRV", "Instantaneous HRV"]},
    {"article name": "A new approach to robust, weighted signal averaging",
     "doi": "https://doi.org/10.1016/j.bbe.2015.06.002",
     "publication date": "01-2015",
     "abstract": "In this paper, a new approach for robust, weighted averaging of time-aligned signals is proposed. Suppression of noise in such case can be achieved with the use of the averaging technique. The signals are time-aligned and then the average template is determined. To this end, the arithmetic mean operator is often applied to the synchronized signal samples or its various modifications. However, the disadvantage of the mean operator is its sensitivity to outliers. The weighted averaging operation can be regarded as special case of clustering. For that reason in this work the averaging process is formulated as the problem of certain criterion function minimization and a few different cost functions are employed. The maximum likelihood estimator of location based on the generalized Cauchy distribution is used as the cost function. Such approach allows to suppress various types of impulsive noise. The proposed methods performance is experimentally evaluated and compared to the reference methods using electrocardiographic signal in the presence of the impulsive noise and the real muscle noise as well as the case of noise power variations.",
     "keywords": ["Weighted averaging", "Impulsive noise", "Robust filtering", "Myriad", "Meridian", "Generalized Cauchy distribution"]},
    {"article name": "A model based study of a quantitative relation between joint strengthening and the highest achievable speed of human walking",
     "doi": "https://doi.org/10.1016/j.bbe.2015.06.001",
     "publication date": "01-2015",
     "abstract": "There is a common belief that muscle strengthening would enhance the capability of fast walking, but the specific impact of different joint's strength on walking speed and the quantitative relation between them is not well explored. While the majority of the previous works in this area are based on experimental methods, it would be very expensive and time consuming to conduct as much experiment as necessary to establish such a quantitative relation. In the current research, instead of experimental methods, a mathematical framework is utilized to solve this problem. The objective of this paper is to briefly introduce this framework and present the obtained results based on that, for the mentioned relation. To achieve the objective of this paper, the highest achievable speed in sagittal plane with normal joint strength was first determined in the mathematical framework for three age groups. Afterward, the highest achievable speed was calculated for different levels of ankle, knee, and hip strength by changing the strength level in the mathematical model in all the studied groups. The results supported the crucial role of plantar flexors in all ages. It was shown that ankle strengthening up to certain critical value affected the speed significantly; whereas increasing the knee and hip strength may only facilitate fast walking without considerable effect on the speed value. Moreover, the critical level of ankle strengthening decreased with age increment. The attained results could be utilized in planning comprehensive joint strengthening exercises in sports and rehabilitation of subjects with lower limb disabilities.",
     "keywords": ["Joint strength", "Fast walking", "Quantitative relationship", "Age effect"]},
    {"article name": "Computer-aided image analysis for microcapsules’ quality assessment",
     "doi": "https://doi.org/10.1016/j.bbe.2015.05.005",
     "publication date": "01-2015",
     "abstract": "Application of computer-aided image analysis to quality assessment of inner structure of alginate-polyethersulfone microcapsule is presented. The microcapsules are provided for analysis in the form of optical microscope images of their cross-sections. A specialized computer program APEK makes it possible to measure and calculate a set of morphological parameters describing microcapsules’ outer and inner size and shape, as well as the thickness of a polyethersulfone membrane which covers hydrogel microcapsule core. It is described a method of thickness profile of microcapsule's membrane measuring based on skeleton line. Calculations are illustrated by an example. Suggestions concerning future works have been formulated.",
     "keywords": ["Computer-aided image analysis", "Alginate-polyethersulfone microcapsules", "Morphological parameters", "Thickness profile analysis", "Size assessment", "Porosity assessment"]},
    {"article name": "Mobile device for the measurement of threshold perception frequency of the flickering source of visible light",
     "doi": "https://doi.org/10.1016/j.bbe.2014.11.002",
     "publication date": "01-2015",
     "abstract": "The article describes design solutions and test results of a mobile device for the measurement of threshold perception frequency of the flickering source of visible light. The device consists of an optical component, a programmable module and a control module. The measurement can be performed on the light source of any color in conjunction with a colored backlight. The authors of the research work developed and tested a unique solution that integrates a subjective measurement of the flicker frequency ff and the blending frequency fm fusing in the flicker fusion test (FFT) with the registration of pupil vibrations that gives information about the level of activation of the autonomic nervous system (ANS). The ANS activation level is estimated in the test called the pupillographic sleepiness test (PST). It is an objective source of data on the level of fatigue, reduced concentration or sleepiness of a subject. The authors focused on the description of the measurement section related to the measurement of pupillary unrest index (PUI) and FFT parameters. The construction of the device allows for its use both in laboratory tests, as well as in terms of everyday human functioning.",
     "keywords": ["Critical flicker frequency", "Sensor", "Fatigue", "Flicker fusion test", "Pupillographic sleepiness test"]},
    {"article name": "Automatic seed point selection in ultrasound echography images of breast using texture features",
     "doi": "https://doi.org/10.1016/j.bbe.2014.10.001",
     "publication date": "01-2015",
     "abstract": "Automatic segmentation of breast lesions in 2D ultrasound B-scan images via active contours, require a seed point to be selected inside the breast lesion. The grey levels on an ultrasound image of the breast show intensity information. The fat tissue is hypo echoic relative to the surrounding glandular tissue. The glandular parenchyma tissue usually appears homogeneously echogenic as compared with fat lobules. Simple cysts are anechoic. Malignant solid masses are usually heterogeneous, hypo echoic and tend to look intensely black compared to surrounding isoechoic fat. Benign solid masses tend to appear on ultrasound with intense and uniform hyper echogenicity. Texture features represent changes in grey level intensities. This paper proposes a method that can automatically identify a seed point based on texture features and allow automatic contour initialization for level set segmentation. This seed point plotted on an US B-scan image is mapped on to its corresponding elastogram pair. The proposed approach is applied to 199 ultrasound B-scan images of which 52 are benign solid masses, 84 malignant solid masses and 63 simple and complex cysts. The seed point obtained using this approach is mapped to its corresponding elastogram pair in 62 US B-scan and US elastography image pairs. Quantitative experiment results show that our proposed approach can successfully find proper seed points based on texture values, in ultrasound B-scan images and therefore in elastography images, with an overall accuracy of 86.93%. This approach is effective and makes segmentation of breast lesions computationally easier, more accurate and fast.",
     "keywords": ["Active contour", "Echogenicity", "Elastography", "Seed point", "Segmentation"]},
    {"article name": "In silico analysis of methylation of the selected genes using computer programs based on various analytical techniques",
     "doi": "https://doi.org/10.1016/j.bbe.2014.09.002",
     "publication date": "01-2015",
     "abstract": "Selected genes were analyzed in silico in three species: red fox (Vulpes vulpes), raccoon dog (Nyctereutes procyonoides), and dog (Canis lupus familiaris). This type of analysis exemplifies current and potential research on gene expression. Four nucleotide sequences, of the genes IGF1, MYO15A, PAX3 and MC1R, were obtained from the NCBI online database. The analyses focused on the presence of CpG islands and two analytical techniques, BSP and MSP. The results from three computer programs, CpG Island Searcher®, BiSearch® and MethPrimer®, were discussed in detail. The applications were compared in terms of their functionality and usefulness.",
     "keywords": ["Bioinformatics", "DNA methylation", "Epigenetics", "In silico", "MSP", "BSP"]},
    {"article name": "Accuracy of the electrodes location method for simultaneous SPECT and EEG examinations",
     "doi": "https://doi.org/10.1016/j.bbe.2014.10.002",
     "publication date": "01-2015",
     "abstract": "A simultaneous SPECT and EEG examination allows for a combined analysis of brain structural and functional changes. The examinations can be visualized as 3D maps of overlapping SPECT (radiopharmaceutical concentration) and EEG (bioelectric potential) data. Synchronization of both maps is difficult, as SPECT shows neither the skull outline nor the EEG electrodes. Thus a technique to reflect electrodes placement in SPECT data was needed. Earlier we devised a method to make a small number of electrodes visible in SPECT without compromising SPECT accuracy. We also proposed a procedure approximating coordinates of the 10–20 system EEG electrodes in a 3D space using only 5 electrodes coordinates, while assuming that all electrodes are placed on 9 intersecting ellipses. Here we used 20 phantoms of real heads from the BrainWeb project and the Oostenveld calculation of electrodes canonical placement in an averaged head model. We divided the electrodes placement error into an easy-to-assess “distance error” (distance from the head surface) and a difficult-to-assess “angular error” (a wrong direction in relation to the symbolic head center). Applying our procedure to the Oostenveld data set, we assessed the ratio between the distance and the angular error and showed that a majority part of the entire approximation error results from the distance error. Our approximation procedure was applied to the BrainWeb phantoms and the distance error was computed allowing estimation of the entire error of electrodes placement. The estimated average error of the electrodes coordinates’ approximation procedure was 4.2 mm and the maximum error was 15.4 mm.",
     "keywords": ["EEG electrodes", "SPECT", "Multimodal co-registration", "Brain phantoms"]},
    {"article name": "3-D trajectory of body sway angles: A technique for quantifying postural stability",
     "doi": "https://doi.org/10.1016/j.bbe.2015.02.001",
     "publication date": "01-2015",
     "abstract": "The article focuses on a non-invasive method of quantifying human postural stability. Recent alternatives to quantify human postural stability have several limitations – the major one being the evaluation of only two physical quantities of body movement in 3D space – however, a complex movement pattern can be described better using three physical quantities. A cheap 3DOF orientation tracker (Xsens MTx unit) placed on patient's trunk was used to measure roll, pitch and yaw. Using a novel method based on the total length of the 3-D trajectory of body sway angles, we are able to evaluate 3-D movements of the trunk. The trajectory length obtained by plotting roll, yaw and pitch vs. each other (i.e. curve in the 3-D plot) was used to identify a pathological balance control. In this study, ten patients with progressive cerebellar ataxia and eleven healthy subjects were measured and a statistical analysis was performed. The results yielded by new method show that the total trajectory lengths of patients with cerebellar disease are significantly larger than the total trajectory lengths of healthy subjects. It is evident from the median of the total trajectory lengths that the method based on the data obtained by an inexpensive orientation tracker may be used to quantify human postural stability and enables for studying body sway in 3-D space. For example, the 3-D deviations of the trunk angles in a time period that are caused by a tremor in 3-dimensional space can be studied accordingly by the method.",
     "keywords": ["Trunk sway", "Postural stability", "Trajectory length", "Cerebellar disease", "3-D trajectory"]},
    {"article name": "Polymeric drug carriers—Control of the daily dose and therapy duration",
     "doi": "https://doi.org/10.1016/j.bbe.2014.11.001",
     "publication date": "01-2015",
     "abstract": "This study evaluates the mass release of cyanocobalamin with various drug carriers. Monolithic structures with a liquid core covering a thick (>150 μm) porous, polymer membrane are recommended. Membrane pore size should ensure easy diffusion of the drug molecules. The selection of the carrier's parameters to fit a required daily dose and therapy duration must consider the following criteria: 1′ the determination of its size (geometric surface); 2′ the number of carriers, if more than one is necessary; 3′ the thickness of membrane covering the carrier; and 4′ the mass of the loading drug.An algorithm to select these conjugated parameters to achieve the therapeutic threshold and duration of the drug effect was expanded upon.A system to constantly deliver drugs over days/weeks/months can be maintained if the loaded mass of the drug significantly exceeds its solubility in the carrier's core.",
     "keywords": ["Drug reservoir", "Diffusion", "Controlled release", "Membrane parameters", "Algorithm"]},
    {"article name": "A physiological measures-based method for detecting inattention in drivers using machine learning approach",
     "doi": "https://doi.org/10.1016/j.bbe.2014.12.002",
     "publication date": "01-2015",
     "abstract": "In recent years, as a result of the usage of electronic gadgets in vehicles, driver inattention has become one of the major causes of road accidents that lead to severe physical injuries, deaths and significant economic losses. Statistics ensure the need of a reliable driver inattention detection system that can alert the driver before a mishap happens.In this work, we aimed to develop a system that can detect inattention using electrocardiogram (ECG) and surface electromyogram (sEMG) signals. Cognitive and visual inattention was manipulated by asking the driver to respond to phone calls and short messaging services, respectively. A total of 15 male subjects participated in the data collection process. The subjects were asked to drive for two hours in a simulated environment at three different times of the day. ECG, sEMG and video were obtained throughout the experiment. The gathered physiological signals were preprocessed to remove noises and artefacts. The inattention features were extracted from the preprocessed signals using conventional statistical, higher-order statistical and higher-order spectral features. The features were classified using k-nearest neighbour analysis, linear discriminant analysis and quadratic discriminant analysis.The bispectral features gave overall maximum accuracies of 98.12% and 90.97% for the ECG and EMG signals, respectively.We conclude that ECG and EMG signals can be explored further to develop a robust and reliable inattention detection system.",
     "keywords": ["ECG", "EMG", "Physiological measures", "Driver inattention", "Driver distraction"]},
    {"article name": "Biomedical images enhancement based on the properties of morphological spectra",
     "doi": "https://doi.org/10.1016/j.bbe.2014.10.005",
     "publication date": "01-2015",
     "abstract": "The method enhancing distinctiveness of the micro-morphological structures, developed using the properties of morphological spectra of their monochromatic 2D images, is presented and its effects on the bone section image are statistically compared with enhancements by Sobel, Roberts and Laplace high-pass filters. Comparison of different filters based on statistical parameters of the classes of selected image details is presented. The preferable method for choosing filtering weight coefficients is described and illustrated by an example of processing an electron-microscope image of a biotechnological specimen. The applicability of this approach and possible development directions are discussed.",
     "keywords": ["Image filtering", "Image distinctiveness", "Walsh functions", "Morphological spectra", "Texture segmentation"]},
    {"article name": "Biomedical ontologies—A review",
     "doi": "https://doi.org/10.1016/j.bbe.2014.06.002",
     "publication date": "01-2015",
     "abstract": "Current societies undergo a transformation into information societies. “Digitialization” is progressing in every aspect of life, including health care. Handling the increasing flow of biomedical data presents a serious challenge to researchers and clinicians. Ontologies – controlled vocabularies that allow describing the meaning of data (its semantics) in a human and machine readable way are used more and more often to aid processing of information in biomedical research and in healthcare systems. The aim of this work is to bring closer the field of ontologies to the medical society. The theoretical basics are presented and exemplified with a range of ontologies used for describing diseases, medications, proteins, experimental procedures, etc. Currently the multitude of ontologies is an obstacle in further data integration. Unified Medical Language System (UMLS) and OBO Foundry (Open Biomedical Ontologies) are projects started to counteract this problem. UMLS aims at merging existing vocabularies, while OBO initiative is based on coordinated, harmonic development of new ontologies and reformation of existing ones. The pros and cons of both philosophies are presented. The final section of the article features examples of ontology applications.",
     "keywords": ["Biomedical ontologies", "Data annotation", "Information storage"]},
    {"article name": "Separation of overlapping bacilli in microscopic digital TB images",
     "doi": "https://doi.org/10.1016/j.bbe.2014.08.002",
     "publication date": "01-2015",
     "abstract": "The sputum smear microscopy based tuberculosis (TB) screening method is a conventional method employed for disease identification. It provides significant benefit to TB burdened communities across the globe; however, there are many challenges faced in processing the sputum smear images. When the smear is thick or uneven the number of overlapping bacilli is more which impedes the diagnosis. The separation of overlapping bacilli is significant without which the results lead to gross errors in identification of the disease causing agent. In this work, separation of overlapping bacilli is carried out by method of concavity (MOC) and is compared with the conventional methods such as multi-phase active contour (MAC) and marker-controlled watershed (MCW). Performance of the methods is evaluated based on the statistical mean quality score of shape descriptors extracted from the separated and existing true bacilli. The shape descriptors employed in this work include geometric features, Hu's, Zernike moments and Fourier descriptors. Results of separated overlapping bacilli demonstrate that MOC performs better than MAC and MCW. It is observed that the statistical mean quality score of the separated bacilli using the proposed MOC shows nearest match with true bacilli. The validation performed with experimental results to that of human annotations highlights the performance of MOC in separating the overlapping bacilli in the sputum smear images.",
     "keywords": ["Tuberculosis", "Sputum smear images", "Multi-phase active contour", "Marker-controlled watershed", "Hu's and Zernike moment", "Fourier descriptors"]},
    {"article name": "Comparison study of the prosthetics interface pressure profile of air splint socket and ICRC polypropylene socket for upper limb prosthetics",
     "doi": "https://doi.org/10.1016/j.bbe.2014.08.003",
     "publication date": "01-2015",
     "abstract": "This study examined the interface pressure differences at the stump socket between an ICRC polypropylene socket and an air splint socket for a common wearer of transhumeral amputee using F-socket transducers. Two F-socket sensors arrays were attached to the residual limb. The subject was asked to complete the following tasks: Normal position, stand in a normal position without conducting any motion and shoulder movements, flexion/extension and abduction. The results revealed that the interface pressure applied using ICRC polypropylene socket was maximize at the end distal of the residual limb and give more pressure contact to any shoulder movements. Conversely, while using air splint socket, the socket was able to auto-adjust for required socket fitting even for any change while doing shoulder movements. Our result demonstrated how the comparison of pressure applied at the stump socket may lead in chosen the suitable prosthetic's socket for the amputee. The impending development of an auto-adjusted socket that uses an air splint system will provide the prosthetic socket with a less contact pressure at the residual limb.",
     "keywords": ["Biomechanics", "Pressure", "Rehabilitation", "Biomedical engineering", "Transhumeral"]},
    {"article name": "Segmentation of pulmonary vascular tree from 3D CT thorax scans",
     "doi": "https://doi.org/10.1016/j.bbe.2014.07.001",
     "publication date": "01-2015",
     "abstract": "This paper considers the problem of pulmonary vessels identification in thoracic 3D CT scans. In particular, the method for pulmonary vascular tree segmentation is introduced. The main idea behind the introduced method is to extract both thoracic trees together (i.e. the vascular tree and the airway tree) and then remove airway walls. Therefore, firstly segmentation of vessels and airway walls is performed using 3D region growing where the growth of the region is guided and constrained by results of random walk segmentation applied to consecutive CT slices. In particular, results of random walk segmentation of one slice are used to determine seeds for random walk segmentation of the following slice. Next step is airway tree segmentation using 3D region growing algorithm guided and constrained by the morphological gradient. Finally, morphological processing is applied in order to extend airway lumen onto airway walls and remove the overlapping regions. The main steps of the proposed approach are described in detail. Results of pulmonary vascular tree segmentation from example thoracic volumetric CT datasets provided by the introduced approach are presented and discussed. Based on a manually selected and radiologist's verified ground truth pixels and the resulting quality measures it can be concluded, that the average accuracy of the introduced approach is about 90%.",
     "keywords": ["Pulmonary vascular tree", "Airway tree", "3D CT", "Image segmentation", "Region growing", "Random walk segmentation"]},
    {"article name": "Application and evaluation of layered silicate–chitosan composites for site specific delivery of diclofenac",
     "doi": "https://doi.org/10.1016/j.bbe.2014.08.004",
     "publication date": "01-2015",
     "abstract": "The present study focuses on the in situ intercalation of anionic drug (diclofenac sodium, DS) and cationic polymer, Chitosan (CS) in montmorillonite (MMT) for drug release applications. The prepared DS/CS-MMT composites were further compounded with alginate (AL) to form beads to modify release response in gastric juice. The DS/CS-MMT composites were characterized by UV spectroscopy, XRD, FT-IR, TGA and DSC. Antibacterial assay of drug loaded composites was investigated and in vitro cell viability assay results point out the drug encapsulated in clay plates are less toxic to the cell than pristine drug. The in vitro release experiments revealed that the DS was released from DS/CS-MMT/AL in a controlled and pH dependent manner.",
     "keywords": ["Layered structures", "Chitosan", "Thermal analysis", "Biomaterials", "Controlled release"]},
    {"article name": "Brace for variability in tool positioning: Modeling and simulation of 1 DoF needle insertion task under tool-braced condition",
     "doi": "https://doi.org/10.1016/j.bbe.2014.10.003",
     "publication date": "01-2015",
     "abstract": "Erroneous human arm motion leads to inaccuracy in tool positioning which often affects the quality of many precision manipulation tasks. Variability in tool endpoints during mechanical interactions among humans, tools, and environments can be reduced by bracing strategies; therefore, such a cost-effective approach may increase accuracy and reproducibility in human arm movements and thus prove useful in improving performance of selected interactive tasks. Although a great number of works is found in the literature related to performance augmentation of braced robotic manipulators, only a few studies are found on bracing strategies for performing interactive tasks and on analogies to human manipulation. In this paper, a method for predicting bracing properties is proposed for single degree of freedom interactive task to improve performance. To reflect real workplace scenarios, models of the human impedance, the brace, and the contact of the interaction are represented and used to predict the quality of the executed task. The task execution model intended to predict real-life performance in both free arm and braced conditions are then used to estimate the brace properties to augment performance of the representative task.",
     "keywords": ["Co-manipulation", "Precision tool positioning", "Human-tool interaction", "Bracing system design", "Performance augmentation"]},
    {"article name": "Methods of face localization in thermograms",
     "doi": "https://doi.org/10.1016/j.bbe.2014.09.001",
     "publication date": "01-2015",
     "abstract": "This paper presents an algorithm for determination of the head centre in thermograms. The paper includes a comparison of the method developed by the authors with the known methods presented in the literature for locating the head in thermal images. The proposed method enables automatic localization of the head centre, which is essential for practical applications when there is a need to locate the head in an image. Application areas may include the process of face recognition in biometrics, recognition of emotions, the creation of a human–computer interface. The presented method is reproducible and enables to obtain correct results in cases of large interindividual variability of the test subjects.",
     "keywords": ["Face localization", "Face detection", "Thermograms", "Thermovision", "Image processing"]},
    {"article name": "The thermographic signal reconstruction method: A powerful tool for the enhancement of transient thermographic images",
     "doi": "https://doi.org/10.1016/j.bbe.2014.07.002",
     "publication date": "01-2015",
     "abstract": "Important progress occurred in pulse-stimulated thermography, in particular thanks to the TSR technique, a technique based on the decomposition of thermograms on a logarithmic polynomial basis and the use of the logarithmic derivatives to enhance the detection of defects in structures. Its fields of application begin to broaden to the characterization of transient internal heat sources in experimental mechanics and biomedicine. The TSR technique is presented, in particular the last developments leading to the production of a unique synthetic image. Two recent examples of applications in experimental mechanics and biomedicine, taken from literature, are described: in situ detection of damages in a composite material during mechanical tests and in vivo visualization of subcutaneous functional angioarchitecture in humans.",
     "keywords": ["Stimulated thermography", "Non-destructive evaluation", "Experimental mechanics", "Damage detection", "Biomedicine", "Thermographic signal reconstruction"]},
    {"article name": "Application of content-based image analysis to environmental microorganism classification",
     "doi": "https://doi.org/10.1016/j.bbe.2014.07.003",
     "publication date": "01-2015",
     "abstract": "Environmental microorganisms (EMs) are single-celled or multi-cellular microscopic organisms living in the environments. They are crucial to nutrient recycling in ecosystems as they act as decomposers. Occurrence of certain EMs and their species are very informative indicators to evaluate environmental quality. However, the manual recognition of EMs in microbiological laboratories is very time-consuming and expensive. Therefore, in this article an automatic EM classification system based on content-based image analysis (CBIA) techniques is proposed. Our approach starts with image segmentation that determines the region of interest (EM shape). Then, the EM is described by four different shape descriptors, whereas the Internal Structure Histogram (ISH), a new and original shape feature extraction technique introduced in this paper, has turned out to possess the most discriminative properties in this application domain. Afterwards, for each descriptor a support vector machine (SVM) is constructed to distinguish different classes of EMs. At last, results of SVMs trained for all four feature spaces are fused in order to obtain the final classification result. Experimental results certify the effectiveness and practicability of our automatic EM classification system.",
     "keywords": ["Environmental microorganism classification", "Microscopic images", "Image segmentation", "Shape features", "Support vector machine", "Late fusion"]},
    {"article name": "Method of automatic recognition and other solutions used in new computer program for full decomposition of EMG signals",
     "doi": "https://doi.org/10.1016/j.bbe.2014.05.002",
     "publication date": "01-2015",
     "abstract": "The analysis of electromyographic signals can be very time consuming. In designing a program for EMG signal analysis, there are two competing factors: the accuracy of the final result and its speed. In scientific work, accuracy is the most important factor. All of the existing decomposition programs used in neurophysiology require a final phase of manual corrections, if reliable results are to be obtained. This phase is considerably longer than the phase of automatic recognition.The solutions presented below, used in our new MUR program, allow for the accurate decomposition of complex EMG signals in a reasonable amount of time. The decomposition is performed interactively with optimal time division between automatic and manual tasks. All of this is achieved through a simple method of automatic recognition with the use of the modified coefficient of determination and the method of multiple subtractions of potentials.",
     "keywords": ["MUR name of the program", "name of the program", "AP \u201canchor point\u201d. The extreme point in which every potential generated by a given motor unit is labelled", "\u201canchor point\u201d. The extreme point in which every potential generated by a given motor unit is labelled", "Dev. value of the deviation from the value of the y-coordinate in an anchor point of the template", "value of the deviation from the value of the y-coordinate in an anchor point of the template", "LB left border of the last saved template. Indicates the first point of the graph of the saved template", "left border of the last saved template. Indicates the first point of the graph of the saved template", "RB right border of the last saved template. Indicates the last point of the graph of the saved template", "right border of the last saved template. Indicates the last point of the graph of the saved template", "RL radius left. Distance from the anchor point to the left border of the template (number of measure points on the left from the anchor point)", "radius left. Distance from the anchor point to the left border of the template (number of measure points on the left from the anchor point)", "RR radius right. Distance from the anchor point to the right border of the template (number of measure points on the right from the anchor point)", "radius right. Distance from the anchor point to the right border of the template (number of measure points on the right from the anchor point)", "R2 coefficient of determination", "coefficient of determination", "R mod 2 modified coefficient of determination (here as the measure of the similarity between the template and the potential in the signal \u2013 analysed signal fragment)", "modified coefficient of determination (here as the measure of the similarity between the template and the potential in the signal \u2013 analysed signal fragment)", "Motor unit", "Potential", "Signal", "Decomposition", "Automatic recognition", "Modified coefficient of determination"]},
    {"article name": "A novel phase-intensive local pattern for periocular recognition under visible spectrum",
     "doi": "https://doi.org/10.1016/j.bbe.2014.05.003",
     "publication date": "01-2015",
     "abstract": "The article proposes a novel multi-scale local feature based on the periocular recognition technique which is capable of extracting high-dimensional subtle features existent in the iris region as well as low-dimensional gross features in the periphery skin region of the iris. A set of filter banks of different scales is employed to exploit the phase-intensive patterns in visible spectrum periocular image of a subject captured from a distance in partial non-cooperative scenario. The proposed technique is verified with experiments on near-infrared illumination databases like BATH and CASIA-IrisV3-Lamp. Experiments have been further extended to images from visible spectrum ocular databases like UBIRISv2 and low-resolution eye regions extracted from FERETv4 face database to establish that the proposed feature performs comparably better than existing local features. To find the robustness of the proposed approach, the low resolution visible spectrum images of mentioned databases are converted to grayscale images. The proposed approach yields unique patterns from these grayscale images. The ability to find coarse-to-fine features in multi-scale and different phases is accountable for the improved robustness of the proposed approach.",
     "keywords": ["Personal identification", "Periocular biometric", "Automated recognition"]},
    {"article name": "A texture-based method for classification of schizophrenia using fMRI data",
     "doi": "https://doi.org/10.1016/j.bbe.2014.08.001",
     "publication date": "01-2015",
     "abstract": "This paper presents a texture-based method for classification of individuals into schizophrenia patient and healthy control groups based on their resting state functional magnetic resonance imaging (R-fMRI) data. In this research a combination of three different classifiers is proposed for classification of subjects into predefined groups. For all fMRI scans, the number of time points is reduced using principal component analysis (PCA) method, which projects data onto a new space. Then, independent component analysis (ICA) algorithm is used for estimation of the independent components (ICs). ICs are sorted based on their variance. For feature extraction a texture based operator called volume local binary patterns (VLBP) is applied on the estimated ICs. In order to obtain a set of features with large discrimination power, a two-sample t-test method is used. Finally, a test subject is classified into patient or control group using a combination of three different classifiers based on a majority vote method. The performance of the proposed method is evaluated using a leave-one-out cross validation method. Experimental results reveal that the proposed method has a very high accuracy.",
     "keywords": ["Schizophrenia", "Functional magnetic resonance imaging", "Independent component analysis", "Volume local binary patterns", "Histogram extraction", "T-test"]},
    {"article name": "Investigation of microstructure of bone tissue in mandibles of newborn rats after maternal treatment with antiretroviral drugs",
     "doi": "https://doi.org/10.1016/j.bbe.2014.05.004",
     "publication date": "01-2015",
     "abstract": "High-resolution imaging has become a powerful tool for measurements in clinics, laboratory and animal studies, etc. In the present study, we aimed to investigate age related changes in bone development, and the effect of two antiretroviral agents (zidovudine and indinavir), which were administered during pregnancy, on the microstructure and bone mineral density (BMD) in newborn rats (7-, 14- and 28-day-old), with the use of X-ray microcomputed tomography (XMT). Fifty-four mandible bones were collected and divided into 3 groups: group 1 and 2: newborns after maternal treatment of zidovudine and indinavir respectively, group 3: control animals. The specimens were XMT scanned with the resolution of 7 μm and with a density phantom. Histomorphometric parameters and BMD were calculated to assess bone development depending on the administered drug. A statistical analysis was carried out to compare the differences among the control, zidovudine and indinavir groups. The analysis of the microstructure revealed disturbances in the development of the bone tissue in newborn rats. Indinavir seems to have a greater impact on bone microstructure than zidovudine.",
     "keywords": ["XMT X-ray microcomputed tomography", "X-ray microcomputed tomography", "HIV human immunodeficiency virus", "human immunodeficiency virus", "ARV antiretroviral treatment", "antiretroviral treatment", "X-ray microcomputed tomography", "Mandibular condyle", "Antiretroviral drugs", "Bone mineral density (BMD)", "Histomorphometric parameters"]},
    {"article name": "Exploiting Stein's paradox in analysing sparse data from genome-wide association studies",
     "doi": "https://doi.org/10.1016/j.bbe.2014.10.004",
     "publication date": "01-2015",
     "abstract": "Unbiased estimation appeared to be an accepted golden standard of statistical analysis ever until the Stein's discovery of a surprising phenomenon attributable to multivariate spaces. So called Stein's paradox arises in estimating the mean of a multivariate standard normal random variable. Stein showed that both natural and intuitive estimate of a multivariate mean given by the observed vector itself is not even admissible and may be improved upon under the squared-error loss when the dimension is greater or equal to three. Later Stein and his student James developed so called ‘James–Stein estimator’, a shrunken estimate of the mean, which had uniformly smaller risk for all values in the parameter space. The paradox first appeared both unintuitive and even unacceptable, but later it was recognised as one of the most influential discoveries of all times in statistical science. Today the ‘shrinkage principle’ literally permeates the statistical technology for analysing multivariate data, and in its application is not exclusively confined to estimating the mean, but also the covariance structure of multivariate data. We develop shrinkage versions of both the linear and quadratic discriminant analysis and apply them to sparse multivariate gene expression data obtained at the Centre for Biomedical Informatics (CBI) in Prague.",
     "keywords": ["00-01", "99-00", "Multivariate analysis", "Shrinkage", "Biased estimation", "Risk", "Squared-error loss", "Bias-variance trade-off"]},
    {"article name": "Usefulness of chest perfusion computed tomography in the diagnosis of diabetic pulmonary microangiopathy",
     "doi": "https://doi.org/10.1016/j.bbe.2014.08.005",
     "publication date": "01-2015",
     "abstract": "This paper presents the usefulness of perfusion computed tomography (pCT) in the diagnosis of diabetic pulmonary microangiopathy. Our previous works have shown that perfusion parameters are useful in the diagnosis of diabetic pulmonary microangiopathy. We are looking for such measurements and perfusion parameters that provide the most accurate diagnosis. Two types of comparison were made based on the results of clinical trials: non-diabetic vs. diabetic and diabetes without microangiopathy vs. diabetes with microangiopathy. Our studies have shown that PS (permeability surface) is only perfusion parameter statistically significant. In certain regions of interest logistic regression as a classifier produces very good results in diagnosing lung microangiopathy: sensitivity Sens = 89% and excellent specificity Spec = 100%. The results were obtained on the base of measurements taken from 23 subjects. These results were compared with results reported in the literature and based on diffusion capacity and spirometry measurements and modeling. None of the previous results was as good as those obtained using the PS and logistic regression for binary classification.",
     "keywords": ["Chest perfusion computed tomography", "pCT", "Pulmonary microangiopathy", "Diabetes mellitus", "Lung"]},
    {"article name": "Expandable endoprosthesis for growing patients—Reliability and research",
     "doi": "https://doi.org/10.1016/j.bbe.2014.05.005",
     "publication date": "01-2014",
     "abstract": "Nowadays expandable endoprosthesis for growing children is an alternative to amputation in the course of surgical treatment. Modern non-invasive endoprosthesis gives the possibility of elongation without a surgical operation. In the paper, the results of research with the application of computer technique in geometrical modelling are presented, as well as the design and manufacture in processing the medical images and experimental studies during an initial estimation of a new expandable prosthesis construction for growing patients, which will lead to the preparation for production and implantation processes in Poland.",
     "keywords": ["Bone sarcoma", "Invasive- and non-invasive expandable prosthesis", "Arthroplasty", "Reliability", "Preoperative planning"]},
    {"article name": "An integrated electromechanical model for the cochlear microphonic",
     "doi": "https://doi.org/10.1016/j.bbe.2014.06.001",
     "publication date": "01-2014",
     "abstract": "The cochlear microphonic (CM) is an electrical signal generated inside the cochlea in response to sound. This electrical signal reflects mechanical activity in the cochlea and the excitation processes involved in its generation. However, the difficulty of obtaining this signal and the simplicity of obtaining other signals such as otoacoustic emissions have discouraged the use of the cochlear microphonic as a tool for studying cochlear functions. In this article, a model of the cochlea is presented which integrates both mechanical and electrical aspects, enabling the interaction between them to be investigated. The resulting model is then used to observe the effect of the cochlear amplifier on the CM. The results indicate that while the cochlear amplifier significantly amplifies the basilar membrane displacement, the effect on the CM is less significant. Both of these outcomes are consistent with previous physiological findings.Moreover, the close match between mechanical and electrical predictions of the model and experimental measurements validates the model, and suggests that further investigations using the model into various pathologies and anomalies are warranted.",
     "keywords": ["Cochlear microphonic", "Electrophysiology", "Outer hair cells", "Cochlear modelling"]},
    {"article name": "Biomechanical analysis of diversified screw arrangement on 11 holes locking compression plate considering time-varying properties of callus",
     "doi": "https://doi.org/10.1016/j.bbe.2014.05.001",
     "publication date": "01-2014",
     "abstract": "The 11 holes locking compression plate (LCP) is a type of fixator which is currently used in orthopedic surgeries for fixing fractures of long bones. 8 styles of screw positioning on this plate are possible so each orthopedist may use one of them during operations. The aim of the current study was the analysis of diversified screw arrangement on the mentioned LCP for fixation of medial transverse fracture of tibia considering time- varying properties of bone callus in 16-weeks curing duration. Stress shielding effects were also considered. Finite element method using Mimics 10.01, Solid works 2012 and Abaqus 6.11-1 software have been applied. Modeling of bone was done based on computer tomography (CT) scan of human right tibia and four types of forces have been loaded on intact bone and the same was loaded on fixated fractured ones in 8 treatments of fixation. Stresses in bone, plate and screws, also gap or callus strains and stiffnesses in 5 terms of curing duration in all of the treatments have been investigated and compared together using new defined parameters. Finally the preferred treatment was concluded. Results of this study may be used by orthopedists in applying such a fixator for fixation of tibia and other fractured long bones.",
     "keywords": ["Screw arrangement", "LCP", "Tibia", "Medial transverse fracture", "Biomechanical analysis"]},
    {"article name": "Rapid capture and exemplary detection of clinical pathogen using surface modified fluorescent silica coated iron oxide nanoparticles",
     "doi": "https://doi.org/10.1016/j.bbe.2014.03.001",
     "publication date": "01-2014",
     "abstract": "Rapid, sensitive and selective detection of pathogenic bacteria is very important for treatment of diseases like foodborne illness, sepsis and bioterrorism. The silica coated iron oxide nanoparticles (SIO) were synthesized using simple, cost-effective method and used for the rapid capture and detection of clinical pathogen. The surface modification of nanoparticles was carried out using 3-aminopropyltriethoxy silane. The scanning electron microscopy image results showed the slightly agglomerated spherical shaped nanoparticles. Transmission electron microscope result showed the polydispersed particles in the size ranges from 5 to 12 nm. The EDAX results confirmed the coating of silica with iron oxide particles. The SAED pattern confirmed the crystalline nature of iron oxide nanoparticles and also indicated the presence of silica. The FTIR spectrum of the nanoparticles confirmed the functional groups of the iron oxide and surface modified fluorescent silica coated iron oxide nanoparticles (SFSIO). This work provides a very effective method for controlling the growth, capture and detection of pathogenic bacteria.",
     "keywords": ["Bio-imaging", "FITC", "E. coli", "Fluorescence microscope", "Scanning electron microscope", "Transmission electron microscope"]},
    {"article name": "An adaptive level dependent wavelet thresholding for ECG denoising",
     "doi": "https://doi.org/10.1016/j.bbe.2014.03.002",
     "publication date": "01-2014",
     "abstract": "This paper describes the research carried out to eliminate the noise found in ECG signal and cardiac rhythm. For this, ECG signals were collected carefully from BIOPAC data acquisition system and MIT-BIH database. MIT-BIH noise stress test database was used for generating realistic noises. In addition, to get a better denoised ECG, Symlet wavelet was chosen because its scaling function is closely related to the shape of ECG. For denoising ECG signal, a novel modified S-median thresholding technique is proposed and evaluated in this paper. The optimal Symlet wavelet of order 6 and decomposition level of 8 are attained for modified S-median thresholding technique. The evaluation results showed that the proposed system performed better than S-median and other existing techniques in the time domain. The frequency domain analysis also showed the preservation of important phenomena of ECG. The scalogram difference of 0.004% indicates the well preservation of time–frequency information.",
     "keywords": ["ECG", "MABWT", "Modified S-median", "Symlet wavelet", "Scalogram difference", "S-median"]},
    {"article name": "Susceptibility of switching between in-phase and anti-phase patterns in the network of relaxation oscillators",
     "doi": "https://doi.org/10.1016/j.bbe.2014.04.001",
     "publication date": "01-2014",
     "abstract": "Neural networks composed of two or four cells with combined, electrical and inhibitory, synapses and realized for various network topologies were examined. The aim of this study was to determine a set of phases of oscillatory cycle in which different patterns of activity, characteristic for such networks, can be switched under an external stimulus. In particular, we studied susceptibility of switching between in-phase (IP) and anti-phase (AP) patterns (and vice versa). Our results demonstrate that windows of switching between patterns are similar for networks with electrical and mixed synapses and, in general, relatively independent of the network topology. The only effect of the network topology is an increase of the robustness of the AP pattern in networks of ring-like connectivity. The switching window width and thereby the robustness of the transitions between patterns decreases with the increase of the electrical coupling strength.",
     "keywords": ["Electrical coupling", "Gap junction", "Multistability", "Anti-phase pattern", "Central Pattern Generators", "Relaxation oscillators"]},
    {"article name": "A methodological review of data mining techniques in predictive medicine: An application in hemodynamic prediction for abdominal aortic aneurysm disease",
     "doi": "https://doi.org/10.1016/j.bbe.2014.03.003",
     "publication date": "01-2014",
     "abstract": "Modern clinics and hospitals need accurate real-time prediction tools. This paper reviews the importance and present trends of data mining methodologies in predictive medicine by focusing on hemodynamic predictions in abdominal aortic aneurysm (AAA). It also provides potential data mining working frameworks for hemodynamic predictions in AAA. These frameworks either allow the coupling between a typical computational modeling simulation and various data mining techniques, using the existing medical datasets of real-patient and mining it directly using various data mining techniques or implementing visual data mining approach to already available computed results of various hemodynamic features within the AAA models. These approaches allow the possibility of statistically predicting rupture potentials of aneurismal patients and ideally provide an alternate solution for substituting tedious and time-consuming computational modeling. Prediction trends of patient-specific aneurismal conditions via mining huge volume of medical data can also speed up the decision making process in real life medicine.",
     "keywords": ["Data mining techniques", "Hemodynamic prediction", "Abdominal aortic aneurysm"]},
    {"article name": "MESA: Complete approach for design and evaluation of segmentation methods using real and simulated tomographic images",
     "doi": "https://doi.org/10.1016/j.bbe.2014.02.003",
     "publication date": "01-2014",
     "abstract": "In this paper we present MESA: a platform for design and evaluation of medical image segmentation methods. The platform offers a complete approach for the method creation and validation using simulated and real tomographic images. The system consists of several modules that provide a comprehensive workflow for generation of test data, segmentation method development as well as experiment planning and execution. The test data can be created as a virtual scene that provides an ideal reference segmentation and is also used to simulate the input images by a virtual magnetic resonance imaging (MRI) scanner. Both ideal reference segmentation and simulated images could be utilized during the evaluation of the segmentation methods. The platform offers various experimental capabilities to measure and compare the performance of the methods on various data sets, parameters and initializations. The segmentation framework, currently based on deformable models, uses a template solution for dynamical composition and creation of two- and three-dimensional methods. The platform is based on a client–server architecture, with computational and data storage modules deployed on the server and with browser-based client applications. We demonstrate the platform capabilities during the design of segmentation methods with the use of simulated and actual tomographic images.",
     "keywords": ["Image segmentation", "Magnetic resonance imaging", "Deformable models", "Segmentation evaluation"]},
    {"article name": "Selection of an efficient feature space for EEG-based mental task discrimination",
     "doi": "https://doi.org/10.1016/j.bbe.2014.03.004",
     "publication date": "01-2014",
     "abstract": "The aim of this paper is to contribute toward exploring an optimal feature space for discriminating mental tasks. Empirical mode decomposition (EMD) algorithm seems useful for designing such a feature space. The adjustment of nonlinear and non-stationary properties of the EEG signals with this algorithm and the successful application of this approach together biomedical signal processing problems encourage us to examine a variety of statistical and spectral measures within the EMD space as the adapted features. In this sense, as a measure of complexity, the Lempel–Ziv algorithm is utilized within the framework of the EMD algorithm. A modified form of the Lempel–Ziv complexity algorithm is then proposed. The features derived from the modified algorithm outperform the other features individually. By combining the modified Lempel–Ziv features with the other adopted features, in average, 97.78% classification accuracy is achieved for different subjects. It is concluded that the EMD–LZ kernel allows for achieving of better performances in classifying mental tasks than the results obtained with other methods.",
     "keywords": ["Mental task", "Electroencephalogram signals (EEG)", "Empirical mode decomposition (EMD)", "Lempel\u2013Ziv"]},
    {"article name": "Application of clustering techniques for visually evoked potentials based detection of vision impairments",
     "doi": "https://doi.org/10.1016/j.bbe.2014.02.002",
     "publication date": "01-2014",
     "abstract": "Visually evoked potentials (VEP) are evoked responses of the brain corresponding to a specific visual stimulus. Ophthalmologists often refer their patients to VEP test if the latter suffers any vision abnormalities that cannot be diagnosed using conventional analysis. By investigating the VEP responses, medical experts can narrow down the possible cause of the defect. Although this method provides valuable information to the medical practitioner, there are several drawbacks of the analysis that can affect the diagnosis result. The conventional averaging of the signals results in inter-trial variation between the VEP responses to be lost. This method also requires large number of trials, which causes fatigue in patients and reduces the diagnostic accuracy. Therefore, we have proposed a new method of analysis using statistical features derived from time and spectral space for the discrimination of vision impairments. Feature enhancement methods such as feature weighting and dimensional reduction are used to enhance the statistical features prior to the analysis. Four clustering methods are employed to increase the interclass separability of the control and myopic features while reducing the within class variability. The dimension of the weighted features is reduced using a combination of principal component analysis (PCA) and independent component analysis (ICA) techniques prior to classification. The proposed method is able to achieve 100% accuracy using extreme learning machine (ELM) and multi layer neural network (MLNN) classifiers.",
     "keywords": ["Visually evoked potential", "Vision impairment", "Feature weighting", "Feature reduction", "Extreme learning machine", "Multi layer neural network"]},
    {"article name": "The influence of ambient temperature on foot temperature in patients with diabetic foot ulceration",
     "doi": "https://doi.org/10.1016/j.bbe.2014.04.002",
     "publication date": "01-2014",
     "abstract": "Patients with diabetic neuropathy exhibit a higher foot temperature than those without neuropathy and they are at risk for foot ulceration. Ambient temperature and foot ulceration additionally influence foot temperature in such patients. The aim of the study was to assess the influence of ambient temperature on foot temperature in patients with an ulcer on one of the feet.Miniature temperature data loggers were used for the monitoring of foot skin and ambient temperature. Twenty patients with diabetic neuropathy and ten healthy subjects were monitored for about 24 h each.The temperature of the foot with an ulcer correlates significantly with ambient temperature, with the slope of the regression line of 0.09. The temperature of the non-ulcerated foot also correlates significantly with ambient temperature, with the slope of 0.31, however the correlation coefficient and the slope are significantly higher than in the case of the foot with an ulcer. The difference of temperature of the foot with an ulcer and temperature of the foot without an ulcer correlates well with ambient temperature with the slope of −0.219. The temperatures of left and right feet were studied as a function of ambient temperature in healthy individuals and there were no statistically significant differences between correlation coefficients and slopes.It is apparent that ambient temperature influences foot temperature even during foot ulceration. Thus ambient temperature should be taken into consideration in any application when foot temperatures are important, especially in the prediction of diabetic foot ulceration.",
     "keywords": ["Foot temperature", "Diabetic foot ulceration", "Ambient temperature", "Wound healing", "Data logger"]},
    {"article name": "A way in determination of patellar position: Ligamentum patellae angle and a neural network application",
     "doi": "https://doi.org/10.1016/j.bbe.2014.02.004",
     "publication date": "01-2014",
     "abstract": "The patients may show various patellar order samples. Patellofemoral disorders are defined in all cases with patellofemoral pain syndrome. Right and left knees belonging to the 60 men and 60 women volunteers were measured. By using the distances from the measurements, ligamentum patellae (LP) angle was estimated by artificial neural network (ANN) method. According to the results, one can confidently say that the method is capable for estimating this angle. The related root mean square error belonging to the test data of ANN is between 0.48° and 1.18°. These angles for women are two times larger than men's. Eventually, the risk of patellofemoral disorders is greater for women than men.",
     "keywords": ["Ligamentum patellae", "Patellar order", "Gender difference", "Artificial neural network"]},
    {"article name": "Photoactivated titania-based nanomaterials for potential application as cardiovascular stent coatings",
     "doi": "https://doi.org/10.1016/j.bbe.2014.03.005",
     "publication date": "01-2014",
     "abstract": "Intravascular stenting of atherosclerotic coronary arteries is a life-saving, widely used procedure in interventional cardiology. Adverse clinical outcomes such as restenosis highlight the importance of meeting the excellent biocompatibility by cardiovascular implants. Many attempts have been made to improve the safety profile of implant surface. We for the first time developed the photoactive intravascular titania-based nanomaterials for the application as cardiovascular stent coating. Photoactive biomaterial deposited on the cardiovascular stent surface demonstrated promising features, making it an excellent substrate for endothelial cells growth and proliferation. The biocompatibility of these coatings has been compared with 316L stainless steel surfaces typically used in commercial coronary stents production. The results of the study proved that the innovative titania-based coatings have better biocompatibility characteristics than the 316L stainless steel and in regard of its antithrombotic potential provided protection against restenosis. Furthermore, the titania coating supported endothelial cells attachment and proliferation, and induced prolonged plasma recalcification time in comparison with stainless steel surface. Innovative photoactive titania coating can be an important factor to prevent the process of the restenosis in the place of implantation.",
     "keywords": ["Cardiovascular stent", "Photoactive coating", "Endothelial cells", "Surface charge", "Biocompatibility"]},
    {"article name": "Clinical and non-clinical initial assessment of facial nerve paralysis: A qualitative review",
     "doi": "https://doi.org/10.1016/j.bbe.2014.02.005",
     "publication date": "01-2014",
     "abstract": "This paper illustrates a brief review of some clinical and non-clinical methods to evaluate the facial nerve function in facial paralysis cases. A rigorous search of online databases such as IEEE, Springer, Elsevier, ACM digital library, Wiley online library, and Pub Med was conducted from January, 2012 to August, 2013 to discover and examine previous works on the field of facial treatment and rehabilitation. A brief introduction of facial nerve paralysis is provided. We examined the type of facial disorders, the number of subjects, and methods used to evaluate the facial nerve function. Different keywords were used to acquire the studies based on the desired criteria. A total of 80 articles were identified and were analysed for inclusion in this search. A brief discussion of both types of methods is presented. In conclusion, the review provides recommendations for further improvements.",
     "keywords": ["Facial assessment", "Facial nerve evaluation", "Facial grading systems", "Facial paralysis"]},
    {"article name": "A novel exoskeleton robotic system for hand rehabilitation – Conceptualization to prototyping",
     "doi": "https://doi.org/10.1016/j.bbe.2014.01.003",
     "publication date": "01-2014",
     "abstract": "This research presents a novel hand exoskeleton rehabilitation device to facilitate tendon therapy exercises. The exoskeleton is designed to assist fingers flexion and extension motions in a natural manner. The proposed multi-Degree Of Freedom (DOF) system consists of a direct-driven, optimized and underactuated serial linkage mechanism having capability to exert extremely high force levels perpendicularly on the finger phalanges. Kinematic and dynamic models of the proposed device have been derived. The device design is based on the results of multi-objective optimization algorithm and series of experiments conducted to study capabilities of the human hand. To permit a user-friendly interaction with the device, the control is based on minimum jerk trajectory generation. Using this control system, the transient response and steady state behavior of the proposed device are analyzed after designing and fabricating a two-fingered prototype. The pilot study shows that the proposed rehabilitation system is capable of flexing and extending the fingers with accurate trajectories.",
     "keywords": ["Hand rehabilitation", "Motion assistance", "Robotic exoskeleton", "Wearable robotics"]},
    {"article name": "Monte Carlo simulation approaches to dose distributions for 6 MV photon beams in clinical linear accelerator",
     "doi": "https://doi.org/10.1016/j.bbe.2014.01.002",
     "publication date": "01-2014",
     "abstract": "Monte Carlo method is often used in radiation therapy as utilized in all the branches of science. For this purpose, various preset codes are used for the dose calculations in radiotherapy. In this study, a new Monte Carlo Simulation Program (MCSP) was developed for the dose distributions of a clinical linear accelerator (LINAC) in water phantom. MCSP was carried out by taking into account the interactions of photons with matter in MATLAB (The Mathworks, Inc.). In the study, 6 MeV (6 MV photon mode) energies of photons are examined. In order to validate the performance and accuracy of the simulation, the experimental measurements and MCSP calculations were compared for both percentage depth dose curves and beam profiles. The Monte Carlo results show good agreement with experimental results.",
     "keywords": ["Dose distribution", "Monte Carlo", "6\u00a0MV photon beam", "Linear accelerator (LINAC)", "Beam profiles", "Percentage depth dose"]},
    {"article name": "A new approach to ballistocardiographic measurements using fibre Bragg grating-based sensors",
     "doi": "https://doi.org/10.1016/j.bbe.2014.02.001",
     "publication date": "01-2014",
     "abstract": "A method for acquiring a ballistocardiographic (BCG) signal from the feet of a standing person and the back of a sitting or lying patient is described. The measurements are carried out using in-house constructed fibre-optic sensors interrogated with a commercially available system. The sensor head consists of a fibre Bragg grating (FBG) attached to an elastic board that is placed between the monitored person's body and a soft surface, enabling the board to deform in an unobstructed way. The body's movements, including the BCG component, exert pressure on the board and make it deform along with the attached FBG. The changes to the Bragg wavelength are proportional to the body's movement and a BCG signal can be extracted from the obtained recording. The measuring capabilities of the sensors were evaluated by comparing the heart rate (obtained on the basis of the BCG signal) with the reference signal registered by an ECG recorder. An RMS value of the relative error is below 1.8% and statistical analyses show a satisfactory reconstruction of measurements. Tests carried out in the MRI environment proved the method to be immune to strong electromagnetic fields. The presence of the sensor in an MRI scanner does not affect the quality of imaging.",
     "keywords": ["Ballistocardiography (BCG)", "Fibre Bragg grating (FBG) sensors", "Heart rate (HR)", "Magnetic resonance imaging (MRI)", "Mechanograms"]},
    {"article name": "Computerized screening of diabetic retinopathy employing blood vessel segmentation in retinal images",
     "doi": "https://doi.org/10.1016/j.bbe.2014.01.004",
     "publication date": "01-2014",
     "abstract": "Diabetic retinopathy is a severe sight threatening disease which causes blindness among working age people. This research work presents a retinal vessel segmentation technique, which can be used in computer based retinal image analysis. This proposed method could be used as a prescreening system for the early detection of diabetic retinopathy. The algorithm implemented in this work can be effectively used for detection and analysis of vascular structures in retinal images. The retinal blood vessel morphology helps to classify the severity and identify the successive stages of a number of diseases. The changes in retinal vessel diameter are one of the symptoms for diseases based on vascular pathology. The size of typical retinal vessel is a few pixels wide and it becomes critical and challenging to obtain precise measurements using computer based automatic analysis of retinal images. This method classifies each image pixel as vessel or non-vessel and thereby produces the segmentation of vasculature in retinal images. Retinal blood vessels are identified and segmented by making use of a multilayer perceptron neural network, for which the inputs are derived from three primary colour components of the image, i.e., red, green and blue. Back propagation algorithm which provides a proficient technique to change the weights in a feed-forward network is employed. The performance of this method was evaluated and tested using the retinal images from the DRIVE database and has obtained illustrative results. The measured accuracy of the proposed system was 95.03% for the segmentation algorithm tested on this database.",
     "keywords": ["Vessel segmentation", "Retinopathy", "Neural network", "Retinal images", "Ophthalmology"]},
    {"article name": "Hematopoietic stem cell based therapy of immunosuppressive viral infection—Numerical simulations",
     "doi": "https://doi.org/10.1016/j.bbe.2013.12.003",
     "publication date": "01-2014",
     "abstract": "In the light of recent advantages in stem cell research and gene based therapies of viral infections, we present a numerical experiment referring to hematopoietic stem cell based therapy of immunosuppressive viral infection. We use a variation of basic mathematical model for impairment of help to simulate immune impairing infection. Next, we increase virus-specific CTL production (as in therapy) in different stages of infection. Obtained results are analyzed and compared with results from recent in vivo experiment.",
     "keywords": ["Numerical modeling", "Virus", "Adaptive immune system", "Cellular immunity", "Immunosuppression", "Hematopoietic stem cells (HSC)"]},
    {"article name": "Dynamic simulation of tibialis posterior tendon transfer in the treatment of drop-foot",
     "doi": "https://doi.org/10.1016/j.bbe.2014.01.001",
     "publication date": "01-2014",
     "abstract": "An extensive range of studies have been performed to describe kinematics and dynamics of human movements. However, the forces and moments generated by muscles are not measurable. Dynamic simulations are needed to estimate internal loading of the musculoskeletal system, to establish scientific basis of treatment planning before performing the surgery, and to predict the functional consequences of treatments. In this study, an ankle joint model consisting of 30 bones and 12 muscles was generated by using lower extremity model of OpenSim software. Muscle insertion points were virtually re-defined for simulation of tendon transfer operation of tibialis posterior in treatment of drop foot deformity. Flexion and inversion moments of ankle, and moment arm distances of tibialis posterior before and after operation were investigated comparatively. Tibialis posterior provided the dorsal flexion moment up to 28 N m after transfer, while providing the plantar flexion moment of −14.5 N m before transfer. Moment arm distance became average 33 mm after transfer, while it is average −11 mm before transfer. These increases provided the active dorsal flexion as the treatment of drop foot.",
     "keywords": ["Dynamic simulation", "Musculoskeletal model", "Tendon transfer", "Tibialis posterior", "Drop-foot"]},
    {"article name": "Study of muscular tissue in different physiological conditions using electrical impedance spectroscopy measurements",
     "doi": "https://doi.org/10.1016/j.bbe.2013.10.004",
     "publication date": "01-2014",
     "abstract": "While performing physiological functions, muscles modify their intrinsic characteristics. As has already successfully done in various clinical fields, the technique of electrical impedance spectroscopy (EIS) measurement can be applied in order to study tissue changes. The aim of this study was to study changes in the electrical properties of muscular tissues due to an isometric contraction and successive relaxation.For this work, the electrodes lay out and trials protocol were carefully designed, also according to studies concerning muscle fatigue. A device previously tested and employed for in vivo EIS measurements was used. Impedance measurements were carried out on the forearm flexor muscles in a group of sixteen healthy adult subjects. In order to have a quantitative index of spectral impedance variation, the relative variation of the area under curve of Nyquist plots was computed to study the different muscle states under consideration (rest, contraction and 4 min after contraction).The index introduced showed itself to be sensitive to different muscular conditions. Results from healthy subjects showed statistically significant differences in the impedance data in the various muscle conditions under examination.",
     "keywords": ["Muscular tissue", "Impedance measurements", "Biomedical equipment"]},
    {"article name": "Classification methods for high-dimensional genetic data",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.007",
     "publication date": "01-2014",
     "abstract": "Standard methods of multivariate statistics fail in the analysis of high-dimensional data. This paper gives an overview of recent classification methods proposed for the analysis of high-dimensional data, especially in the context of molecular genetics. We discuss methods of both biostatistics and data mining based on various background, explain their principles, and compare their advantages and limitations. We also include dimension reduction methods tailor-made for classification analysis and also such classification methods which reduce the dimension of the computation intrinsically. A common feature of numerous classification methods is the shrinkage estimation principle, which has obtained a recent intensive attention in high-dimensional applications.",
     "keywords": ["Multivariate statistics", "Classification analysis", "Shrinkage estimation", "Dimension reduction", "Data mining"]},
    {"article name": "Left ventricle phantom and experimental setup for MRI and echocardiography – Preliminary results of data acquisitions",
     "doi": "https://doi.org/10.1016/j.bbe.2013.12.002",
     "publication date": "01-2014",
     "abstract": "Methods for imaging myocardial strains are a subject of intense research. Many methods are being proposed by scientists from numerous laboratories. Those methods are designated for ultrasonic imaging or for magnetic resonance tomography. Attempts to quantitatively compare results obtained from those modalities are scarce. In this work a left ventricle phantom and an experimental setup are described, that enable subsequent acquisition of ultrasonic and MRI data with a well defined phantom geometry and deformation pattern and thus enabling quantitative comparison of strain estimation results. Tagged MRI and ultrasonic RF data appropriate for strain estimation techniques have been registered and presented.",
     "keywords": ["Ultrasonography", "Echocardiography", "Magnetic resonance imaging", "MRI", "Phantom"]},
    {"article name": "Cepstral separation difference: A novel approach for speech impairment quantification in Parkinson's disease",
     "doi": "https://doi.org/10.1016/j.bbe.2013.06.001",
     "publication date": "01-2014",
     "abstract": "This paper introduces a novel approach, Cepstral Separation Difference (CSD), for quantification of speech impairment in Parkinson's disease (PD). CSD represents a ratio between the magnitudes of glottal (source) and supra-glottal (filter) log-spectrums acquired using the source-filter speech model. The CSD-based features were tested on a database consisting of 240 clinically rated running speech samples acquired from 60 PD patients and 20 healthy controls. The Guttmann (μ2) monotonic correlations between the CSD features and the speech symptom severity ratings were strong (up to 0.78). This correlation increased with the increasing textual difficulty in different speech tests. CSD was compared with some non-CSD speech features (harmonic ratio, harmonic-to-noise ratio and Mel-frequency cepstral coefficients) for speech symptom characterization in terms of consistency and reproducibility. The high intra-class correlation coefficient (>0.9) and analysis of variance indicates that CSD features can be used reliably to distinguish between severity levels of speech impairment. Results motivate the use of CSD in monitoring speech symptoms in PD.",
     "keywords": ["Parkinson's disease", "Speech processing", "Dysarthria", "Acoustic analysis", "Speech cepstrum"]},
    {"article name": "Classification of speech intelligibility in Parkinson's disease",
     "doi": "https://doi.org/10.1016/j.bbe.2013.10.003",
     "publication date": "01-2014",
     "abstract": "A problem in the clinical assessment of running speech in Parkinson's disease (PD) is to track underlying deficits in a number of speech components including respiration, phonation, articulation and prosody, each of which disturbs the speech intelligibility. A set of 13 features, including the cepstral separation difference and Mel-frequency cepstral coefficients were computed to represent deficits in each individual speech component. These features were then used in training a support vector machine (SVM) using n-fold cross validation. The dataset used for method development and evaluation consisted of 240 running speech samples recorded from 60 PD patients and 20 healthy controls. These speech samples were clinically rated using the Unified Parkinson's Disease Rating Scale Motor Examination of Speech (UPDRS-S). The classification accuracy of SVM was 85% in 3 levels of UPDRS-S scale and 92% in 2 levels with the average area under the ROC (receiver operating characteristic) curves of around 91%. The strong classification ability of selected features and the SVM model supports suitability of this scheme to monitor speech symptoms in PD.",
     "keywords": ["Parkinson's disease", "Speech processing", "Dysarthria", "Support vector machine", "Tele-monitoring"]},
    {"article name": "Quantification of gait asymmetry in patients with ankle foot orthoses based on hip–hip cyclograms",
     "doi": "https://doi.org/10.1016/j.bbe.2013.10.001",
     "publication date": "01-2014",
     "abstract": "Our work focuses on a new approach of studying asymmetry in walking based on the orientation of the synchronized bilateral hip–hip cyclograms. Patients with foot drop were included in the study and were asked to walk without an orthosis, and with foot-up splint, calf mounted support strap and ankle wrap. The hip–hip cyclograms were created to quantify gait asymmetry before and immediately after the application of ankle foot orthoses. This approach has never been applied before to study the gait asymmetry in patients with ankle foot orthoses. In order to quantify the gait asymmetry, we have tested the application of the approach based on the inclination angle of the synchronized hip–hip cyclograms. The symmetry index was used as a comparative method to evaluate the symmetry of bipedal walking. The results indicate the correlation between the symmetry index and inclination angle of the synchronized hip–hip cyclograms. The methods based on the inclination angle and symmetry index show slightly different results because the symmetry index depends on discrete variables and is unable to reflect the asymmetry as it evolves over a complete gait cycle. The inclination angle of the hip–hip cyclogram depends on the complete gait cycle. Except for the inclination angles of patients with the support strap, the results show that the new approach did not identify significant improvement in the gait symmetry after the application of the orthoses. The approach based on the orientation of the hip–hip cyclograms can be used as an additional approach for determining the gait asymmetry.",
     "keywords": ["Human walking", "Gait asymmetry", "Foot drop", "Cyclogram", "Ankle foot orthosis", "Hip joint angle"]},
    {"article name": "Wearable acceleration sensor application in unilateral trans-tibial amputation prostheses",
     "doi": "https://doi.org/10.1016/j.bbe.2013.10.002",
     "publication date": "01-2014",
     "abstract": "The availability of human walking gait data collected from the wearable acceleration sensors for trajectory control of an active artificial ankle joint in the unilateral trans-tibial prosthesis was investigated in this study. It is observed that the collected acceleration data can be used in the rulebased control of the prosthetic leg. A portable microprocessor-based data acquisition system, and data transfer module were designed for capturing the acceleration signals during walking. Flexionextension angle pattern of ankle joint was determined from acceleration signals of two tri-axial wearable accelerometers placed on the shank and foot segments. This pattern was utilized for control of the active artificial ankle joint in the trans-tibial prosthesis. This approach may have the potential of contributing the development of better prostheses.",
     "keywords": ["Wearable acceleration sensor", "Trans-tibial prosthesis", "Rule-based control", "Ankle pattern", "Walking gait", "Rehabilitation"]},
    {"article name": "Assessment of participant compliance with a Web-based home healthcare system for promoting specific health checkups",
     "doi": "https://doi.org/10.1016/j.bbe.2013.12.001",
     "publication date": "01-2014",
     "abstract": "We investigated the effectiveness of a Web-based healthcare system that allows participants to record measurements of blood pressure, body weight, and the number of steps walked per day. After receiving a medical examination, participants were registered on the Web-based system and encouraged to record data. A total of 223 participants initiated contact with the system; however, only 27 monitored their blood pressure on more than 60 days during the 3-month period. Furthermore, only 46 participants monitored their body weight, and 79 monitored the number of steps taken per day. Although specific health checkups are important to prevent diseases, we conclude that existing health checkup monitoring is not sufficient, and we should develop a new Web-based health checkup and monitoring system that is more familiar to the participants.",
     "keywords": ["Blood pressure monitoring", "Health checkups", "Healthcare", "Web"]},
    {"article name": "Surface electromyography for assessing triceps brachii muscle activities: A literature review",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.001",
     "publication date": "01-2013",
     "abstract": "The goal of this review was to summarise the scientific findings of research conducted on the triceps brachii muscle using surface electromyography. To achieve this goal, we searched through several articles available from the online databases ScienceDirect and SpringerLink published in the English language between January 2008 and June 2012. We specifically searched for the phrases “EMG” and “triceps brachii” in the title, abstract, keywords or methods sections. From a total of 569 articles we identified 77 potentially relevant studies where 42 studies have been examined triceps brachii muscle activity using surface electromyography that applied in the field of rehabilitation, physiological exercise, sports, and prosthesis control. Among the 42 articles found, 16 studies have been examined triceps brachii muscle activity in rehabilitation, 13 for physiological exercise, 9 for sports, and 4 for prosthesis control in this literature review. We therefore believe that the information contained in this review will greatly assist and guide the progress of studies that use surface electromyography to measure triceps brachii muscle activity in the context of rehabilitation, physiological exercise, sports, and prosthesis control.",
     "keywords": ["Triceps brachii muscle activity", "Surface electromyography", "Rehabilitation", "Physiological exercise", "Sports", "Prosthesis control"]},
    {"article name": "Integration of EEG and SPECT data acquired from simultaneous examinations",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.002",
     "publication date": "01-2013",
     "abstract": "The aim of this study was to develop a convenient method for superimposing SPECT images and EEG maps. This work was performed as part of research concerning feasibility of improving the localization of epileptic foci comparing to the standard SPECT examination by applying the technique of EEG mapping. The described method relies on making five EEG electrodes visible in SPECT images, calculating the coordinates of these electrodes in SPECT image space, approximating the coordinates of the remaining electrodes used in EEG recording and then computing a sequence of 3D EEG maps spanning on all the electrodes. An example of visualization of EEG and SPECT data integration was presented. The maximum error of the five base electrodes location was assessed below 10 mm. Assuming the exact placement of the base electrodes the accuracy of the proposed method was estimated below 5.5 mm.",
     "keywords": ["SPECT", "EEG mapping", "Multimodal co-registration", "BioImage Suite", "EEG electrodes"]},
    {"article name": "Evaluation of voice-based data entry to an electronic health record system for dentistry",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.003",
     "publication date": "01-2013",
     "abstract": "This paper compares three methods of storage data of the patients in the field of dentistry: the paper dental card, a lifetime dental EHR controlled by keyboard and a lifetime dental EHR controlled by voice. The EuroMISE Center developed a pilot EHR application called MUDR Lite (multimedia distributed electronic health record). The study compares the elapsed time necessary to update/enter the information about the patient's dental status using the above mentioned three methods. The paper dental card is the most rapid method, but not the best for medical documentation and dentists.",
     "keywords": ["Dentistry", "Medical documentation", "Electronic health record", "Automatic speech recognition"]},
    {"article name": "Improving fetal heart rate signal interpretation by application of myriad filtering",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.004",
     "publication date": "01-2013",
     "abstract": "Analysis of the fetal heart rate (FHR) signal is aimed at detection of clinically important patterns like bradycardia or tachycardia, accelerations and decelerations, as well as quantification of instantaneous FHR variability. Automated pattern recognition methods are based on estimation of so-called FHR baseline. It is a common opinion that the baseline estimation algorithm determines the efficiency of an entire process of quantitative signal analysis. Automated methods for baseline determination have been continuously improved for many years since there are still new classes of FHR signals being identified, for which the previous methods fail. The new method proposed for the baseline estimation is based on the weighted myriad filtering. The application of this method required filter parameter selection ensuring its operation according to clinical guidelines for baseline estimation. A very important feature of the myriad filtering is that there is no need for preliminary interpolation of signal loss segments. Our new algorithm was tested against two other methods. Thirty one-hour FHR recordings were selected for the analysis. Quantitative inconsistency was measured using differences between corresponding baseline samples. Additionally, the baselines were evaluated as regards their influence on identification of the acceleration and deceleration patterns. Obtained results allow us to conclude that the new algorithm delivers more reliable baselines particularly for signals with specific changes of the basal FHR level which has been recognized as difficult for baseline estimation.",
     "keywords": ["Electronic fetal monitoring", "Fetal heart rate analysis", "Baseline estimation", "Signal processing"]},
    {"article name": "Rule based functional description of genes – Estimation of the multicriteria rule interestingness measure by the UTA method",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.005",
     "publication date": "01-2013",
     "abstract": "In this paper we present new extension of RuleGO rule generation method. The method was designed to discover logical rules including combination of GO terms in their premises in order to provide functional description of analyzed gene signatures. As the number of obtained rules is typically huge, filtration algorithm is required to select only the most interesting ones. Rule interestingness measures currently used within the RuleGO method do not always allow for the selection of the rules according to user's subjective preferences. In this paper we propose an application of the UTA method for estimation of the multicriteria rule interestingness measure reflecting expert's subjective rule evaluation. In the presented method, each of the rules is characterized by a vector of values reflecting its quality due to the different parial interestingness measures. From the designated set of rules a set of representative rules is selected and presented to an expert who orders the rules based on his preferences. Using the information about the order and values of the partial interestingness measures, the additive multicriteria interestingness measure is estimated. The measure is estimated in such a way that the rule ranking obtained by this function is consistent with the ranking given by an expert. The presented approach is applied to three microarray data sets and obtained rule orders are compared with rule orders generated with the standard RuleGO rule evaluation method. Presented method allows obtaining the rule ranking that is better correlated with expert ranking than the ranking obtained in the standard way.",
     "keywords": ["Multicriteria rule evaluation", "Rule interestingness", "UTA method", "Logical rules", "Gene Ontology", "Expression data"]},
    {"article name": "Aryl and N-arylamide carbon nanotubes for electrical coupling of laccase to electrodes in biofuel cells and biobatteries",
     "doi": "https://doi.org/10.1016/j.bbe.2013.09.006",
     "publication date": "01-2013",
     "abstract": "Single walled carbon nanotubes (SWCNTs) were equipped with aryl residues by chemical reactions. These insoluble materials were used to substitute classical soluble mediators, which help to transfer electrical charge between the conducting electrode and the redox active center of enzyme molecules. The effect of different aryl residues on the efficiency of the catalytic reduction of dioxygen in the presence of laccase was systematically studied using voltammetry and measuring the power output of a biofuel cell.",
     "keywords": ["Biocathode", "Biobattery", "Chemically modified carbon nanotubes", "Electron transfer", "Laccase"]},
    {"article name": "Machine learning in lung sound analysis: A systematic review",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.001",
     "publication date": "01-2013",
     "abstract": "Machine learning has proven to be an effective technique in recent years and machine learning algorithms have been successfully used in a large number of applications. The development of computerized lung sound analysis has attracted many researchers in recent years, which has led to the implementation of machine learning algorithms for the diagnosis of lung sound. This paper highlights the importance of machine learning in computer-based lung sound analysis. Articles on computer-based lung sound analysis using machine learning techniques were identified through searches of electronic resources, such as the IEEE, Springer, Elsevier, PubMed and ACM digital library databases. A brief description of the types of lung sounds and their characteristics is provided. In this review, we examined specific lung sounds/disorders, the number of subjects, the signal processing and classification methods and the outcome of the analyses of lung sounds using machine learning methods that have been performed by previous researchers. A brief description on the previous works is thus included. In conclusion, the review provides recommendations for further improvements.",
     "keywords": ["Review", "Lung sound", "Lung disorder", "Statistical", "Machine learning"]},
    {"article name": "A method for quantification of lung resistive and compliant properties for spirometry interpretation support—Tests on a virtual patient",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.002",
     "publication date": "01-2013",
     "abstract": "The forced expiratory volume in one second (FEV1), the fundamental index in obstructive lung disease diagnosis, depends on both resistive (RP) and compliant (CP) properties of the respiratory system (RS). The study aim was to test initially a method that could differentiate their influence to aid spirometry interpretation during screening examinations. Tests were done on a virtual RS elaborated previously. After respiratory muscle relaxation, a part of air was exhaled passively to an added compliance (Cad) or through an added resistance (Rad). The CP and RP were estimated from mouth pressure changes under different conditions of RS and measurement (different obstruction severities, various Cad and Rad values, etc.). Measurements had to be performed after maximal inspiration to avoid dependence of results on the lung volume. The Cad maneuver enabled to estimate the CP properly. Inertances and bronchi collapse caused pressure fluctuations, whereas bronchi reopening modified pressure rise after airflow interruption. Rad > 0.8 kPa s/L eliminated these problems and made the RP estimation independent from the Rad value and the CP. The calculated value of resistance depended on both airway resistance and parenchyma viscosity (like FEV1) and viscosity of other tissues. Since collapse instantaneous observation in real patients is impossible, initial but extensive tests illustrating influence of the collapse on measurement could be done only on a virtual RS.",
     "keywords": ["Airway resistance", "Interrupter technique", "Respiratory system compliance", "Spirometry"]},
    {"article name": "Fetal state assessment using fuzzy analysis of fetal heart rate signals—Agreement with the neonatal outcome",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.003",
     "publication date": "01-2013",
     "abstract": "Fetal monitoring is based on analysis of fetal heart rate signal. Visual interpretation is difficult so computer-aided systems for quantitative analysis are commonly used. The clinical interpretation guidelines provided by FIGO (Fédération Internationale de Gynécologie et d’Obstétrique) were used to develop the weighted fuzzy scoring system for qualitative assessment of the fetal state. In this work, agreement of the fuzzy classification system with the neonatal outcome assessment was analyzed. Various datasets were evaluated, depending on interpretation method of the signals which were recorded from patients. The obtained results confirmed possibility of the efficient fetal state assessment using the fuzzy inference method proposed.",
     "keywords": ["Fetal monitoring", "Fetal heart rate analysis", "Fuzzy systems", "Signal classification"]},
    {"article name": "The effect of type of filters and collimators on the SPECT axis of rotation error",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.004",
     "publication date": "01-2013",
     "abstract": "High resolution and artifact free SPECT reconstruction of the distribution of radioactive sources over the entire imaging field requires exact alignment between the electronic and the mechanical axis of rotations. In this paper, the effect of misalignment between the electronic and the mechanical axis of rotations of SPECT system equipped with low-energy high-resolution and low-energy general-purpose collimators through the field of view has been studied. In addition, the useful dimensions of the SPECT field of view without artifact due to axis of rotation error have been calculated. Furthermore, the roles of digital filters in reducing this effect have been studied.",
     "keywords": ["SPECT", "LEHR collimator", "LEGP collimator"]},
    {"article name": "Exploratory data analysis for outlier detection in bioequivalence studies",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.005",
     "publication date": "01-2013",
     "abstract": "Exploratory Data Analysis techniques are recognized as useful tools in outlier detection through visual representations. One limitation of this direction is the lack of studies concerning the reliability of the visual interpretation. In this paper we propose a method that combines an Exploratory Data Analysis technique, Andrews curves, with a statistical approach which can be applied to automatically classify the data. Using a simulation study we show that the results provided by the Andrews curves approach are markedly superior to the estimates distance test (the best proposed method for detecting outliers revealed in the literature) for the crossover bioequivalence design.",
     "keywords": ["Outlier detection", "Bioequivalence studies", "Crossover design", "Andrews curves", "Estimates distance"]},
    {"article name": "Time-efficient removal of power-line noise from EMG signals using IIR notch filters with non-zero initial conditions",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.006",
     "publication date": "01-2013",
     "abstract": "Power-line interference is always a problem when biopotential signals are recorded. This paper presents a technique for time-efficient power-line interference suppression from EMG signals using digital IIR (Infinite Impulse Response) notch filters with reduced transient response. The reduction of the transient response is obtained by finding optimal non-zero initial conditions for the considered notch filters. Simulations verifying the effectiveness of the proposed technique are presented and compared with the performance of the traditional notch filters with zero initial conditions using EMG signal with unwanted sinusoidal interferences as a study case.",
     "keywords": ["Signal processing", "Power-line noise", "EMG signal", "Notch filters", "Transient response", "Initial conditions"]},
    {"article name": "A computer system for a human semen quality assessment",
     "doi": "https://doi.org/10.1016/j.bbe.2013.07.007",
     "publication date": "01-2013",
     "abstract": "An automatic computer system to assist assessment of a human semen quality is described. The hardware of the system consists of PC with frame grabber and CCD camera connected to an optical microscope with bright field optic. The software of the system consists of four modules: (1) acquisition of real time sequences of semen, (2) assessment of mobility o sperm cells, (3) calculation of density, and (4) morphology examination of sperm cells.There are few commercial CASA (Computer Assisted Semen Analysis) systems that measure a quantity of semen. Some of them measure only one factor of semen whereas others recognize sperm cells based on user-defined parameters. The described system calculates all factors required for semen quality assessment and recognizes sperm cells by its shape, structure and size.",
     "keywords": ["Image processing", "Image recognition", "Computer system", "Sperm cell", "Semen"]},
    {"article name": "Protein structural classification based on pseudo amino acid composition using SVM classifier",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.002",
     "publication date": "01-2013",
     "abstract": "This paper deals with a structural classification by the aid of support vector machine (SVM) classifier. Amino acid composition (AAC) and pseudo amino acid composition (PseAA) features were applied with different variants. Additionally the feature reflecting the length of protein chain was taken into consideration. The SVM classifier was compared to minimal-length classifiers with respect to the AAC features. The best model of SVM classifier was chosen using grid method on the basis of cross-validation (CV) as criterion. The best model of SVM classifier is evaluated with respect to proper evaluation rates. The SCOP database and the ASTRAL tool were a source of non-homologous data to avoid the redundancy and to ensure a maximal amount of available data.",
     "keywords": ["Pseudo amino acid composition", "Support vector machine", "Minimal-distance methods", "Protein structural class", "SCOP database"]},
    {"article name": "The study on pH gradient control in solution for driving bacteria",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.003",
     "publication date": "01-2013",
     "abstract": "Medical applications are the most impactful areas of microrobotics, such as targeting tumoral lesions for therapeutic purposes, minimally invasive surgery (MIS) and highly localized drug delivery. However, miniaturization of the power source with an effective onboard controllable propulsion system has prevented the implementation of such mobile robots. Flagellated chemotactic bacteria can be used as an effective integrated propulsion system for microrobots. In this paper, we study the pH gradients control in solution for driving bacteria. The swimming property of flagellar bacteria and mechanism of forming the pH gradient field in solution are discussed. By experiments, we found that the pH gradient field distribution in solution is mainly related to the electrode shape. And the input voltage value can control the stable time of the pH gradient field, while it has no effect on the distribution of the field. The electric potential distribution is analyzed by simulation with COMSOL Multiphysics. The simulation results are consistent with the experiment results, which indicate that the bacteria movement can be controlled by the electrodes’ shape and the input voltage.",
     "keywords": ["Bacteria driven robot", "Electrolysis", "pH gradient"]},
    {"article name": "Wearable lower limb robotics: A review",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.005",
     "publication date": "01-2013",
     "abstract": "Owing to the recent progress in the field of supportive robotic technologies, interest in the area of active orthoses and exoskeletons has increased rapidly. The first attempts to create such devices took place 40 years ago. Although many solutions have been found since then, many challenges still remain. Works concerning the lower extremities and active orthoses are listed and described in this paper. The research conducted and commercially available devices are presented, and their actuation, hardware, and movements they make possible are described. In addition, possible challenges and improvements are outlined.",
     "keywords": ["Wearable robotic", "Rehabilitative robotic", "Lower limbs", "Active orthosis", "Exoskeleton"]},
    {"article name": "Planar arm movement trajectory formation: An optimization based simulation study",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.006",
     "publication date": "01-2013",
     "abstract": "Rehabilitation of post stroke patients with upper extremity motor deficits is typically focused on relearning of motor abilities and functionalities requiring interaction with physiotherapists and/or rehabilitation robots. In a point-to-point movement training, the trajectories are usually arbitrarily determined without considering the motor impairment of the individual. In this paper, we used an optimal control model based on arm dynamics enabling also incorporation of muscle functioning constraints (i.e. simulation of muscle tightness) to find the optimal trajectories for planar arm reaching movements. First, we tested ability of the minimum joint torque cost function to replicate the trajectories obtained in previously published experimental trials done by neurologically intact subjects, and second, we predicted the optimal trajectories when muscle constraints were modeled. The resulting optimal trajectories show considerable similarity as compared to the experimental data, while on the other hand, the muscle constraints play a major role in determination of the optimal trajectories for stroke rehabilitation.",
     "keywords": ["Trajectory planning", "Stroke rehabilitation", "Upper extremity", "Muscle tightness", "Dynamic optimization", "Rehabilitation robotics"]},
    {"article name": "A powered prosthetic knee joint inspired from musculoskeletal system",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.004",
     "publication date": "01-2013",
     "abstract": "This paper reports on a powered prosthetic knee joint powered by artificial muscles. A musculoskeletal system integrating artificial and biological muscles was simulated. The gait cycle was divided into seven modes. Based on the results of the simulation, the artificial muscles were pressurized to provide the biological knee torque. Analysis of the gait trials of an amputee showed the timing of artificial muscles was similar to EMG of biological knee muscles. This paper is an initial step forward to implement the concept of biomimetic approach in prosthetic knee technology.",
     "keywords": ["Prosthetic knee", "Biomimetics-musculoskeletal system"]},
    {"article name": "Saccadometry and LATER model shed light on brain plasticity in aging",
     "doi": "https://doi.org/10.1016/j.bbe.2013.03.001",
     "publication date": "01-2013",
     "abstract": "As frequency of falls increases in older adults, understanding how motor training programs counteract motor decline is a challenging issue. This study examined ocular saccades to test the effects of fall prevention (FP) on central motor control of older fallers. Saccades were recorded using a saccadometer in twelve participants aged 64–91 years before and after 2.5-month training in FP. We performed LATER analysis enabling us to examine the changes in motor control. FP decreased saccade latency and increased left-right symmetry of motor responses. LATER analysis showed that FP modulated decisional thresholds extending our knowledge of FP influence on motor control.",
     "keywords": ["Aging", "Motor control", "Eye movements", "Saccade", "Motor activity", "Plasticity"]},
    {"article name": "Comparison of Performance of Different Feature Extraction Methods in Detection of P300",
     "doi": "https://doi.org/10.1016/S0208-5216(13)70052-4",
     "publication date": "01-2013",
     "abstract": "The aim of this paper is to design a pattern recognition based system to detect the P300 component in the EEG trials. This system has two main blocks, feature extraction and clas-sification. In the feature extraction block, in addition to morphological features, some new features including intelligent segmentation, common spatial pattern (CSP) and combined features (CSP + Segmentation) have also been used. Two criteria were used for the feature evaluation. Firstly, a t-test has been applied. Secondly, each of these four groups of features was evaluated by a Linear Discriminant Analysis (LDA) classifier. Afterwards, the best set of features was selected by using Stepwise Linear Discriminant Analysis (SWLDA). In the classification phase, the LDA was used as a linear classifier. The algorithm described here was tested with dataset II from the BCI competition 2005. In this research, the best result for the P300 detection was 97.4%. This result has proven to be more accurate than the results of previous works carried out in this filed.",
     "keywords": ["P300", "brain computer interface (BCI)", "pattern recognition", "feature extraction", "classification"]},
    {"article name": "NMR-based Metabonomics of Cerebrospinal Fluid Applied to Amyotrophic Lateral Sclerosis",
     "doi": "https://doi.org/10.1016/S0208-5216(13)70053-6",
     "publication date": "01-2013",
     "abstract": "The aim of this study was applications of cerebrospinal fluid (CSF) NMR-based metabolic fingerprinting to amyotrophic lateral sclerosis (ALS) as possible early diagnostic tool. Two CSF sample categories were collected: 9 ALS patients and 13 age-matched control patients (without neurological disease). Metabolic profile of the CSF was determined by high resolution proton NMR spectroscopy. For statistical analysis magnitudes of 33 signals of the NMR spectrum were selected. Partial least square discriminant analysis (PLS-DA) and orthogonal PLS-DA (OPLS-DA) modeling were used to find potential biomarkers of the disease. Those analyses showed that it was possible to distinguish the ALS patients from the control ones on the basis of the CSF metabolic profile. Significantly higher levels of metabolites observed in the patients with ALS may represent the state of anaerobic metabolism and excitotoxicity.",
     "keywords": ["cerebrospinal fluid", "amyotrophic lateral sclerosis", "NMR spectroscopy", "metabolomics", "discriminant analysis"]},
    {"article name": "Performance Comparison of Artificial Neural Network and Gaussian Mixture Model in Classifying Hand Motions by Using sEMG Signals",
     "doi": "https://doi.org/10.1016/S0208-5216(13)70054-8",
     "publication date": "01-2013",
     "abstract": "In this study, a home-made four channel sEMG amplifier circuit was designed for measu-ring of sEMG signals. The measured sEMG signals were recorded on to a computer with help of a DAQ board. The recorded sEMG signals were filtered first with a high-pass filter and afterwards a wavelet based filtering was applied to remove unwanted noises. Before applying of the wavelet based filtering, it was first determined which wavelet type, threshold selection rule and threshold would be suitable for the denoising process. As a second step, the recorded and denoised signals’ features were extracted. For classification of motions 8 time domain and 2 frequency domain features were used individually and in combinations. Lastly, seven different motions were classified and their classification performances were compared. In this study, classification rates of ANN and GMM classifiers were compared as regards features.",
     "keywords": ["hand motion classification", "artificial neural network", "gaussian mixture model"]},
    {"article name": "Feature Selection of Protein Structural Classification Using SVM Classifier",
     "doi": "https://doi.org/10.1016/S0208-5216(13)70055-X",
     "publication date": "01-2013",
     "abstract": "Recursive feature elimination method (RFE), cross validation coefficient (CV) and accuracy of classification of test data are applied as a criterion of feature selection in order to find relevant features and to analyze their influence on classifier accuracy. Feature selection method was compared to principal component analysis (PCA) to understand the effectiveness of feature reduction. Support vector machine classifier with radial basis function (RBF) kernel is applied to find the best set of features using grid model selection and to select and assess relevant features. The best selected feature set is then analyzed and interpreted as the source of knowledge about the protein structure and biochemical properties of amino acids included in the protein domain sequence.",
     "keywords": ["pseudo amino acid composition", "support vector machine", "principal component analysis", "recursive feature elimination", "feature selection", "SCOP database"]},
    {"article name": "Equalisation of Archival Microscopic Images from Immunohistochemically Stained Tissue Sections",
     "doi": "https://doi.org/10.1016/S0208-5216(13)70056-1",
     "publication date": "01-2013",
     "abstract": "A method of image equalisation that reduces non-uniformity of light distribution caused by optical devices and dust on camera sensors is presented. The method explores non-uniformity which occurs in archival images captured by a typical optical set which consists of a light microscope and a digital camera. A sufficient number of images with low density of foreground objects has been used to extract a global map of non-uniformity of the particular microscope and camera. The proposed method consists of two steps: – (1) extraction of the map of non-uniformity based upon a set of chosen images and – (2) correction of images acquired by the optical set. The global map is created based upon a modified value layer, the third layer of HSV colour space. The proposed method has been tested on images of immunohistochemically (IHC) stained samples of a biopsy tissue, and it has been validated using an image segmentation method developed earlier. The results of the light distribution equalization, as well as the equalized images segmentation turn out to be more similar to the reference method results (namely the manual counting results), than the results of the original images segmentation. The equalization method can be used for other types of images, but all of them should be acquired by the same optical set.",
     "keywords": ["immunohistochemically stained images", "image light distribution", "image equalization"]},
    {"article name": "Animal Models of Duchenne Muscular Dystrophy, with Special Reference to the mdx Mouse",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70045-1",
     "publication date": "01-2012",
     "abstract": "Duchenne muscular dystrophy (DMD) is a progressive muscle wasting disease that affects approximately 1 in 3500 male births. We describe animal models of DMD with special reference to the mdx mouse. We also describe some of the standard operating procedures (SOPs) developed by the TREAT-NMD neuromuscular network (http://www.treat-nmd.eu/) for assessment of the mdx mouse, with a focus on techniques for assessing cardiac function that are used in our lab, including the cardiac conductance catheter. We have also recently developed cardiac MRI as a novel cardiac assessment technique for mouse models of muscular dystrophy. We describe how this technique can be used both in the assessment of ventricular function and in the investigation of the role of abnormal calcium influx in muscular dystrophy-associated cardiomyopathy.",
     "keywords": ["duchenne muscular dystrophy", "mdx mouse", "cardiomyopathy", "animal models", "MRI", "cardiac catheter", "standard operating procedures"]},
    {"article name": "Sporadic Amyotrophic Lateral Sclerosis: Brief Pathogenic Review and a New Causal Hypothesis",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70046-3",
     "publication date": "01-2012",
     "abstract": "This article summarizes the pathogenic mechanisms known to be responsible for sporadic amyotrophic lateral sclerosis, such as excitoxicity, endoplasmic reticulum stress, oxidative stress, proteins damage, inflammation, genes abnormalities and neuronal death; some clinical features of the disorder are discussed as well. Finally, it puts forward the hypothesis that astrocytes, rather than the motor neurons, may be the cells initially damaged by the action of a still unknown causal agent, being the neuronal death a consequence of that first insult. The article suggests that an emergent virus, perhaps a retro-virus, or a misfolded infectious protein might be the agent able to accomplish the task.",
     "keywords": ["amyotrophic lateral sclerosis", "sporadic amyotrophic lateral sclerosis", "SALS cause", "SALS pathogenesis", "motoneurons related astrocytes", "motor neuron diseases"]},
    {"article name": "Variability and Plasticity of Motor Unit Properties in Mammalian Skeletal Muscle",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70047-5",
     "publication date": "01-2012",
     "abstract": "In the majority of mammalian skeletal muscles, contractile properties of motor units are variable and three main types of these units can be distinguished. The present review summarizes: results of studies of motor unit properties in the medial gastrocnemius muscle and their variability in two species, cats and rats, and studies on differences of motor unit properties in two genders. Moreover, plasticity of motor unit properties in rat medial gastrocnemius evoked by two kinds of spinal cord injury, total transection and hemisection, is reviewed, and effects of two types of training, treadmill locomotor and whole-body vibration training, are summarized. Finally, changes in the motor unit properties during the aging process are presented.",
     "keywords": ["motor unit", "plasticity", "contractile properties", "motor unit action potentials"]},
    {"article name": "Monitoring of Sweat Secretion from Eccrine Sweat Glands Using Electric Conductivity Method",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70048-7",
     "publication date": "01-2012",
     "abstract": "Sweat secretion from a single sweat gland can be monitored by using microtube or by visual observation of the skin region using a microscope or video recorder. Another method described in the present paper is based on perfusion with ultra-low conductive water of a small region of the skin with only one sweat pore. Sweat secreted from a gland is reach in ions comparing to perfusion fluid and therefore increases conductivity of the perfusion fluid. Conductivity of the perfusion fluid is measured on inlet and outlet of the measure-ment probe and the diference is amplified and sampled by an analog-to-digital converter controlled by developed software on PC. The goal of the present paper is to present an improved system of single sweat glands monitoring.",
     "keywords": ["single sweat gland", "electric conductivity method", "sweat gland activity"]},
    {"article name": "Continuous Monitoring of Feet Temperature Using a Data Logger with Wireless Communication",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70049-9",
     "publication date": "01-2012",
     "abstract": "The aim of the present study was to verify a system for continuous monitoring of feet temperature. The temperature measurement system developed in cooperation of the Center for Biomedical Technology (Krems, Austria) and Digilog Inc. (Perg, Austria) company was used for monitoring of the skin temperature on foot. The temperature monitoring devices are wirelessly controlled and they could be encapsulated in order to achieve waterproofing and facilitate disinfection with liquid disinfectant. The skin temperature measurements were performed every 1 or 5 minutes. Two healthy subjects were monitored for 7-9 days. The preliminary system application showed its usefulness in continuous temperature monitoring of feet.",
     "keywords": ["continuous temperature monitoring", "foot temperature"]},
    {"article name": "Membranes’ Porosity Evaluation by Computer-aided Analysis of SEM Images - a Preliminary Study",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70050-5",
     "publication date": "01-2012",
     "abstract": "The problem of quality control of membranes destined for medicai applications is presented. The shape of the membranes surface, its structure, porosity and coarseness are of importance in contact with live cells or simply with live tissue, and as such they should be controlled. For this purpose, scanning electron microscopy (SEM) in our work was used. Results of capillary polysulphone (PSF) 70000 m.m. and polyetherosulphone (PES) 42000 m.m. membranes examination are described. An attempt to apply the computer-aided SEM images processing methods to the membranes’ porosity evaluation was made and is presented in the paper. In particular, an approach to segmentation ofcontours of micropores in the visualized membrane’s sections and to evaluation of their morphological parameters is described. An attempt to an approximate statistical reconstruction of 3-dimensional structure of micropores on the basis of collections of 2-dimensional membranes’ sections is also described.",
     "keywords": ["polysulfone membrane porosity", "semipermeable polysulfone membranes", "structure polysulfone membranes", "computer-aided image processing"]},
    {"article name": "A Hybrid (Hydro-numerical) Cardiovascular Model: Application to Investigate Continuous-flow Pump Assistance Effect",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70051-7",
     "publication date": "01-2012",
     "abstract": "A hybrid (Hydro-numerical) model of blood circulation developed at the Institute of Biocybernetics and Biomedical Engineering (IBIB) of the Polish Academy of Sciences (PAN) -Warsaw, Poland, in co-operation with the Institute of Clinical Physiology (IFC) of the National Council of Research (CNR) - Rome, Italy, is a basic model of this type solutions commonly accepted by the researchers. It is able to simulate all essential hemodynamic functions of the human cardiovascular system including the heart. During last years, resumption of works on constant-flow non pulsatile rotary pumps to be used as heart support devices is observed because of their small dimensions and easier way of implantation. Control modes of rotary pumps are different and evidently influence heart support effects. The main aim of this paper was to investigate different control systems of rotary pumps in a role of the assist devices. To fulfill this task on the hybrid model, a special computer application was worked out. The investigations included: a) loading characteristics p(q) of the rotary pump assignment at two values of a control voltage - 18 V, 24V; b) physiological and pathological states simulation including parallel atrial-aortic assistance by the rotary pump. The results of the simulations obtained on the model treated as a “virtual patient” are in agreement with the data received in medical conditions.",
     "keywords": ["hybrid (Hydro-numerical) model of blood circulation", "constant-flow rotary pumps", "parallel atrial-aortic assistance"]},
    {"article name": "High-density Surface EMG: Techniques and Applications at a Motor Unit Level",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70039-6",
     "publication date": "01-2012",
     "abstract": "Surface EMG comprises a variety of widely applied experimental tools in basic neuroscience, biomechanics and exercise physiology, but also in applied disciplines like clinical neuro-physiology, ergonomics and sports sciences. To increase the usefulness of surface EMG, we contributed to the introduction and application of a spatiotemporal variant of the usual single channel surface EMG techniques, called high-density surface EMG (HD-sEMG). In the present paper, we first discuss the background of the HD-sEMG technique and basic principles of recording and analysis. In a second part, we illustrate the usefulness of the technique on the basis of studies in which the analysis of HD-sEMG at a motor unit level is at hand. It concerns a precise analysis of the activity of the facial musculature that leads to a map of muscle fibre directions and the positions of motor endplate zones. Two other applications refer to neuromuscular pathology, being motor unit number estimation and the quantification of spontaneous motor unit activity, known as fasciculations.",
     "keywords": ["high density surface EMG", "motor unit number estimation", "fasciculations", "spatiotemporal EMG activity", "facial musculature"]},
    {"article name": "Motor Unit Contractions Evoked by Stimulation with Variable Interpulse Intervals",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70040-2",
     "publication date": "01-2012",
     "abstract": "During natural contractions motor units (MUs) are activated by variable frequency discharge patterns of motoneurones. The aim of this review was (1) to discuss differences between tetanic contractions developed at constant and random frequencies of pulses; (2) to show results of mathematical decomposition of these tetani into series of twitch-shaped responses to individual pulses; (3) to indicate that it is possible to predict the tetanic force of a MU with high accuracy by using regrxession equations derived on a basis of the relationships between the parameters of the decomposed twitches and the force level at which the next response begins.",
     "keywords": ["motor unit", "tetanic force", "decomposition", "rat"]},
    {"article name": "Assessment of Human Motoneuron Afterhyperpolarization Duration in Health and Disease",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70041-4",
     "publication date": "01-2012",
     "abstract": "The results of the investigation of afterhyperpolarization (AHP) duration in normal aging and selected neuromuscular disorders are presented. This investigation yielded unexpected results: the AHP shortening in myogenic disease (DMD) and no significant difference from control values in neurogenic disease (ALS). However, introduction of age factor revealed novel aspects of the human ALS, which can be interpreted on the basis of the results obta-ined in a SOD1 mice, thus confirming usefulness of this animal model of ALS. In spastic patients the AHP was prolonged and the difference from the control AHP duration decre-ased with age and disease duration. Our results suggest that the match between temporal characteristics of the AHP of MN and of the twitch of its muscle unit is preserved during normal aging and in spasticity, but not in the DMD.",
     "keywords": ["human motoneurone", "afterhyperpolarization", "aging", "duchenne muscular dystrophy", "amyotrophic lateral sclerosis", "post-stroke spasticity"]},
    {"article name": "Culture of Human Autologous Chondrocytes on Polysulphonic Membrane – Preliminary Studies",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70042-6",
     "publication date": "01-2012",
     "abstract": "This work investigated an effective method of isolation and culture of human autologous chondrocytes placed on a polysulphonic membrane. The cartilage was taken from the hip joint of 78 years old woman who underwent total hip arthroplasty due to idiopatic arthrosis and from the knee of 46 years old man with cartilage lesion from non-weight bear area. The cells were released from the matrix in the course of enzymatic digestion. The isolated cells were placed with parts of polysulphonic membrane in the same culture flask and incubated. Due to evaluation the weight of tissue grown on the polysulphonic membrane the elementary analysis was performed. The elementary analysis of the polysulphonic membrane slices after ten weeks of the culture revealed higher concentration of the tissue on one part of the membrane in case of the older woman −0.726 mg of protein per 1 mg of the membrane then in case of man −0.513 mg per 1 mg. The established method of isolation and culture of chondrocytes is effective enough to provide a sufficient number of cells that can be used as a transplant.",
     "keywords": ["autologous chondrocytes", "polysulphonic membrane", "burning analysis"]},
    {"article name": "Linear Regression Modeling of Interval-censored Survival Times Based on a Convex Piecewise-linear Criterion Function",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70043-8",
     "publication date": "01-2012",
     "abstract": "Regression models of censored survival data are often required to handle the cases, where information on the dependent (response) variable is only available as intervals, within which the actual values are located. We report on implementation and some preliminary tests of a new general method for regression with an interval-censored response variable. This method is based on minimization of a convex piecewise-linear (CPL) criterion function introduced earlier for perceptron-type classifier design. The presented interval regression method (CPL-IR) can handle arbitrary pattern of exact and left-, right-, or interval-censored data in one flexible computational framework.",
     "keywords": ["interval regression", "interval censoring", "censored data", "current-status data", "survival time", "CPL function"]},
    {"article name": "An Attempt to Speed-up the Examination of Saccadic Reaction Time",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70044-X",
     "publication date": "01-2012",
     "abstract": "One of possible ways to speed-up the prosaccadic latency examination is applying the target walk paradigm. The authors describe the physiological phenomena involved in carrying such paradigms, which may affect latency time and which should be balanced in this kind of task. Thirteen subjects were examined applying the newly designed target-walk paradigm and for comparison the standard prosaccade task. A significant reduction of the saccadic latency (p < 0.01) was found on average by 21 ms, which probably resulted from an increased saccadic decision urgency forced by the new test design. Another reason can be different ways of capturing of the subject’s attention achieved in this task.",
     "keywords": ["saccadic latency", "standard prosaccade task", "inhibition of saccadic return", "directional asymmetry"]},
    {"article name": "Highly Robust Statistical Methods in Medicai Image Analysis",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70033-5",
     "publication date": "01-2012",
     "abstract": "Standard multivariate statistical methods in medicai applications are too sensitive to the assumption of multivariate normality and the presence of outliers in the data. This paper is devoted to robust statistical methods. In the context of medical image analysis they allow to solve the tasks of face detection and face recognition in a database of images. The results of the robust approaches in image analysis turn out to outperform those obtained with standard methods. Robust methods also have desirable properties appealing for practical applications, including dimension reduction and clear interpretability.",
     "keywords": ["robust statistics", "classification", "faces", "robust image analysis", "faces", "forensic science"]},
    {"article name": "Boosting, Bagging and Fixed Fusion Methods Performance for Aiding Diagnosis",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70034-7",
     "publication date": "01-2012",
     "abstract": "Multiple classifier fusion may generate more accurate classification than each of the constituent classifiers. The aim was to examine the ensemble performance by the comparison of boosting, bagging and fixed fusion methods for aiding diagnosis. Real-life medical data set for thyroid diseases recognition was applied. Different fixed combined classifiers (mean, average, product, minimum, maximum, and majority vote) built on parametric and nonparametric Bayesian discriminant methods have been employed. No very significant improvement of recognition rates by a fixed classifier combination was achieved on the examined data. The best performance was obtained for resampling methods with classification trees, for both the bagging and the boosting combining methods. The bagging and the boosting logistic regression methods have proven less efficient than the bagging or the boosting of neural networks. Difference between the bagging and the boosting performance for the examined data set was not obtained.",
     "keywords": ["thyroid disease diagnosis", "combining classifiers performance", "bagging", "boosting", "trees", "logistic regression", "neural networks"]},
    {"article name": "Saccadometry and Movement Inhibition",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70035-9",
     "publication date": "01-2012",
     "abstract": "To reveal some functional constraints of the saccade inhibitory neuronal circuits, we investigated the influence of response monitoring in human. The subjects were instructed to perform a stop signal task in which the probability of stop trial occurrence was manipulated. The purpose of the work was to evaluate the time course necessary to adapt the behavior to changes in the occurrence of stop signal. Our results show that humans are capable to spatially monitor the relative probability event of stopping and to finely and quickly modulate their ability to inhibit a response. These results have important consequence to apprehend pathologies in which, an inaccurate control of inhibitory process results in a loss of fundamental capability of behavioral adaptation.",
     "keywords": ["saccade", "countermanding", "spatial inhibition"]},
    {"article name": "Analysing the Detail of Saccadic Reaction Time Distributions",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70036-0",
     "publication date": "01-2012",
     "abstract": "Measuring saccadic reaction time distributions is an increasingly popular technique, making it possible to obtain a large amount of data non-invasively in a short period of time. Such distributions can often be encapsulated with just two parameters, representing the mean and variance of the rate of rise in the LATER model. For many purposes, both scientific and clinical, this is enough. But for normal as well as pathological subjects, particularly when using more complex tasks, one may often see features that cannot be explained by a simple LATER model. These include early and express saccades, ‘late’ saccades, and (in tasks such as go/no-go and antisaccades) more complex modifications. These features can be explained relatively easily by introducing extra LATER units, and enable them to be quantitatively parameterised; this potentially offers much more precise ways of quantifying the effects of such clinical conditions.",
     "keywords": ["reaction time", "saccades", "latency", "LATER", "antisaccades"]},
    {"article name": "What the Future Holds for the Study of Saccades",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70037-2",
     "publication date": "01-2012",
     "abstract": "Here we review the state of the art using saccadic eye movements as windows to the function of the normal brain and of the abnormal brain plagued by disease or trauma. By combining sophisticated behavioral paradigms with rigorous mathematical analysis and the latest imaging techniques one can use saccades as biomarkers of the highest level decision making to the lowest level basic machinery that generates premotor saccade commands. As technology advances saccades will become even more useful as immediate monitors of the state of the brain in disease and trauma and as a way to evaluate therapies.",
     "keywords": ["saccades", "eye movements", "superior colliculus", "frontal eye fields"]},
    {"article name": "Preparation of Sulfonated Polysulfone Membrane for Enzymes Immobilisation",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70038-4",
     "publication date": "01-2012",
     "abstract": "The paper presents a method for the preparation of sulfonated polysulfone in order to receive a matrix to immobilisation of biomolecules. Optimum conditions of the synthesis are described. The phase inversion method was used to prepare a sulfonated polysulfone membrane and then urease was immobilized on the surface of the prepared matrix. Com-parison of activity of native urease and the immobilized urease is presented.",
     "keywords": ["sulfonated polysulfone", "immobilization of urease", "amination of sulfonated polysulfone"]},
    {"article name": "Cerebral Perfusion in Acute Stroke Monitored by Time-domain Near-infrared Reflectometry",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70028-1",
     "publication date": "01-2012",
     "abstract": "Though potentially relevant for monitoring of acute stroke, even specialized stroke units do not provide continuous methods to determine cerebral perfusion at the bedside. We present patient measurements on cerebral perfusion in ischemic stroke applying optical bolus tracking. To this end, our portable time-domain near-infrared reflectometer has been optimized and technically approved for clinical studies by a notified body. We used data analysis based on statistical moments of measured time-of-flight distributions of photons. Selective sensitivity to deep absorption changes and a suitable representation of cerebral signals is associated with the suppression of movement artifacts in severely affected patients. The proposed technique offers a unique possibility for a frequently repeatable monitoring of cerebral blood flow during acute and subacute cerebral ischemia directly at the bedside.",
     "keywords": ["light propagation in tissues", "time-resolved imaging", "optical bolus tracking"]},
    {"article name": "Multifractal Analysis of Laser Doppler Flowmetry Signals: Partition Function and Generalized Dimensions of Data Recorded before and after Local Heating",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70029-3",
     "publication date": "01-2012",
     "abstract": "Laser Doppler flowmetry (LDF) signals - that reflect the peripheral cardiovascular system - are now widespread in blood microcirculation research. Over the last few years, the central cardiovascular system has been the subject of many fractal and multifractal works. However, only very few multifractal studies of LDF signals have been published. Such multifractal analyses have shown that LDF data can be weakly multifractal but the origin of such characteristics are still unknown. We therefore herein propose a multifractal analysis of LDF signals recorded on the forearm of twelve healthy subjects, before and after skin local heating. The results show that the partition functions for all the signals have power-law characteristics. Moreover, generalized dimensions present very few variations with q for the signals recorded before heating; these variations are larger 20 minutes after local heating. Physiological activities may therefore play a role in the weak multifractal properties of LDF data.",
     "keywords": ["generalized dimensions", "laser Doppler flowmetry", "local heating", "microcir-culation", "multifractal analysis", "partition function"]},
    {"article name": "Reconstruction of the 3D Geometry of the Ossicular Chain Based on Micro-CT Imaging",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70030-X",
     "publication date": "01-2012",
     "abstract": "Modelling of the sound transmission process from the externai ear canal through the middle ear structures to the cochlea is often performed using the finite element method. This requires knowledge of the geometry of the object being modelled. The paper shows the results of reconstruction of the 3D geometry of the ossicular chain. The micro-CT images of a cadaver’s temporal bone were used to carry out the reconstruction process. The obtained geometry may be used not only for modelling of the middle ear mechanics before and after ossicular replacement but also for production of anatomical middle ear prostheses, calculation of inertial properties of the ossicular bones or educating radiologist and otolaryngologist.",
     "keywords": ["middle ear", "micro-CT", "3D geometry"]},
    {"article name": "Sol-gel Coated Fiberoptic Applicator for Photodynamic Medicine - Optical and AFM Characterization",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70031-1",
     "publication date": "01-2012",
     "abstract": "The application of spectroscopic study, microscopic and AFM imaging for examination of fiberoptic applicators is presented. The potential carriers of photoactive agents for photodynamic medicine in form of sol-gel coatings of fiberoptic applicators, are proposed. Optical and morphological properties of the proposed sol-gel coatings doped with photosensitizer Photolon, are characterized. The influence of pH and oxygen changes on entrapped Photolon properties, was examined, as well. The morphology of the applicator coating was examined by using atomic force microscopy. The light distribution from an applicator was studied by means of computer aided image analysis.",
     "keywords": ["photosensitizer", "Photolon", "biocarrier", "fiberoptic applicator", "PDT"]},
    {"article name": "Studies on the Structure of Semi-permeable Membranes by Means of SEM Problems and Potential Sources of Errors",
     "doi": "https://doi.org/10.1016/S0208-5216(12)70032-3",
     "publication date": "01-2012",
     "abstract": "The effect of sputtering with a conductor of the semi-permeable membranes surface on SEM pictures obtained is presented. On the example of photomicrographs of several different types of semi-permeable membranes, changes in the appearance of various membrane surfaces, uncovered and sputtered with thicker and thicker layers of the conductor are presented. It has been shown, how essential differences in the appearance of the studied material can be caused by the deposited conductor. It has been shown what errors in the interpretation of SEM images can be caused by applying the sputtered conductor layer with a thickness insufficient to the structure and properties of the studied material. Necessity of minimizing the layer thickness of the sputtered conductor and experimental determination of the sputtered layer thickness was found. Appropriateness of taking the pictures in the mode without sputtering and necessity of comparing the pictures with and without sputtering have been suggested. The useful way of carrying out magnifications’ of membranes made of polymers of low melting points has been also presented.",
     "keywords": ["SEM", "semi-permeable membranes", "polymeric microcapsules", "membrane studies"]},
    {"article name": "Analytical Microsystems for Biomedical and Environmental Applications",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70022-5",
     "publication date": "01-2011",
     "abstract": "Two types of analytical microsystems for the detection of species of interest in biomedical diagnosis and in environmental monitoring are specifically described in this paper. We describe a novel device that will measure whole blood concentration of D-dimer, a recognized biomarker of increased blood clotting activity and that will then offer opportunity to use the test in the point of care setting. The device combines innovation in antibody bio-engineering for high specificity immunoassay-based diagnostics and nano/ micro engineered impedimetric analysis electrodes incorporating a biocompatible polymer substrate with development of a disposable microfluidic manifold, enabling diagnostics at the point-of-first-contact.The feasibility of a generic microsytem integrating a microfluidic system of concentration and a module of electrochemical detection is demonstrated for the four metals of the European directive (DCE 2000/60/EC) for the quality of water resource: cadmium, mercury, lead and nickel.",
     "keywords": ["analytical microsystems", "fluidic microsystems", "Electrochemical Impedance Spectroscopy", "Deep Venous Thrombosis", "water resource", "heavy metals", "diamond like carbon"]},
    {"article name": "Carbon Nanotubes Chemically Derivatized with Redox Systems as Mediators for Biofuel Cell Applications",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70023-7",
     "publication date": "01-2011",
     "abstract": "The aim of this study was designing of nanostructured bioelectrodes and assembling them into a biofuel cell with no separating membrane. Carbon nanotubes (CNTs) chemically connected with residues of typical mediators, i.e. ferrocene (Fc) and 2,2′-azino-bis-(3-ethylbenzothiazoline)-6-sulfonic acid (ABTS) deposited on glassy carbon electrodes (GCE) were found useful as mediators for the enzyme catalyzed electrode processes. The electrodes were in turn covered with glucose oxidase from Aspergillus niger AM-11 and laccase from Cerrena unicolor C-139, respectively, incorporated in a liquid-crystalline matrix. The nanostructured electrode coating with the cubic phase film containing enzymes acted as the catalytic surface for the enzymatic reactions that is oxidation of glucose at anode and reduction of oxygen at cathode. For the system with mediators anchored to CNTs the catalysis was almost ten times more efficient than on bare GCE electrodes: catalytic current of glucose oxidation was 1 mAcm–2 and oxygen reduction current exceeded 0.6 mAcm–2. The open circuit voltage of the biofuel cell was 0.43 V. Application of the carbon nanotubes increased maximum power output of the constructed biofuel cell to 100 μWcm–2 without stirring the solution. It is ca. 100 times more efficient than using the same bioelectrodes without nanotubes on the electrode surface.",
     "keywords": ["biofuel cell", "laccase", "glucose oxidase", "cubic phase", "carbon nanotubes"]},
    {"article name": "LTCC Microfluidic Systems for Biochemical Diagnosis",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70024-9",
     "publication date": "01-2011",
     "abstract": "This paper presents design, fabrication and testing of three LTCC (Low Temperature Co-fired Ceramics) based microfluidic systems. These microdevices are: enzymatic microreactor for urea determination, potentiometric sensor with ion selective electrodes (ISE) based array sensitive to potassium ions and amperometric glucose sensor. Performance of the presented LTCC-based microfluidic systems has been tested. All ceramic microdevices have revealed high output signal and large detection range. The properties of the presented LTCC-based microfluidic systems are comparable with similar ones made of silicon. Obtained results has shown that presented ceramic microsystems can work as a stand-alone device or can be integrated into a more sophisticated micro analysis system for in vivo or in vitro monitoring of various (bio)chemical compounds.",
     "keywords": ["LTCC (Low Temperature Co-fired Ceramics)", "thick-film", "numerical modelling", "microreactor", "sensor"]},
    {"article name": "Electroconductive Polymers in (Bio)chemical Sensors",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70025-0",
     "publication date": "01-2011",
     "abstract": "In this paper, research concerning application of electroconducting polymers in biosensors is discussed. Selection of the electropolymers has been limited to those which monomers are water-soluble, such as: polypyrrole and polyaniline. In general, experiments concerning EP utilization in dehydrogenase based biosensors were divided in four stages: (1) incorporation of mediators as dopants of the EP’s layer, (2) immobilization of cofactors e.g. NAD+/NADH, (3) immobilization of enzymes and (4) immobilization of all components: mediator, cofactor and enzyme. As a dopant of the PPy water-soluble electroactive compound ferrocyanide was used. Another EP, namely polyaniline was also tested as an electrode material for NADH detection based on its electrochemical oxidation. In the case of simultaneous immobilization of mediator, NAD, and ADH in the PPy layer, as a result of the ethanol oxidation, the oxidation peaks of the mediator become smaller whereas the oxidation peaks of PPy increase. In the analyzed EtOH concentration range (0 – 2 mM), slope of calibration curve for the PPy oxidation peak was around 20 µA/mM. In the case of PAn deposition on the platinum electrode, decrease of the oxidation potential for NADH by 0.4 V was observed.",
     "keywords": ["NAD/NADH", "enzymatic biosensors", "electroconductive polymers", "polypyr-role", "polyaniline", "electroactive mediator"]},
    {"article name": "Artifacts Extraction from EEG Data Using the Infomax Approach",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70026-2",
     "publication date": "01-2011",
     "abstract": "The aim of the research is to detect and remove undesired components from EEG data by means of ICA approach. Besides classical signal analysis tools such as adaptive supervised filtering, parametric or non-parametric spectral estimation, time-frequency analysis, the proposed ICA technique can be used for detection of a wide group of artifacts from EEG data. In this paper a new form of nonlinearity implemented in the infomax approach is presented. As it has been proven experimentally, the proposed new sigmoidal function can effectively detect the selected group of artifacts from EEGs and is an useful approach to speed up computations.",
     "keywords": ["Independent Component Analysis", "infomax algorithm", "sigmoidal function", "EEG data", "artifacts"]},
    {"article name": "Quantitative Examination of Liver Tissue Ultrasound Elastograms",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70027-4",
     "publication date": "01-2011",
     "abstract": "Methods of computer-aided statistical analysis of ultrasound elastograms are presented. An approach consisting in initial segmentation of elastograms visualizing low-elasticity segments distribution in the tissue of an examined biological organ and in statistical analysis of this distribution is described. Satisfactory correlation between the values of some statistics and medical specialists’ description of human liver elastograms was observed. The ways of continuation of the works aimed at improvement of the elastograms-based diagnostic methods are suggested.",
     "keywords": ["image processing", "ultrasound elastography", "image segmentations", "liver fibrosis"]},
    {"article name": "Transcranial Magnetic Stimulation as a Tool for Brain Cortex Excitability Analysis in Migraine Pathophysiology",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70015-8",
     "publication date": "01-2011",
     "abstract": "Evidence is growing that neuronal excitability and responsiveness to sensory stimulation increase in migraine at cortical and brain stem levels. The perception of phosphenes induced by transcranial magnetic stimulation (TMS) allows analysis of visual cortex excitability during migraine attacks and interictal periods; TMS can also help assess prophylactic drug effects. The paper reviews studies of anticonvulsants and discuss the reduction of migraine frequency correlated inversely with an increase of phosphene thresholds and not correlated with motor thresholds. Multidisciplinary analysis along with TMS will aid our understanding of migraine mechanisms since most modern anticonvulsants have complex effects, not simply inhibition of cortical excitability.",
     "keywords": ["migraine", "pathophysiology", "cortex excitability", "transcranial magnetic stimulation", "evoked potential", "electroencephalography", "anticonvulsants"]},
    {"article name": "Deep Brain Recordings",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70016-X",
     "publication date": "01-2011",
     "abstract": "Depth recordings from human subcortical structures have improved our knowledge of human brain circuitries and provided better understanding of the effects and mechanism of action of deep brain stimulation. Two types of signals can be recorded: single unit spikes and local field potentials (LFP). The basal ganglia (BG) are particularly well suited for deep brain recordings and here we review how the oscillatory activities recorded in these structures helped improve our understanding of the sensorimotor brain functions in particular, along with cognitive and emotional-motivational. The oscillations may be classified by frequency into bands at < 8, 8–30 and > 60 Hz. The best characterized band is the 8–30 Hz and existing evidence suggests that it is antikinetic and inversely related to motor processing. On the other hand, accumulating evidence suggests that the > 60 Hz band may be related to normal function.",
     "keywords": ["Deep Brain Stimulation", "basal ganglia", "Local Field Potential", "electrophy-siology", "neurophysiology"]},
    {"article name": "The Influence of Repetitive Transcranial Magnetic Stimulation on Sleep in Parkinson’s Disease",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70017-1",
     "publication date": "01-2011",
     "abstract": "Sleep disturbance is common in Parkinson’s disease (PD). In this study we investigated the effect of a novel therapeutic tool, repetitive transcranial magnetic stimulation (rTMS) on sleep quality in PD patients. The study group consisted of 11 PD patients who underwent ten daily rTMS sessions at 15 Hz. Their sleep patterns were monitored with polysomnography. After the stimulation, non-REM stage-1 sleep and the number of nocturnal arousals decreased, thus improving sleep quality. These changes were probably related to the improvement of motor symptoms observed in UPDRS and in the 9 Hole peg test.",
     "keywords": ["Parkinson\u2019s Disease", "repetitive transcranial magnetic stimulation", "sleep", "polysomnography", "motor symptoms"]},
    {"article name": "Subthalamic Nucleus Deep Brain Stimulation in Parkinson’s Disease",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70018-3",
     "publication date": "01-2011",
     "abstract": "A group of 37 patients diagnosed with Parkinson’s disease (PD) were treated with subthalamic deep brain stimulation (STN DBS). The mean age at implantation was 59±11 years and PD has been present from 6 to 17 years (mean 9). The STN was identified by direct and indirect methods: macro stimulation and microrecording in all cases. At a three month follow-up, the authors observed a mean reduction of 49% in UPDRS II score and a mean reduction of 65% in UPDRS III score. Mean reduction of l-dopa consumption was 62%. The authors concluded that STN DBS safely reduces disabling symptoms of PD.",
     "keywords": ["deep brain stimulation", "subthalamic nucleus", "Parkinson\u2019s disease"]},
    {"article name": "Deep Brain Stimulation in Generalized Dystonia",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70019-5",
     "publication date": "01-2011",
     "abstract": "Eleven patients with diagnosed generalized dystonia (GD) were treated with deep brain stimulation (DBS). The clinical status of the patients was evaluated and recorded pre- and post-operatively. The target globus pallidus or subthalamic nucleus was identified with direct and indirect methods and confirmed electrophysiologically in the operating room. All eleven patients reported subjective improvement following the surgery what was confirmed using scales tailored for the group. The improvement lasted from 10 months to 40 months. DBS can be effectively and safely utilized to alleviate symptoms of generalized dystonia in selected patients.",
     "keywords": ["dystonia", "deep brain stimulation", "globus pallidus"]},
    {"article name": "The Role of Visual Perception in Spoken Responses",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70020-1",
     "publication date": "01-2011",
     "abstract": "How subjects voice responses to flashed visual symbols was investigated at successive stages of the information processing. The representation exits from V1 mainly by 120–140, mean 130ms; cortical motor output to voice onset has a mean delay of 85ms. The latencies of voicing only a noise, blurting versus perceiving before responding correctly yield mean delays for perception (85ms) and for spatio-temporal motor coding of digits (45ms), with a mean total delay of 345ms. Prefrontal cortex and Intralaminar N. also contribute to perception.",
     "keywords": ["visual perception", "occipito-frontal flow", "Broca excitability", "TMS mapping"]},
    {"article name": "Electrodes and Chronic Optic Nerve Stimulation",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70021-3",
     "publication date": "01-2011",
     "abstract": "Visual pathways are often schematized as a parallel afferent transmission of pixel image matrices. Suggested interfaces would thus have numerous contacts in close proximity to the target elements. However, well organised tissue reactions would actively keep electrodes away from the neural units.Alternatively, self sizing spiral cuffs were wrapped around the optic nerve of two blind volunteers in an attempt to develop a visual prosthesis. Unexpected features of the optic nerve code have emerged. This interface remained well tolerated for more than ten years. However, there is still a long way to go before to reach the useful vision rehabilitation.",
     "keywords": ["implantable electrodes", "foreign body reaction", "visual prosthesis", "optic nerve code", "neural interface"]},
    {"article name": "Preventive Systems for the Late Complications of Diabetes",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70007-9",
     "publication date": "01-2011",
     "abstract": "Aim of this work is to review and characterize methods and systems that are used to prevent onset and to slow down the progression of the late complications of diabetes. Two groups of methods and systems that might be used to prevent or to slow down the progression of the late complications of diabetes are characterized in this paper. Each of these two groups serves a different purpose. The first group is composed of the systems that facilitate a maintenance of strict metabolic control in diabetic patients, i.e. the systems which are used for monitoring and treatment of diabetes. The second group contains systems that are aimed at screening/monitoring or treatment of the risk factors or the early signs of the late complications. Obesity increases risk of diabetes and its complications. Thus, body mass monitoring and control systems are examples of the tools that belong to this group. Other examples include the diabetic retinopathy telescreening systems and the systems for monitoring of the diabetic foot syndrome.",
     "keywords": ["diabetes mellitus", "diabetes late complications", "telemedicine", "glucose monitoring", "diabetic retinopathy", "diabetic foot syndrome", "telecare", "telemonitoring"]},
    {"article name": "Development of a Drug Delivery System Using Microcapsules with Ultrasound",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70008-0",
     "publication date": "01-2011",
     "abstract": "Micrometer-sized microcapsules collapse upon exposure to ultrasound. Use of this phenomenon for a drug delivery system (DDS), not only for local delivery of medication but also for gene therapy, should be possible. However, enhancing of efficiency of medication is limited because the capsules in suspension diffuse in the human body after injection, since the motion of the capsules in blood flow cannot be controlled. To control behavior of the microcapsules, an acoustic radiation force was introduced. We detected local changes in the microcapsule density by producing of acoustic radiation force in an artificial blood vessel. Furthermore, we theoretically estimated the conditions required for an active path selection of the capsules at a bifurcation point in the artificial blood vessel. We observed the difference in the capsule density at both in the bifurcation point and in alternative paths downstream of the bifurcation point for the different acoustic radiation forces. We also confirmed that the microcapsules are trapped against flow with the condition when the acoustic radiation force is more than the fluid resistance of the capsules. The possibility of controlling of the capsule flow towards a specific point in a blood vessel was demonstrated.",
     "keywords": ["microcapsule", "acoustic radiation force", "drug delivery", "artificial blood vessel"]},
    {"article name": "Multimodal Neurosurgery Force Feedback System Based on Mesh Fusion Modeling",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70009-2",
     "publication date": "01-2011",
     "abstract": "Virtual reality based force feedback system is spotlighted as a safe and efficient training environment to obtain surgical skills. Neurosurgery utilizes multimodal patient images for visualization of a variety of functions in head. The aim of this study is to establish a concept of multimodal neurosurgery force feedback system based on mesh fusion modeling. In the model of mesh fusion, we developed an algorithm to detect overlapped region between the multiple meshes that are obtained from multimodal images, and to determine a new boundary between the meshes. Then, the method solved interaction between the newly defined mesh boundaries using the interaction model based on a finite element method. The proposed method was implemented, and applied to both simple and patient datasets for evaluating its applicability. As a result, the method succeeded to be applied to both simple and patient datasets. Finally, we demonstrated the early stage of the surgical approach in neurosurgery. Simulation results showed a real-time simulation of brain tissue deformation with force feedback.",
     "keywords": ["virtual reality", "surgical simulation", "neurosurgery", "finite element method", "haptics"]},
    {"article name": "Can Vibration Stimuli to Planta Pedis Prevent the Fall Accident?",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70010-9",
     "publication date": "01-2011",
     "abstract": "Considering the aged population increase, the prevention of falls will become increasingly importance. One of the causes of elderly people fall is the decline of the balance ability. The purpose of this study is to examine the difference of the sensitivities to the single frequency vibration of three places in planta pedis. We made a simple vibration stimulator, which can give 225 Hz vibration stimuli to three places of planta pedis. This frequency was decided by our prior study. The vibration stimuli places were the heel, the root of the big toe and the root of the little toe. The intensity of the stimulus was set to 90% of the smallest stimulus intensity that the subject could feel. We evaluated the effect of vibration stimuli by the center-of-foot-pressure (CFP) sway and the duration of one-leg standing with closed eyes. The results showed that the duration was extended and the locus length of CFP sway was decreased by the stimulation of only one place. The most effective place was the root of the big toe. Our result is that the vibration stimuli to planta pedis are useful for the fall prevention of elderly people.",
     "keywords": ["fall prevention", "vibration stimuli", "Vater-Pacini\u2019s corpuscle"]},
    {"article name": "Method to Develop Pseudo Three-dimensional Dental Image from Dental Panoramic Radiograph",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70011-0",
     "publication date": "01-2011",
     "abstract": "Although three-dimensional imaging can be a powerful tool for dentists to explain treatments to patients, obtaining of three-dimensional image of teeth in general dental clinics is difficult. This paper proposed a method to develop pseudo three-dimensional dental image from conventional dental panoramic radiograph and dental impression. The method estimates imaging parameters of given panoramic radiograph through comparison with dental cast, and re-projects the radiograph into three-dimensional space. The developed pseudo three-dimensional image gives clear impression of the patient’s dental condition.",
     "keywords": ["dental panoramic radiograph", "dental impression", "three-dimensional image development"]},
    {"article name": "Non-invasive Cortical Stimulation for the Treatment of Pain",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70012-2",
     "publication date": "01-2011",
     "abstract": "Non-invasive cortical stimulation techniques are promising tools in the arsenal against refractory chronic pain. Repetitive transcranial magnetic stimulation can produce analgesic effects, leading to consideration of this technique as a therapeutic tool per se or as a prognostic tool to select candidates for subsequent implanted epidural motor cortex stimulation. This review focuses on the optimal parameters of stimulation, including the cortical target, coil orientation, stimulation intensity and frequency. The long-lasting effects of consecutive daily sessions and the possibility for ameliorating specific components of pain are also discussed.",
     "keywords": ["transcranial magnetic stimulation", "TMS trials", "analgesic effects", "motor cortex stimulation"]},
    {"article name": "Transcranial Magnetic Stimulation: Twenty Years of Stimulating the Human Motor Cortex in Health and Disease",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70013-4",
     "publication date": "01-2011",
     "abstract": "In the motor system, transcranial magnetic stimulation (TMS) has proved an invaluable tool to study the organisation and interaction of the cortical motor areas. In this review I describe some of the ways in which TMS has been used to map out the major topographical features of the motor output and to test how these change in response motor learning or after peripheral (e.g. amputation) or central (e.g. stroke) injury. More recent work has shown that longer periods of repeated TMS involving several hundred to a thousand pulses can lead to lasting changes in motor cortex excitability that are thought to involve changes in the efficacy of intracortical synapses equivalent to LTP and LTP in slice preparations. These are accompanied by changes in the rate of motor learning and are presently being trialled as potential treatments to speed recovery from stroke.",
     "keywords": ["transcranial magnetic stimulation", "TMS", "repetitive TMS", "virtual lesion", "plasticity", "stroke rehabilitation", "cortical mapping"]},
    {"article name": "Excitatory and Inhibitory Effects of Transcranial Magnetic Stimulation",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70014-6",
     "publication date": "01-2011",
     "abstract": "This paper reviews the use of transcranial magnetic stimulation (TMS) in investigating intracortical circuits in the primary motor cortex (M1). TMS is a noninvasive and painless method of stimulating the human brain and has become a widely used technique in neuro-physiology and neurology. When TMS is applied to the M1, it generates a motor evoked potential (MEP) in the target muscles. TMS also activates different intracortical circuits within the M1 and connections from other cortical areas to the M1. These intracortical circuits interact with each other. Abnormalities in these circuits are found in neurological and psychiatric disorders and studies of these circuits are useful in understanding the pathophysiology of these conditions.",
     "keywords": ["transcranial magnetic stimulation", "primary motor cortex", "motor evoked potential", "intracortical circuit", "inhibition", "facilitation"]},
    {"article name": "Circulatory Assistance: Basic Classification of Heart Assistance Methods and Devices",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70001-8",
     "publication date": "01-2011",
     "abstract": "This paper is focused on basic classification of mechanical circulatory assistance methods and devices regarding a way of their connection to the circulatory system (parallel, “in-series”), different manner of work (pulsatile, continuous-flow) or a goal of appliance (bridge to recovery, bridge to transplant, Total Artificial Heart). Also schematic layout of subjectively chosen assist devices are shown and discussed.The paper does not pretend to give an exhaustive description of mechanical circulatory assistance but rather evidence, after some brief historical remarks, the substance of the circulatory support itself.",
     "keywords": ["mechanical heart assistance", "coronary perfusion", "heart support devices", "diastolic augmentation", "pulmonary stagnation"]},
    {"article name": "Application of Coherence Function for Calculating Time Shifts between Axial Corneal Displacements and Electrical Heart Activity",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70002-X",
     "publication date": "01-2011",
     "abstract": "The heart activity is one of the most important factors influencing the ocular pulsation. It is known that the high correlation between axial corneal displacements and cardiovascular system activity exists. However, phase relationships between those factors are still unknown. The main goal of the research was to measure noninvasively longitudinal corneal apex displacement (LCAD) of the left eye, applying an ultrasonic sensor. Synchronically, the electrical heart activity (ECG) was recorded in Einthoven’s triangle. To find phase dependencies between these signals the coherence function was used. It is observed that coherence value, computed between the first five harmonics of both signals, is different for shifted signals along each other. Therefore, the time delay between the ECG and LCAD signals, for which particular harmonic achieves the maximum of coherence function, was examined. It can be noticed that for increasing number of the signals’ harmonic, the time delay between considered signals decreases. This tendency is clear for both of examined subjects. To receive more information about this phenomenon more subjects should be measured and the statistical test should be introduced to calculate the time delay values. The presented noninvasive method might be helpful in the future for measuring the IOP pulse and estimating hemodynamic status of the eye.",
     "keywords": ["longitudinal corneal apex displacement", "ECG signal", "coherence analysis", "time shifts calculation"]},
    {"article name": "A New Concept of Filters for Biomedical Data Processing Needs",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70003-1",
     "publication date": "01-2011",
     "abstract": "This paper presents a new class of filters that can meet biomedical signal processing needs. The paper is written in a technical note style, therefore, the proposed filters are not discussed with respect to a specific problem appearing in processing of a particular biosignal. The class of filters presented in this note should be treated as a new effective tool which can be applied to many cases of biomedical signals, especially when the processing time is very important. Nevertheless, a simple example of biomedical signal filtering is presented. This paper presents a new concept of continuous-time Butterworth filters whose parameters are varied in time. Thanks to the variation of the filter parameters, the time-varying filter response is considerably faster in comparison with the traditional time-invariant filters. Therefore, we can measure and register a lot of details in the initial stage of signal duration, which is not possible in the case of traditional time-invariant filters due to their long-lasting transients. Results verifying the effectiveness of the proposed filters are presented and compared to the traditional time-invariant filter structures.",
     "keywords": ["signal processing", "data smoothing", "biomedical signals", "transient state", "time-varying systems"]},
    {"article name": "Distributed Modeling of Osmotic Fluid Flow during Single Exchange with Hypertonic Glucose Solution",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70004-3",
     "publication date": "01-2011",
     "abstract": "The aim of the study was to model fluid and solute peritoneal transport inside the tissue together with the kinetics in peritoneal cavity during single exchange with hypertonic glucose 3.86% solution. The distributed model of osmotic flow and glucose transport was formulated and applied for computer simulations assuming 1 cm width of tissue layer. The simulated kinetics of intraperitoneal volume and glucose concentration were in good agreement with clinical data. The predicted intratissue profiles of glucose concentration and hydrostatic pressure of the interstitial fluid demonstrated a restricted penetration of glucose (0.1 cm) and water (0.25 cm) into the interstitium at the end of dwell time, in agreement with animal data. The proposed model was able to describe correctly the basic kinetics of peritoneal dialysis as investigated in clinical studies and intratissue profiles known from animal studies.",
     "keywords": ["peritoneal dialysis", "distributed model", "osmotic flow"]},
    {"article name": "The Effect of Foot Orthotics on Arch Height: Prediction of Arch Height Correction in Flat-foot Children",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70005-5",
     "publication date": "01-2011",
     "abstract": "Prognosis of the arch height correction could provide valuable information in prescribing appropriate treatment to reduce the consequences of flat-foot. The goal of this study was twofold. First we explored effect of foot orthotics wedging on the gait pattern of flat-footed children population. Then a simple model to predict arch height correction using six variables was proposed. Measured parameters included the arch height, X-ray measurement, and ground reaction force (GRF). The suggested model allows predicting of the arch height correction. The results show that foot orthotics has small, but a positive impact on the arch height correction.",
     "keywords": ["flat-foot", "arch height", "X-ray", "foot orthotics", "regression analysis"]},
    {"article name": "31P High Resolution NMR Spectroscopy in Analysis of Phosphate-containing Compounds of Bile",
     "doi": "https://doi.org/10.1016/S0208-5216(11)70006-7",
     "publication date": "01-2011",
     "abstract": "31P high resolution nuclear magnetic resonance (NMR) spectroscopy was used to examine phospholipid metabolism and to analyze the phosphate-containing compounds in the bile in the transplanted liver recipients, the cholelithiasis patients’ and the living donors’ groups. Three signals of NMR spectrum of raw bile were determined: inorganic phosphate (Pi), lysophosphatidylcholine (LPtdC), and phosphatidylcholine (PtdC) in all investigated groups. Pi concentration was significantly higher in the recipients’ group than in the living donors’ group (Mann-Whitney test, p < 0.05). LPtdC and PtdC concentrations were significantly higher (Mann-Whitney test, p < 0.05) in the cholelithiasis patients’ group in comparison to the recipients’ group. Between the cholelithiasis patients’ group and the living donors’ group no significant differences in the three analysed compounds were found. The chemometric analysis for the 31P NMR spectral data set provided good classifications between the living donors’ and recipients’ groups and the poor one among all groups. Results of our study suggest that 31P NMR spectroscopy in vitro may be used for assessment of graft function, for the early signs of rejection and for the predisposition to gallstone formation.",
     "keywords": ["phospholipids", "orthothopic liver transplantation", "metabolomics", "31P NMR \u2013 Nuclear Magnetic Resonance of phosphorus nuclei", "HPLC \u2013 High Performance Liquid Chromatography", "TLC \u2013 Thin Layer Chromatography", "VIP \u2013 Variable Importance Plot", "PLS \u2013 Partial Least Square", "PLS-DA \u2013 Partial Least Square \u2013 Discriminant Analysis", "MS \u2013 Mass Spectroscopy", "UV \u2013 Ultraviolet", "Pi \u2013 inorganic phosphate", "LPtdC \u2013 lysophosphatidylcholine", "PtdC \u2013 phosphatidylcholine;", "OLTx \u2013 orthothopic liver transplantation", "OD \u2013 outer diameter"]}
    ]
}